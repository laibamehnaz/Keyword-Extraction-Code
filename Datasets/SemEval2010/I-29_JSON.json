{"Distributed Management of Flexible Times Schedules\nStephen F. Smith, Anthony Gallagher, Terry Zimmerman,\nLaura Barbulescu, Zachary Rubinstein\nThe Robotics Institute, Carnegie Mellon University\n5000 Forbes Avenue, Pittsburgh PA 15024\n{sfs,anthonyg,wizim,laurabar,zbr}@cs.cmu.edu\nABSTRACT\nWe consider the problem of managing schedules in an \nuncertain, distributed environment. We assume a team of \ncollaborative agents, each responsible for executing a portion\nof a globally pre-established schedule, but none possessing\na global view of either the problem or solution. The goal\nis to maximize the joint quality obtained from the activities\nexecuted by all agents, given that, during execution, \nunexpected events will force changes to some prescribed \nactivities and reduce the utility of executing others. We describe\nan agent architecture for solving this problem that couples\ntwo basic mechanisms: (1) a flexible times representation\nof the agent\"s schedule (using a Simple Temporal Network)\nand (2) an incremental rescheduling procedure. The former\nhedges against temporal uncertainty by allowing execution\nto proceed from a set of feasible solutions, and the latter acts\nto revise the agent\"s schedule when execution is forced \noutside of this set of solutions or when execution events reduce\nthe expected value of this feasible solution set. Basic \ncoordination with other agents is achieved simply by \ncommunicating schedule changes to those agents with inter-dependent\nactivities. Then, as time permits, the core local problem\nsolving infra-structure is used to drive an inter-agent option\ngeneration and query process, aimed at identifying \nopportunities for solution improvement through joint change. Using\na simulator to model the environment, we compare the \nperformance of our multi-agent system with that of an expected\noptimal (but non-scalable) centralized MDP solver.\nCategories and Subject Descriptors\nI.2.11 [Computing Methodologies]: Artificial \nIntelligenceDistributed Artificial Intelligence\nGeneral Terms\nAlgorithms, Design\n1. INTRODUCTION\nThe practical constraints of many application \nenvironments require distributed management of executing plans\nand schedules. Such factors as geographical separation of\nexecuting agents, limitations on communication bandwidth,\nconstraints relating to chain of command and the high tempo\nof execution dynamics may all preclude any single agent\nfrom obtaining a complete global view of the problem, and\nhence necessitate collaborative yet localized planning and\nscheduling decisions. In this paper, we consider the problem\nof managing and executing schedules in an uncertain and\ndistributed environment as defined by the DARPA \nCoordinators program. We assume a team of collaborative agents,\neach responsible for executing a portion of a globally \npreestablished schedule, but none possessing a global view of\neither the problem or solution. The team goal is to maximize\nthe total quality of all activities executed by all agents, given\nthat unexpected events will force changes to pre-scheduled\nactivities and alter the utility of executing others as \nexecution unfolds. To provide a basis for distributed coordination,\neach agent is aware of dependencies between its scheduled\nactivities and those of other agents. Each agent is also given\na pre-computed set of local contingency (fall-back) options.\nCentral to our approach to solving this multi-agent \nproblem is an incremental flexible-times scheduling framework.\nIn a flexible-times representation of an agent\"s schedule, the\nexecution intervals associated with scheduled activities are\nnot fixed, but instead are allowed to float within imposed\ntime and activity sequencing constraints. This \nrepresentation allows the explicit use of slack as a hedge against simple\nforms of executional uncertainty (e.g., activity durations),\nand its underlying implementation as a Simple Temporal\nNetwork (STN) model provides efficient updating and \nconsistency enforcement mechanisms. The advantages of \nflexible times frameworks have been demonstrated in various\ncentralized planning and scheduling contexts (e.g., [12, 8, 9,\n10, 11]). However their use in distributed problem solving\nsettings has been quite sparse ([7] is one exception), and\nprior approaches to multi-agent scheduling (e.g., [6, 13, 5])\nhave generally operated with fixed-times representations of\nagent schedules.\nWe define an agent architecture centered around \nincremental management of a flexible times schedule. The \nunderlying STN-based representation is used (1) to loosen the\ncoupling between executor and scheduler threads, (2) to \nretain a basic ability to absorb unexpected executional delays\n(or speedups), and (3) to provide a basic criterion for \ndetecting the need for schedule change. Local change is \nac484\n978-81-904262-7-5 (RPS) c 2007 IFAAMAS\nFigure 1: A two agent C TAEMS problem.\ncomplished by an incremental scheduler, designed to \nmaximize quality while attempting to minimize schedule change.\nTo this schedule management infra-structure, we add two\nmechanisms for multi-agent coordination. Basic \ncoordination with other agents is achieved by simple \ncommunication of local schedule changes to other agents with \ninterdependent activities. Layered over this is a non-local option\ngeneration and evaluation process (similar in some respects\nto [5]), aimed at identification of opportunities for global\nimprovement through joint changes to the schedules of \nmultiple agents. This latter process uses analysis of detected\nconflicts in the STN as a basis for generating options.\nThe remainder of the paper is organized as follows. We \nbegin by briefly summarizing the general distributed \nscheduling problem of interest in our work. Next, we introduce the\nagent architecture we have developed to solve this problem\nand sketch its operation. In the following sections, we \ndescribe the components of the architecture in more detail,\nconsidering in turn issues relating to executing agent \nschedules, incrementally revising agent schedules and \ncoordinating schedule changes among multiple agents. We then give\nsome experimental results to indicate current system \nperformance. Finally we conclude with a brief discussion of\ncurrent research plans.\n2. THE COORDINATORS PROBLEM\nAs indicated above the distributed schedule management\nproblem that we address in this paper is that put forth by\nthe DARPA Coordinators program. The Coordinators \nproblem is concerned generally with the collaborative execution\nof a joint mission by a team of agents in a highly dynamic\nenvironment. A mission is formulated as a network of tasks,\nwhich are distributed among the agents by the MASS \nsimulator such that no agent has a complete, objective view\nof the whole problem. Instead, each agent receives only a\nsubjective view containing just the portion of the task\nnetwork that relates to ground tasks that it is responsible\nfor and any remote tasks that have interdependencies with\nthese local tasks. A pre-computed initial schedule is also \ndistributed to the agents, and each agent\"s schedule indicates\nwhich of its local tasks should be executed and when. Each\ntask has an associated quality value which accrues if it is\nsuccessfully executed within its constraints, and the overall\ngoal is to maximize the quality obtained during execution.\nFigure 2: Subjective view for Agent 2.\nAs execution proceeds, agents must react to unexpected \nresults (e.g., task delays, failures) and changes to the mission\n(e.g., new tasks, deadline changes) generated by the \nsimulator, recognize when scheduled tasks are no longer feasible or\ndesirable, and coordinate with each other to take corrective,\nquality-maximizing rescheduling actions that keep execution\nof the overall mission moving forward.\nProblems are formally specified using a version of the\nTAEMS language (Task Analysis, Environment Modeling\nand Simulation) [4] called C TAEMS [1]. Within C TAEMS,\ntasks are represented hierarchically, as shown in the \nexample in Figure 1. At the highest, most abstract level, the\nroot of the tree is a special task called the task group.\nOn successive levels, tasks constitute aggregate activities,\nwhich can be decomposed into sets of subtasks and/or \nprimitive activities, termed methods. Methods appear at the\nleaf level of C TAEMS task structures and are those that\nare directly executable in the world. Each declared method\nm can only be executed by a specified agent (denoted by\nag : AgentN in Figure 1) and each agent can be \nexecuting at most one method at any given time (i.e. agents are\nunit-capacity resources). Method durations and quality are\ntypically specified as discrete probability distributions, and\nhence known with certainty only after they have been \nexecuted.1\nIt is also possible for a method to fail unexpectedly\nin execution, in which case the reported quality is zero.\nFor each task, a quality accumulation function qaf is \ndefined, which specifies when and how a task accumulates \nquality as its subtasks (methods) are executed. For example, a\ntask with a min qaf will accrue the quality of its child with\nlowest quality if all its children execute and accumulate \npositive quality. Tasks with sum or max qafs acquire quality as\nsoon as one child executes with positive quality; as their qaf\nnames suggest, their respective values ultimately will be the\ntotal or maximum quality of all children that executed. A\nsync-sum task will accrue quality only for those children\nthat commence execution concurrently with the first child\nthat executes, while an exactly-one task accrues quality only\nif precisely one of its children executes.\nInter-dependencies between tasks/methods in the \nproblem are modeled via non-local effects (nles). Two types of\nnles can be specified: hard and soft. Hard nles express\n1\nFor simplicity, Figures 1 and 2 show only fixed values for\nmethod quality and duration.\nThe Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 485\ncausal preconditions: for example, the enables nle in Figure\n1 stipulates that the target method M5 can not be executed\nuntil the source M4 accumulates quality. Soft nles, which\ninclude facilitates and hinders, are not required constraints;\nhowever, when they are in play, they amplify (or dampen)\nthe quality and duration of the target task.\nAny given task or method a can also be constrained by an\nearliest start time and a deadline, specifying the window in\nwhich a can be feasibly executed. a may also inherit these\nconstraints from ancestor tasks at any higher level in the\ntask structure, and its effective execution window will be\ndefined by the tightest of these constraints.\nFigure 1 shows the complete objective view of a simple 2\nagent problem. Figure 2 shows the subjective view available\nto agent 2 for the same problem. In what follows, we will\nsometimes use the term activity to refer generically to both\ntask and method nodes.\n3. OVERVIEW OF APPROACH\nOur solution framework combines two basic principles for\ncoping with the problem of managing multi-agent schedules\nin an uncertain and time stressed execution environment.\nFirst is the use of a STN-based flexible times \nrepresentation of solution constraints, which allows execution to be\ndriven by a set of schedules rather than a single point\nsolution. This provides a basic hedge against temporal \nuncertainty and can be used to modulate the need for solution\nrevision. The second principle is to first respond locally to\nexceptional events, and then, as time permits, explore \nnonlocal options (i.e., options involving change by 2 or more\nagents) for global solution improvement. This provides a\nmeans for keeping pace with execution, and for tying the\namount of effort spent in more global multi-agent solution\nimprovement to the time available. Both local and non-local\nproblem solving time is further minimized by the use of a\ncore incremental scheduling procedure.\nFigure 3: Agent Architecture.\nOur solution framework is made concrete in the agent \narchitecture depicted in Figure 3. In its most basic form, an\nagent comprises four principal components - an Executor, a\nScheduler, a Distributed State Manager (DSM), and an \nOptions Manager - all of which share a common model of the\ncurrent problem and solution state that couples a \ndomainlevel representation of the subjective c taems task structure\nto an underlying STN. At any point during operation, the\ncurrently installed schedule dictates the timing and sequence\nof domain-level activities that will be initiated by the agent.\nThe Executor, running in its own thread, continually \nmonitors the enabling conditions of various pending activities,\nand activates the next pending activity as soon as all of its\ncausal and temporal constraints are satisfied.\nWhen execution results are received back from the \nenvironment (MASS) and/or changes to assumed external \nconstraints are received from other agents, the agent\"s model of\ncurrent state is updated. In cases where this update leads\nto inconsistency in the STN or it is otherwise recognized\nthat the current local schedule might now be improved, the\nScheduler, running on a separate thread, is invoked to revise\nthe current solution and install a new schedule. Whenever\nlocal schedule constraints change either in response to a \ncurrent state update or through manipulation by the Scheduler,\nthe DSM is invoked to communicate these changes to \ninterested agents (i.e., those agents that share dependencies and\nhave overlapping subjective views).\nAfter responding locally to a given state update and \ncommunicating consequences, the agent will use any remaining\ncomputation time to explore possibilities for improvement\nthrough joint change. The Option Manager utilizes the\nScheduler (in this case in hypothetical mode) to generate\none or more non-local options, i.e., identifying changes to\nthe schedule of one or more other agents that will enable the\nlocal agent to raise the quality of its schedule. These options\nare formulated and communicated as queries to the \nappropriate remote agents, who in turn hypothetically evaluate\nthe impact of proposed changes from their local \nperspective. In those cases where global improvement is verified,\njoint changes are committed to.\nIn the following sections we consider the mechanics of\nthese components in more detail.\n4. THE SCHEDULER\nAs indicated above, our agent scheduler operates \nincrementally. Incremental scheduling frameworks are ideally\nsuited for domains requiring tight scheduler-execution \ncoupling: rather than recomputing a new schedule in response\nto every change, they respond quickly to execution events\nby localizing changes and making adjustments to the current\nschedule to accommodate the event. There is an inherent\nbias toward schedule stability which provides better support\nfor the continuity in execution. This latter property is also\nadvantageous in multi-agent settings, since solution stability\ntends to minimize the ripple across different agents\" \nschedules.\nThe coupling of incremental scheduling with flexible times\nscheduling adds additional leverage in an uncertain, \nmultiagent execution environment. As mentioned earlier, slack\ncan be used as a hedge against uncertain method execution\ntimes. It also provides a basis for softening the impact of\ninter-dependencies across agents.\nIn this section, we summarize the core scheduler that we\nhave developed to solve the Coordinators problem. In \nsubsequent sections we discuss its use in managing execution\nand coordinating with other agents.\n4.1 STN Solution Representation\nTo maintain the range of admissible values for the start\nand end times of various methods in a given agent\"s \nsched486 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)\nule, all problem and scheduling constraints impacting these\ntimes are encoded in an underlying Simple Temporal \nNetwork (STN)[3]. An STN represents temporal constraints\nas a graph G < N, E >, where nodes in N represent the\nset of time points of interest, and edges in E are distances\nbetween pairs of time points in N. A special time point,\ncalled calendar zero grounds the network and has the value\n0. Constraints on activities (e.g. release time, due time,\nduration) and relationships between activities (e.g. \nparentchild relation, enables) are uniformly represented as \ntemporal constraints (i.e., edges) between relevant start and finish\ntime points. An agent\"s schedule is designated as a total\nordering of selected methods by posting precedence \nconstraints between the end and start points of each ordered\npair. As new methods are inserted into a schedule or \nexternal state updates require adjustments to existing constraints\n(e.g., substitution of an actual duration constraint, \ntightening of a deadline), the network propagates constraints and\nmaintains lower and upper bounds on all time points in the\nnetwork. This is accomplished efficiently via the use of a\nstandard all-pairs shortest path algorithm; in our \nimplementation, we take advantage of an incremental procedure based\non [2]. As bounds are updated, a consistency check is made\nfor the presence of negative cycles, and the absence of any\nsuch cycle ensures the continued temporal feasibility of the\nnetwork (and hence the schedule). Otherwise a conflict has\nbeen detected, and some amount of constraint retraction is\nnecessary to restore feasibility.\n4.2 Maintaining High-Quality Schedules\nThe scheduler consists of two basic components: a quality\npropagator and an activity allocator that work in a tightly \nintegrated loop. The quality propagator analyzes the activity\nhierarchy and collects a set of methods that (if scheduled)\nwould maximize the quality of the agent\"s local problem.\nThe methods are collected without regard for resource \ncontention; in essence, the quality propagator optimally solves\na relaxed problem where agents are capable of performing\nan infinite number of activities at once. The allocator \nselects methods from this list and attempts to install them in\nthe agent\"s schedule. Failure to do so reinvokes the quality\npropagator with the problematic activity excluded.\nThe Quality Propagator - The quality propagator \nperforms the following actions on the C TAEMS task structure:\n\u00e2\u20ac\u00a2 Computes the quality of all activities in the task \nstructure: The expected quality qual(m) of a method m is\ncomputed from the probability distribution of the \nexecution outcomes. The quality qual(t) of a task t is\ncomputed by applying its qaf to the assessed quality\nof its children.\n\u00e2\u20ac\u00a2 Generates a list of contributors for each task: methods\nthat, if scheduled, will maximize the quality obtained\nby the task.\n\u00e2\u20ac\u00a2 Generates a list of activators for each task: methods\nthat, if scheduled, are sufficient to qualify the task as\nscheduled. Methods in the activators list are chosen\nto minimize demands on the agent\"s timeline without\nregard to quality.\nThe first time the quality propagator is invoked, the \nqualities of all tasks and methods are calculated and the initial\nlists of contributors and activators are determined. \nSubsequent calls to the propagator occur as the allocator installs\nmethods on the agent\"s timeline: failure of the allocator to\ninstall a method causes the propagator to recompute a new\nlist of contributors and activators.\nThe Activity Allocator - The activity allocator seeks\nto install the contributors of the taskgroup identified by\nthe quality propagator onto the agent\"s timeline. Any \ncurrently scheduled methods that do not appear in the \ncontributors list are first unscheduled and removed from the\ntimeline. The contributors are then preprocessed using a\nquality-centric heuristic to create an agenda sorted in \ndecreasing quality order. In addition, methods associated with\na and task (i.e., min, sumand) are grouped consecutively\nwithin the agenda. Since an and task accumulates quality\nonly if all its children are scheduled, this biases the \nscheduling process towards failing early (and regenerating \ncontributors) when the methods chosen for the and cannot \ntogether be allocated.\nThe allocator iteratively pops the first method mnew from\nthe agenda and attempts to install it. This entails first\nchecking that all activities that enable mnew have been \nscheduled, while attempting to install any enabler that is not. If\nany of the enabler activities fails to install, the allocation\npass fails. When successful, the enables constraints linking\nthe enabler activities to mnew are activated. The STN \nrejects an infeasible enabler constraint by returning a conflict.\nIn this event any enabler activities it has scheduled are \nuninstalled and the allocator returns failure. Once scheduling\nof enablers is ensured, a feasible slot on the agent\"s \ntimeline within mnew\"s time window is sought and the allocator\nattempts to insert mnew between two currently scheduled\nmethods. At the STN level, mnew\"s insertion breaks the \nsequencing constraint between the two extant timeline \nmethods and attempts to insert two new sequencing constraints\nthat chain mnew to these methods. If these insertions \nsucceed, the routine returns success, otherwise the two extant\ntimeline methods are relinked and allocation attempts the\nnext possible slot for mnew insertion.\n5. THE DYNAMICS OF EXECUTION\nMaintaining a flexible-times schedule enables us to use\na conflict-driven approach to schedule repair: Rather than\nreacting to every event in the execution that may impact\nthe existing schedule by computing an updated solution, the\nSTN can absorb any change that does not cause a conflict.\nConsequently, computation (producing a new schedule) and\ncommunication costs (informing other agents of changes that\naffect them) are minimized.\nOne basic mechanism needed to model execution in the\nSTN is a dynamic model for current time. We employ a\nmodel proposed by [7] that establishes a \u00e2\u20ac\u02dccurrent-time\" time\npoint and includes a link between it and the calendar-zero\ntime point. As each method is scheduled, a simple \nprecedence constraint between the current-time time point and\nthe method is established. When the scheduler receives a\ncurrent time update, the link between calendar-zero and\ncurrent-time is modified to reflect this new time, and the\nconstraint propagates to all scheduled methods.\nA second issue concerns synchronization between the \nexecutor and the scheduler, as producer and consumer of the\nschedule running on different threads within a given agent.\nThis coordination must be robust despite the fact that the\nThe Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 487\nexecutor needs to start methods for execution in real-time\neven while the scheduler may be reassessing the schedule to\nmaximize quality, and/or transmitting a revised schedule.\nIf the executor, for example, slates a method for execution\nbased on current time while the scheduler is instantiating\na revised schedule in which that method is no longer \nnextto-be-executed, an inconsistent state may arise within the\nagent architecture. This is addressed in part by \nintroducing a freeze window; a specified short (and adjustable)\ntime period beyond current time within which any activity\nslated as eligible to start in the current schedule cannot be\nrescheduled by the scheduler.\nThe scheduler is triggered in response to various \nenvironmental messages. There are two types of environmental\nmessage classes that we discuss here as execution \ndynamics: 1) feedback as a result of method execution - both\nthe agent\"s own and that of other agents, and 2) changes in\nthe C TAEMS model corresponding to a set of \nsimulatordirected evolutions of the problem and environment. Such\nmessages are termed updates and are treated by the \nscheduler as directives to permanently modify parameters in its\nmodel. We discuss these update types in turn here and \ndefer until later the discussion of queries to the scheduler, a\n\"what-if\" mode initiated by a remote agent that is pursuing\nhigher global quality.\nWhether it is invoked via an update or a query, the \nscheduler\"s response is an option; essentially a complete \nschedule of activities the agent can execute along with associated\nquality metrics. We define a local option as a valid schedule\nfor an agent\"s activities, which does not require change to\nany other agent\"s schedule. The overarching design for \nhandling execution dynamics aims at anytime scheduling \nbehavior in which a local option maximizing the local view\nof quality is returned quickly, possibly followed by globally\nhigher quality schedules that entail inter-agent coordination\nif available scheduler cycles permit. As such, the default\nscheduling mode for updates is to seek the highest quality\nlocal option according to the scheduler\"s search strategy, \ninstantiate the option as its current schedule, and notify the\nexecutor of the revision.\n5.1 Responding to Activity Execution\nAs suggested earlier, a committed schedule consists of a\nsequence of methods, each with a designated [est, lst] start\ntime window (as provided by the underlying STN \nrepresentation). The executor is free to execute a method any time\nwithin its start time window, once any additional enabling\nconditions have been confirmed. These scheduled start time\nwindows are established using the expected duration of each\nscheduled method (derived from associated method duration\ndistributions during schedule construction). Of course as \nexecution unfolds, actual method durations may deviate from\nthese expectations. In these cases, the flexibility retained\nin the schedule can be used to absorb some of this \nunpredictability and modulate invocation of a schedule revision\nprocess.\nConsider the case of a method completion message, one\nof the environmental messages that could be communicated\nto the scheduler as an execution state update. If the \ncompletion time is coincident with the expected duration (i.e.,\nit completes exactly as expected), then the scheduler\"s \nresponse is to simply mark it as \u00e2\u20ac\u02dccompleted\" and the agent can\nproceed to communicate the time at which it has \naccumulated quality to any remote agents linked to this method.\nHowever if the method completes with a duration shorter\nthan expected a rescheduling action might be warranted.\nThe posting of the actual duration in the STN introduces\nno potential for conflict in this case, either with the latest\nstart times (lsts) of local or remote methods that depend\non this method as an enabler, or to successively scheduled\nmethods on the agent\"s timeline. However, it may present a\npossibility for exploiting the unanticipated scheduling slack.\nThe flexible times representation afforded by the STN \nprovides a quick means of assessing whether the next method on\nthe timeline can begin immediate execution instead of \nwaiting for its previously established earliest start time (est).\nIf indeed the est of the next scheduled method can spring\nback to current-time once the actual duration constraint is\nsubstituted for the expected duration constraint, then the\nschedule can be left intact and simply communicated back\nto the executor. If alternatively, other problem constraints\nprevent this relaxation of the est, then there is forced idle\ntime that may be exploited by revising the schedule, and the\nscheduler is invoked (always respecting the freeze period).\nIf the method completes later than expected, then there\nis no need for rescheduling under flexible times scheduling\nunless 1) the method finishes later than the lst of the \nsubsequent scheduled activity, or 2) it finishes later than its\ndeadline. Thus we only invoke the scheduler if, upon \nposting the late finish in the STN, a constraint violation occurs.\nIn the latter case no quality is accrued and rescheduling\nis mandated even if there are no conflicts with subsequent\nscheduled activities.\nOther execution status updates the agent may receive \ninclude:\n\u00e2\u20ac\u00a2 method start - If a method sent for execution is started\nwithin its [est, lst] window, the response is to mark it\nas \"executing\". A method cannot start earlier than\nwhen it is transmitted by the executor but it is \npossible for it to start later than requested. If the posted\nstart time causes an inconsistency in the STN (e.g. \nbecause the expected method duration can no longer be\naccommodated) the duration constraint in the STN is\nshortened based on the known distribution until either\nconsistency is restored or rescheduling is mandated.\n\u00e2\u20ac\u00a2 method failure - Any method under execution may fail\nunexpectedly, garnering no quality for the agent. At\nthis point rescheduling is mandated as the method may\nenable other activities or significantly impact quality\nin the absence of local repair. Again, the executor will\nproceed with execution of the next method if its start\ntime arrives before the revised schedule is committed,\nand the scheduler accommodates this by respecting the\nfreeze window.\n\u00e2\u20ac\u00a2 current time advances An update on \"current time\"\nmay arrive either alone or as part of any of the \npreviously discussed updates. If, when updating the \ncurrenttime link in the STN (as described above), a conflict\nresults, the execution state is inconsistent with the\nschedule. In this case, the scheduler proceeds as if \nexecution were consistent with its expectations, subject\nto possible later updates.\n488 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)\n5.2 Responding to Model Updates\nThe agent can also dynamically receive changes to the\nagent\"s underlying C TAEMS model. Dynamic revisions in\nthe outcome distributions for methods already in an agent\"s\nsubjective view may impact the assessed quality and/or \nduration values that shaped the current schedule. Similarly,\ndynamic revisions in the designated release times and \ndeadlines for methods and tasks already in an agent\"s subjective\nview can invalidate an extant schedule or present \nopportunities to boost quality. It is also possible during execution\nto receive updates in which new methods and possibly \nentire task structures are given to the agent for inclusion in\nits subjective view. Model changes that involve temporal\nconstraints are handled in much the same fashion as \ndescribed for method starts and completions, i.e, rescheduling\nis required only when the posting of the revised constraints\nleads to an STN conflict. In the case of non-temporal model\nchanges, rescheduling action is currently always initiated.\n6. INTER-AGENT COORDINATION\nHaving responded locally to an unexpected execution \nresult or model change, it is necessary to communicate the\nconsequences to agents with inter-dependent activities so\nthat they can align their decisions accordingly. Responses\nthat look good locally may have a sub-optimal global effect\nonce alignments are made, and hence agents must have the\nability to seek mutually beneficial joint schedule changes.\nIn this section we summarize the coordination mechanisms\nprovided in the agent architecture to address these issues.\n6.1 Communicating Non-Local Constraints\nA basic means of coordination with other agents is \nprovided by the Distributed State Mechanism (DSM), which is\nresponsible for communicating changes made to the model\nor schedule of a given agent to other interested agents.\nMore specifically, the DSM of a given agent acts to push\nany changes made to the time bounds, quality, or status\nof a local task/method to all the other agents that have\nthat same task/method as a remote node in their subjective\nviews. A recipient agent treats any communicated changes\nas additional forms of updates, in this case an update that\nmodifies the current constraints associated with non-local\n(but inter-dependent) tasks or methods. These changes are\nhandled identically to updates reflecting schedule execution\nresults, potentially triggering the local scheduler if the need\nto reschedule is detected.\n6.2 Generating Non-Local Options\nAs mentioned in the previous section, the agent\"s first \nresponse to any given query or update (either from execution\nor from another agent) is to generate one or more local \noptions. Such options represent local schedule changes that are\nconsistent with all currently known constraints originating\nfrom other agents\" schedules, and hence can be implemented\nwithout interaction with other agents. In many cases, \nhowever, a larger-scoped change to the schedules of two or more\nagents can produce a higher-quality response.\nExploration of opportunities for such coordinated action\nby two or more agents is the responsibility of the Options\nManager. Running in lower priority mode than the \nExecutor and Scheduler, the Options Manager initiates a non-local\noption generation and evaluation process in response to any\nlocal schedule change made by the agent if computation time\nconstraints permits. Generally speaking, a non-local option\nidentifies certain relaxations (to one or more constraints \nimposed by methods that are scheduled by one or more remote\nagents) that enable the generation of a higher quality local\nschedule. When found, a non-local option is used by a \ncoordinating agent to formulate queries to any other involved\nagents in order to determine the impact of such constraint\nrelaxations on their local schedules. If the combined \nquality change reported back from a set of one or more relevant\nqueries is a net gain, then the issuing agent signals to the\nother involved agents to commit to this joint set of schedule\nchanges. The Option Manager currently employs two \nbasic search strategies for generating non-local options, each\nexploiting the local scheduler in hypothetical mode.\nOptimistic Synchronization - Optimistic \nsynchronization is a non-local option generation strategy where search\nis used to explore the impact on quality if optimistic \nassumptions are made about currently unscheduled remote\nenablers. More specifically, the strategy looks for would\nbe contributor methods that are currently unscheduled due\nto the fact that one or more remote enabling (source) tasks\nor methods are not currently scheduled. For each such local\nmethod, the set of remote enablers are hypothetically \nactivated, and the scheduler attempts to construct a new local\nschedule under these optimistic assumptions. If successful,\na non-local option is generated, specifying the value of the\nnew, higher quality local schedule, the temporal constraints\non the local target activity, and the set of must-schedule\nenabler activities that must be scheduled by remote agents\nin order to achieve this local quality. The needed queries\nrequesting the quality impact of scheduling these activities\nare then formulated and sent to the relevant remote agents.\nTo illustrate, consider again the example in Figure 1. The\nmaximum quality that Agent1 can contribute to the task\ngroup is 15 (by scheduling M1, M2 and M3). Assume\nthat this is Agent1\"s current schedule. Given this state, the\nmaximum quality that Agent2 can contribute to the task\ngroup is 10, and the total task group quality would then\nbe 15 + 10 = 25. Using optimistic synchronization, Agent2\nwill generate a non-local option that indicates that if M5\nbecomes enabled, both M5 and M6 would be scheduled,\nand the quality contributed by Agent2 to the task group\nwould become 30. Agent2 sends a must schedule M4 query\nto Agent1. Because of the time window constraints, Agent1\nmust remove M3 from its schedule to get M4 on, \nresulting in a new lower quality schedule of 5. However, when\nAgent2 receives this option response from Agent1, it \ndetermines that the total quality accumulated for the task group\nwould be 5 + 30 = 35, a net gain of 10. Hence, Agent 2\nsignals to Agent1 to commit to this non-local option.\nConflict-Driven Relaxation - A second strategy for\ngenerating non-local options, referred to as Conflict-Directed\nRelaxation, utilizes analysis of STN conflicts to identify and\nprioritize external constraints to relax in the event that a\nparticular method that would increase local quality is found\nto be unschedulable. Recall that if a method cannot be \nfeasibly inserted into the schedule, an attempt to do so will\ngenerate a negative cycle. Given this cycle, the mechanism\nproceeds in three steps. First, the constraints involved in\nthe cycle are collected. Second, by virtue of the connections\nin the STN to the domain-level C TAEMS model, this set is\nfiltered to identify the subset associated with remote nodes.\nThird, constraints in this subset are selectively retracted to\nThe Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 489\nFigure 4: A high quality task is added to the task\nstructure of Agent2.\nFigure 5: If M4, M5 and M7 are scheduled, a conflict\nis detected by the STN.\ndetermine if STN consistency is restored. If successful, a\nnon-local option is generated indicating which remote \nconstraint(s) must be relaxed and by how much to allow \ninstallation of the new, higher quality local schedule.\nTo illustrate this strategy, consider Figure 5 where Agent1\nhas M1, M2 and M4 on its timeline, and therefore est(M4) =\n21. Agent2 has M5 and M6 on its timeline, with est(M5) =\n31 (M6 could be scheduled before or after M5). Suppose\nthat Agent2 receives a new task M7 with deadline 55 (see\nFigure 4). If Agent2 could schedule M7, the quality \ncontributed by Agent2 to the task group would be 70. \nHowever, an attempt to schedule M7 together with M5 and M6\nleads to a conflict, since the est(M7) = 46, dur(M7) = 10\nand lft(M7) = 55 (see Figure 5). Conflict-directed \nrelaxation by Agent 2 suggests relaxing the lft(M4) by 1 tick\nto 30, and this query is communicated to Agent 1. In fact,\nby retracting either method M1 or M2 from the schedule\nthis relaxation can be accommodated with no quality loss\nto Agent1 (due to the min qaf). Upon communication of\nthis fact Agent 2 signals to commit.\n7. EXPERIMENTAL RESULTS\nAn initial version of the agent described in this paper\nwas developed in collaboration with SRI International and\nsubjected to the independently conducted Coordinators \nprogrammatic evaluation. This evaluation involved over 2000\nproblem instances randomly generated by a scenario \ngenerator that was configured to produce scenarios of varying\nProblem Class Description Agent\nClass Quality\nOD \u00e2\u20ac\u02dcOnly Dynamics\". No NLEs. 97.9%\n(390 probs) Actual task duration & quality\nvary according to distribution.\nINT \u00e2\u20ac\u02dcInterdependent\". Frequent & 100%\n(360 probs) random (esp. facilitates)\nCHAINS Activities chained together 99.5%\n(360 probs) via sequences of enables NLEs\n(1-4 chains/prob)\nTT \u00e2\u20ac\u02dcTemporal Tightness\". Release - 94.9%\n(360 probs) Deadline windows preclude\npreferred high quality (longest\nduration) tasks from all\nbeing scheduled.\nSYNC Problems contain range of 97.1%\n(360 probs) different Sync sum tasks\nNTA \u00e2\u20ac\u02dcNew Task Arrival\". cTaems 99.0%\n(360 probs) model is augmented with new\ntasks dynamically during run.\nOVERALL Avg: 98.1%\n(2190 probs) Std dev: 6.96\nTable 1: Performance of year 1 agent over \nCoordinators evaluation. \u00e2\u20ac\u02dcAgent Quality\" is % of \u00e2\u20ac\u02dcoptimal\"\ndurations within six experiment classes. These classes, \nsummarized in Table 1, were designed to evaluate key aspects of\na set of Coordinators distributed scheduling agents, such as\ntheir ability to handle unexpected execution results, chains\nof nle\"s involving multiple agents, and effective scheduling\nof new activities that arise unexpectedly at some point \nduring the problem run. Year 1 evaluation problems were \nconstrained to be small enough (3 -10 agents, 50 - 100 methods)\nsuch that comparison against an optimal centralized solver\nwas feasible. The evaluation team employed an MDP-based\nsolver capable of unrolling the entire search space for these\nproblems, choosing for an agent at each execution decision\npoint the activity most likely to produce maximum global\nquality. This established a challenging benchmark for the\ndistributed agent systems to compare against. The \nhardware configuration used by the evaluators instantiated and\nran one agent per machine, dedicating a separate machine\nto the MASS simulator.\nAs reported in Table 1, the year 1 prototype agent clearly\ncompares favorably to the benchmark on all classes, \ncoming within 2% of the MDP optimal averaged over the \nentire set of 2190 problems. These results are particularly\nnotable given that each agent\"s STN-based scheduler does\nvery little reasoning over the success probability of the \nactivity sequences it selects to execute. Only simple tactics\nwere adopted to explicitly address such uncertainty, such as\nthe use of expected durations and quality for activities and a\npolicy of excluding from consideration those activities with\nfailure likelihood of >75%. The very respectable agent \nperformance can be at least partially credited to the fact that\nthe flexible times representation employed by the scheduler\naffords it an important buffer against the uncertainty of \nexecution and exogenous events.\nThe agent turns in its lowest performance on the TT\n(Temporal Tightness) experiment classes, and an \nexamination of the agent trace logs reveals possible reasons. In about\nhalf of the TT problems the year 1 agent under-performs\non, the specified time windows within which an agent\"s \nac490 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)\ntivities must be scheduled are so tight that any scheduled\nactivity which executes with a longer duration than the \nexpected value, causes a deadline failure. This constitutes a\ncase where more sophisticated reasoning over success \nprobability would benefit this agent. The other half of \nunderperforming TT problems involve activities that depend on\nfacilitation relationships in order to fit in their time windows\n(recall that facilitation increases quality and decreases \nduration). The limited facilitates reasoning performed by the\nyear 1 scheduler sometimes causes failures to install a \nheavily facilitated initial schedule. Even when such activities\nare successfully installed they tend to be prone to deadline\nfailures -If a source-side activity(s) either fails or exceeds its\nexpected duration the resulting longer duration of the target\nactivity can violate its time window deadline.\n8. STATUS AND DIRECTIONS\nOur current research efforts are aimed at extending the \ncapabilities of the Year 1 agent and scaling up to significantly\nlarger problems. Year 2 programmatic evaluation goals call\nfor solving problems on the order of 100 agents and 10,000\nmethods. This scale places much higher computational \ndemands on all of the agent\"s components. We have recently\ncompleted a re-implementation of the prototype agent \ndesigned to address some recognized performance issues. In\naddition to verifying that the performance on Year 1 \nproblems is matched or exceeded, we have recently run some\nsuccessful tests with the agent on a few 100 agent problems.\nTo fully address various scale up issues, we are \ninvestigating a number of more advanced coordination mechanisms.\nTo provide more global perspective to local scheduling \ndecisions, we are introducing mechanisms for computing, \ncommunicating and using estimates of the non-local impact of\nremote nodes. To better address the problem of establishing\ninter-agent synchronization points, we expanding the use of\ntask owners and qaf-specifc protocols as a means for \ndirecting coordination activity. Finally, we plan to explore the use\nof more advanced STN-driven coordination mechanisms, \nincluding the use of temporal decoupling [7] to insulate the\nactions of inter-dependent agents and the introduction of\nprobability sensitive contingency schedules.\n9. ACKNOWLEDGEMENTS\nThe Year 1 agent architecture was developed in \ncollaboration with Andrew Agno, Roger Mailler and Regis \nVincent of SRI International. This paper is based on work\nsupported by the Department of Defense Advance Research\nProjects Agency (DARPA) under Contract # \nFA8750-05-C0033. Any opinions findings and conclusions or \nrecommendations expressed in this paper are those of the authors and\ndo not necessarily reflect the views of DARPA.\n10. REFERENCES\n[1] M. Boddy, B. Horling, J. Phelps, R. Goldman,\nR. Vincent, A. Long, and B. Kohout. C taems\nlanguage specification v. 1.06, October 2005.\n[2] A. Cesta and A. Oddi. Gaining efficiency and\nflexibility in the simple temporal problem. In Proc.\n3rd Int. Workshop on Temporal Representation and\nReasoning, Key West FL, May 1996.\n[3] R. Dechter, I. Meiri, and J. Pearl. Temporal constraint\nnetworks. Artificial Intelligence, 49:61-95, May 1991.\n[4] K. Decker. T\u00c3\u2020MS: A framework for environment\ncentered analysis & design of coordination\nmechanisms. In G. O\"Hare and N. Jennings, editors,\nFoundations of Distributed Artificial Intelligence,\nchapter 16, pages 429-448. Wiley Inter-Science, 1996.\n[5] K. Decker and V. Lesser. Designing a family of\ncoordination algorithms. In Proc. 1st. Int. Conference\non Multi-Agent Systems, San Francisco, 1995.\n[6] A. J. Garvey. Design-To-Time Real-Time Scheduling.\nPhD thesis, Univ. of Massachusetts, Feb. 1996.\n[7] L. Hunsberger. Algorithms for a temporal decoupling\nproblem in multi-agent planning. In Proc. 18th\nNational Conference on AI, 2002.\n[8] S. Lemai and F. Ingrand. Interleaving temporal\nplanning and execution in robotics domains. In Proc.\n19th National Conference on AI, 2004.\n[9] N. Muscettola, P. P. Nayak, B. Pell, and B. C.\nWilliams. Remote agent: To boldly go where no AI\nsystem has gone before. Artificial Intelligence,\n103(1-2):5-47, 1998.\n[10] W. Ruml, M. B. Do, and M. Fromherz. On-line\nplanning and scheduling of high-speed manufacturing.\nIn Proc. ICAPS-05, Monterey, 2005.\n[11] I. Shu, R. Effinger, and B. Williams. Enabling fast\nflexible planning through incremental temporal\nreasoning with conflict extraction. In Proce.\nICAPS-05, Monterey, 2005.\n[12] S. Smith and C. Cheng. Slack-based heuristics for\nconstraint satisfaction scheduling. In Proc. 12th\nNational Conference on AI, Wash DC, July 1993.\n[13] T. Wagner, A. Garvey, and V. Lesser. Criteria-directed\nheuristic task scheduling. International Journal of\nApproximate Reasoning, 19(1):91-118, 1998.\nThe Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 491\n": ["managing schedule", "distributed environment", "agent architecture", "schedule", "inter-dependent activity", "geographical separation", "flexible time", "centralized planning", "management", "scheduler-execution", "slack", "shortest path algorithm", "activity allocator", "conflict-driven approach", "optimistic synchronization", "inter-agent coordination", "performance", "multi-agent schedule", ""]}