{"Design and Implementation of a\nDistributed Content Management System\nC. D. Cranor, R. Ethington, A. Sehgal\u00e2\u20ac\u00a0\n, D. Shur, C. Sreenan\u00e2\u20ac\u00a1\nand J.E. van der Merwe\nAT&T Labs - Research \u00e2\u20ac\u00a0\nUniversity of Kentucky \u00e2\u20ac\u00a1\nUniversity College Cork\nFlorham Park, NJ, USA Lexington, KY, USA Cork, Ireland\nABSTRACT\nThe convergence of advances in storage, encoding, and networking\ntechnologies has brought us to an environment where huge amounts\nof continuous media content is routinely stored and exchanged \nbetween network enabled devices. Keeping track of (or managing)\nsuch content remains challenging due to the sheer volume of data.\nStoring live continuous media (such as TV or radio content) adds\nto the complexity in that this content has no well defined start or\nend and is therefore cumbersome to deal with. Networked storage\nallows content that is logically viewed as part of the same collection\nto in fact be distributed across a network, making the task of \ncontent management all but impossible to deal with without a content\nmanagement system. In this paper we present the design and \nimplementation of the Spectrum content management system, which\ndeals with rich media content effectively in this environment.\nSpectrum has a modular architecture that allows its application\nto both stand-alone and various networked scenarios. A unique \naspect of Spectrum is that it requires one (or more) retention policies\nto apply to every piece of content that is stored in the system. This\nmeans that there are no eviction policies. Content that no longer\nhas a retention policy applied to it is simply removed from the \nsystem. Different retention policies can easily be applied to the same\ncontent thus naturally facilitating sharing without duplication. This\napproach also allows Spectrum to easily apply time based policies\nwhich are basic building blocks required to deal with the storage of\nlive continuous media, to content. We not only describe the details\nof the Spectrum architecture but also give typical use cases.\nCategories and Subject Descriptors\nC.2.4 [Computer Systems Organization]: \nComputer-communication Networks-distributed systems; H.3.4 [Information \nSystems]: Information Storage and Retrieval-systems and software\nGeneral Terms\nDesign, Management\n1. INTRODUCTION\nManipulating and managing content is and has always been one\nof the primary functions of a computer. Initial computing \napplications include text formatters and program compilers. Content was\ninitially managed by explicit user interaction through the use of\nfiles and filesystems. As technology has advanced, both the types\nof content and the way people wish to use it have greatly changed.\nNew content types such as continuous multimedia streams have \nbecome commonplace due to the convergence of advances in storage,\nencoding, and networking technologies. For example, by \ncombining improvements in storage and encoding, it is now possible to\nstore many hours of TV-quality encoded video on a single disk\ndrive. This has led to the introduction of stand alone digital video\nrecording or personal video recording (PVR) systems such as \nTiVO [8] and ReplayTV [7]. Another example is the combination of\nencoding and broadband networking technology. This combination\nhas allowed users to access and share multimedia content in both\nlocal and remote area networks with the network itself acting as a\nhuge data repository.\nThe proliferation of high quality content enabled by these \nadvances in storage, encoding, and networking technology creates the\nneed for new ways to manipulate and manage the data. The focus\nof our work is on the storage of media rich content and in \nparticular the storage of continuous media content in either pre-packaged\nor live forms. The need for content management in this area is\napparent when one consider the following:\n\u00e2\u20ac\u00a2 Increases in the capacity and decreases in the cost of storage\nmeans that even modest desktop systems today have the \nability to store massive amounts of content. Managing such \ncontent manually (or more correctly manual non-management\nof such content) lead to great inefficiencies where unwanted\nand forgotten content waste storage and where wanted \ncontent cannot be found.\n\u00e2\u20ac\u00a2 While true for all types of content the storage of \ncontinuous media content is especially problematic. First \ncontinuous media content is still very demanding in terms of storage\nresources which means that a policy-less approach to \nstoring it will not work for all but the smallest systems. \nSecond, the storing of live content such as TV or radio is \ninherently problematic as these signals are continuous streams\nwith no endpoints. This means that before one can even think\nabout managing such content there is a need to abstract it into\nsomething that could be manipulated and managed.\n4\n\u00e2\u20ac\u00a2 When dealing with stored continuous media there is a need\nto manage such content at both a fine-grained as well as an\naggregate level. For example, an individual PVR user \nwanting to keep only the highlights of a particular sporting event\nshould not be required to have to store the content pertaining\nto the complete event. At the same time the user might want\nto think of content in the aggregate, e.g. remove all of the\ncontent that I have not watched for the last month except that\ncontent which was explicitly marked for archival.\n\u00e2\u20ac\u00a2 As indicated above, trying to keep track of content on a \nstandalone system without a content management system is very\ndifficult. However, when the actual storage devices are \ndistributed across a network the task of keeping track of content\nis almost impossible. This scenario is increasingly common\nin network based content distribution systems and is likely to\nalso become important in home-networking scenarios.\nIt would seem clear then that a content management system that\ncan efficiently handle media rich content while also exploiting the\nnetworked capability of storage devices is needed. This system\nshould allow efficient storage of and access to content across \nheterogeneous network storage devices according to user preferences.\nThe content management system should translate user preferences\ninto appropriate low-level storage policies and should allow those\npreferences to be expressed at a fine level of granularity (while not\nrequiring it in general). The content management system should \nallow the user to manipulate and reason about (i.e. change the storage\npolicy associated with) the storage of (parts of) continuous media\ncontent.\nAddressing this distributed content management problem is \ndifficult due to the number of requirements placed on the system. For\nexample:\n\u00e2\u20ac\u00a2 The content management system must operate on a large\nnumber of heterogeneous systems. In some cases the system\nmay be managing content stored on a local filesystem, while\nin others the content may be stored on a separate network\nstorage appliance. The content manager may be responsible\nfor implementing the policies it uses to reference content or\nthat role may be delegated to a separate computer. A \napplication program interface (API) and associated network \nprotocols are needed in order for the content management system\nto provide a uniform interface.\n\u00e2\u20ac\u00a2 The content management system should be flexible and be\nable to handle differing requirements for content \nmanagement policies. These policies reflect what content should be\nobtained, when it should be fetched, how long it should be \nretained, and under what circumstances it should be discarded.\nThis means that the content management system should \nallow multiple applications to reference content with a rich set\nof policies and that it should all work together seamlessly.\n\u00e2\u20ac\u00a2 The content management system needs to be able to \nmonitor references for content and use that information to place\ncontent in the right location in the network for efficient \napplication access.\n\u00e2\u20ac\u00a2 The content management system must handle the interaction\nbetween implicit and explicit population of content at the \nnetwork edge.\n\u00e2\u20ac\u00a2 The content system must be able to efficiently manage large\nsets of content, including continuous streams. It needs to be\nable to package this content in such a way that it is convenient\nfor users to access.\nTo address these issues we have designed and implemented the\nSpectrum content management system architecture. Our layered \narchitecture is flexible - its API allows the layers to reside either on\na single computer or on multiple networked heterogeneous \ncomputers. It allows multiple applications to reference content using\ndiffering policies. Note that the Spectrum architecture assumes the\nexistence of a content distribution network (CDN) that can \nfacilitate the efficient distribution of content (for example, the PRISM\nCDN architecture [2]).\nThe rest of this paper is organized as follows. Section 2 describes\nthe architecture of our content management system. In Section 3\nwe describe both our implementation of the Spectrum architecture\nand examples of its use. Related work is described in Section 4,\nand Section 5 contains our conclusion and suggestions for future\nwork.\n2. THE SPECTRUM DISTRIBUTED \nCONTENT MANAGEMENT SYSTEM \nARCHITECTURE\nThe Spectrum architecture consists of three distinct management\nlayers that may or may not be distributed across multiple machines,\nas shown in Figure 1. The three layers are:\ncontent manager: contains application specific information that\nis used to manage all of an application\"s content according to\nuser preferences. For example, in a personal video recorder\n(PVR) application the content manager receives requests for\ncontent from a user interface and interacts with the lower \nlayers of the Spectrum architecture to store and manage content\non the device.\npolicy manager: implements and enforces various storage polices\nthat the content manager uses to refer to content. The policy\nmanager exports an interface to the content manager that \nallows the content manager to request that a piece content be\ntreated according to a specific policy. Spectrum allows for\narbitrary policies to be realized by providing a fixed set of\nbase-policy templates that can easily be parameterized. It is\nour belief that for most implementations this will be adequate\n(if not, Spectrum can easily be extended to dynamically load\nnew base-policy template code at run time). A key aspect\nof the policy manager is that it allows different policies to\nbe simultaneously applied to the same content (or parts of\nthe same content). Furthermore content can only exist in the\nsystem so long as it is referenced by at least one existing\npolicy. Policy conflicts are eliminated by having the policy\nmanager deal exclusively with retention policies rather than\nwith a mix of retention and eviction policies. This means that\ncontent with no policy associated with it is immediately and\nautomatically removed from the system. This approach \nallows us to naturally support sharing of content across \ndifferent policies which is critical to the efficient storage of large\nobjects.\nNote that a key difference between the content manager and\nthe policy manager is that the content manager manages \nreferences to multiple pieces of content, i.e. it has an \napplicationview of content. On the other hand, the policy manager\nis only concerned with the policy used to manage \nstandalone pieces of content. For example, in a PVR \napplication, the content manager layer would know about the \ndifferent groups of managed content such as keep-indefinitely,\nkeep for one day, and keep if available diskspace. \nHowever, at the policy manager level, each piece of content has\n5\nContent Manager\nPolicy Manager\nStorage Manager\nContent Manager Content Manager Content Manager\nPolicy Manager Policy Manager\nPolicy Manager\nStorage Manager\nStorage Manager\nStorage Manager\nRemote Invocation\nFigure 1: The components of the Spectrum architecture and the four ways they can be configured\nits own policy (or policies) applied to it and is independent\nfrom other content.\nstorage manager: stores content in an efficient manner while \nfacilitating the objectives of the higher layers. Specifically the\nstorage manager stores content in sub-object chunks. This\napproach has advantages for the efficient retrieval of content\nbut more importantly allows policies to be applied at a \nsubobject level which is critically important when dealing with\nvery large objects such as parts of continuous media, e.g. \nselected pieces of TV content being stored on a PVR. Note that\nthe storage manager has no knowledge of the policies being\nused by the content and policy managers.\nAnother unique part of our approach is that the interfaces \nbetween the layers can either be local or distributed. Figure 1 shows\nthe four possible cases. The case on the far left of the Figure shows\nthe simplest (non-distributed) case where all the layers are \nimplemented on a single box. This configuration would be used in \nselfcontained applications such as PVRs.\nThe next case over corresponds to the case where there is a \ncentralized content manager that controls distributed storage devices\neach of which is responsible for implementing policy based \nstorage. In this case although the remote devices are controlled by the\ncentral manager they operate much more independently. For \nexample, once they receive instructions from the central manager they\ntypically operate in autonomous fashion. An example of this type\nof configuration is a content distribution network (CDN) that \ndistributes and stores content based on a schedule determined by some\ncentralized controller. For example, the CDN could pre-populate\nedge devices with content that is expected to be very popular or\ndistribute large files to branch offices during off-peak hours in a\nbandwidth constrained enterprise environment.\nAllowing a single policy manager to control several storage \nmanagers leads to the next combination of functions and the most \ndistributed case. The need for this sort of separation might occur for\nscalability reasons or when different specialized storage devices or\nappliances are required to be controlled by a single policy manager.\nThe final case shows a content manager combined with a \npolicy manager controlling a remote storage manager. This separation\nwould be possible if the storage manager is somewhat autonomous\nand does not require continuous fine grained control by the policy\nmanager.\nWe now examine the function of the three layers in detail.\n2.1 Content Manager\nThe content manager layer is the primary interface through which\nspecific applications use the Spectrum architecture. As such the\ncontent manager layer provides an API for the application to \nmanipulate all aspects of the Spectrum architecture at different levels\nof granularity. The content manager API has functions that handle:\nPhysical devices: This set of functions allows physical storage \ndevices to be added to Spectrum thereby putting them under\ncontrol of the content manager and making the storage \navailable to the system. Physical devices can be local or remote\n- this is the only place in the architecture where the \napplication is required to be aware of this distinction. Once a\ndevice is mapped into the application through this interface,\nthe system tracks its type and location. Users simply refer to\nthe content through an application-provided label.\nStores: Stores are subsets of physical storage devices. Through\nthese functions an application can create a store on a physical\ndevice and assign resources (e.g. disk space) to it. Stores can\nonly be created in physical devices that are mapped into the\nsystem.\nPolicy Groups: Policy groups are the means whereby an \napplication specifies, instantiates, and modifies the policies that are\napplied to Spectrum content. Typical usage of this set of\nfunctions is to select one of a small set of base policies and\nto parameterize this specific instance of the policy. Policy\ngroups are created within existing stores in the system. The\nSpectrum architecture has policies that are normally \nassociated with storage that aim to optimize disk usage. In addition\na set of policies that take a sophisticated time specification\nenable storage that is cognizant of time. For example, a \nsimple time-based policy could evict content from the system\nat a certain absolute or relative time. A slightly more \ninvolved time-based policy enabled by the Spectrum \narchitecture could allow content to be stored in rolling window of\na number of hours (for example, the most recent N-number\nof hours is kept in the system). Time-based polices are of\nparticular use when dealing with continuous content like a\nlive broadcast.\n6\nContent: At the finest level of granularity content can be added\nto or removed from the system. Content is specified to the\nsystem by means of a uniform resource locator (URL) which\nconcisely indicates the location of the content as well as the\nprotocol to be used to retrieve it. Optionally a time \nspecification can be associated with content. This allows content to\nbe fetched into the system at some future time, or at future\ntime intervals. Again, this is particularly useful for dealing\nwith the storage and management of live content.\n2.2 Policy Manager\nThe policy manager layer of the Spectrum architecture has two\nmain types of API functions. First, there are functions that operate\non managed storage areas and policy-based references (prefs) to\ncontent stored there. Second, there are sets of functions used to\nimplement each management policy. The first class of functions is\nused by the content manager layer to access storage. Operations\ninclude:\ncreate, open, and close: These operations are used by the content\nmanager to control its access to storage. The policy \nmanager\"s create operation is used to establish contact with a\nstore for the first time. Once this is done, the store can be\nopen and closed using the appropriate routines. Note that the\nparameters used to create a store contain information on how\nto reach it. For example, local stores have a path associated\nwith them, while remote stores have a remote host and \nremote path associated with them. The information only needs\nto be passed to the policy manager once at create time. For\nopen operations, the policy manager will use cached \ninformation to contact the store.\nlookup: The lookup operation provides a way for the content \nmanager to query the policy manager about what content is \ncurrently present for a given URL. For continuous media time\nranges of present media will be returned.\nresource: The resource routines are used to query the policy \nmanager about its current resource usage. There are two resource\nroutines: one that applies to the store as a whole and another\nthat applies to a particular policy reference. The resource\nAPI is extensible, we currently support queries on disk usage\nand I/O load.\npref establish/update: The pref establish operation is used by the\ncontent manager to reference content on the store. If the \ncontent is not present, this call will result in the content being\nfetched (or being scheduled to be fetched if the content is\nnot currently available). Parameters of this function include\nthe URL to store it under, the URL to fetch data from if it\nis not present, the policy to store the content under, and the\narguments used to parameterize the policy. The result of a\nsuccessful pref establish operation is a policy reference ID\nstring. This ID can be used with the update operation to \neither change the storage policy parameters or delete the \nreference entirely.\nThe second group of policy manager functions are used to \nimplement all the polices supported by Spectrum. We envision a small\nset of base-level policy functions that can be parameterized to \nproduce a wide range of storage polices. For example, a policy that\nimplements recording a repeating time window can be \nparameterized to function daily, weekly, or monthly. Note that the policy\nmanager is only concerned with executing a specific policy. The\nhigher-level reasons for choosing a given policy are handled by the\ncontent and application manager.\nA base policy is implemented using six functions:\nestablish: called when a pref is established with the required URLs\nand base policy\"s parameters. The establish routine \nreferences any content already present in the store and then \ndetermines the next time it needs to take action (e.g. start a\ndownload) and schedules a callback for that time. It can also\nregister to receive callbacks if new content is received for a\ngiven URL.\nupdate: called to change the parameters of a pref, or to discard the\npolicy reference.\nnewclip: called when a chunk of new content is received for a\nURL of interest. The base policy typically arranges for \nnewclip to be called for a given URL when the pref is established.\nWhen newclip is called, the base policy checks its \nparameters to determine if it wishes to add a reference to the clip\njust received.\ncallback: called when the pref schedules a timer-based callback.\nThis is a useful wakeup mechanism for prefs that need to be\nidle for a long period of time (e.g. between programs).\nboot/shutdown: called when the content management system is\nbooting or shutting down. The boot operation is typically\nused to schedule initial callbacks or start I/O operations. The\nshutdown operation is used to gracefully shutdown I/O streams\nand save state.\n2.3 Storage Manager\nThe role of Spectrum\"s storage manager is to control all I/O \noperations associated with a given store. Spectrum\"s storage manager\nsupports storing content both on a local filesystem and on a remote\nfileserver (e.g. a storage appliance). For continuous media, at the\nstorage manager level content is stored as a collection of time-based\nchunks. Depending on the underlying filesystem, a chunk could\ncorrespond to a single file or a data node in a storage database.\nThe two main storage manager operations are input and output.\nThe input routine is used to store content in a store under a given\nname. The output routine is used to send data from the store to a\nclient. For streaming media both the input and output routines take\ntime ranges that schedule when the I/O operation should happen,\nand both routines return an I/O handle that can be used to modify\nor cancel the I/O request in the future.\nMuch like the policy manager, the storage manager also provides\nAPI functions to create, open, and close stores. It also supports \noperations to query the resource usages and options supported by the\nstore. Finally, the storage manager also has a discard routine that\nmay be used by the policy manager to inform the store to remove\ncontent from the store.\n3. IMPLEMENTATION AND USE CASES\nIn this section we describe our implementation of Spectrum and\ndescribe how it can be used.\n3.1 Implementation\nWe have implemented Spectrum\"s three layers in C as part of a\nlibrary that can be linked with Spectrum-based applications. Each\nlayer keeps track of its state through a set of local data files that\npersist across reboots, thus allowing Spectrum to smoothly handle\npower cycles. For layers that reside on remote systems (e.g. a \nremote store) only the meta-information needed to contact the remote\n7\nContent Manager\nPolicy Manager\nStorage Manager\nStorage\nFetcher\nProgram\nListings\nGraphical User\nInterface\nNetwork Enabled DVR\nProgram Information\nContent\nDVR Application\nFigure 2: Spectrum in a Network Enabled DVR\nnode is stored locally. Our test application uses a local policy and\nstorage manager to fetch content and store it in a normal \nUnixbased filesystem.\nTo efficiently handle communications with layers running on \nremote systems, all Spectrum\"s API calls support both synchronous\nand asynchronous modes through a uniform interface defined by\nthe reqinfo structure. Each API call takes a pointer to a \nreqinfo structure as one of its arguments. This structure is used\nto hold the call state and return status. For async calls, the \nreqinfo also contains a pointer to a callback function. To use a\nSpectrum API function, the caller first chooses either the sync or\nasync mode and allocates a reqinfo structure. For sync calls, the\nreqinfo can be allocated on the stack, otherwise it is allocated\nwith malloc. For async calls, a callback function must be provided\nwhen the reqinfo is allocated. Next the caller invokes the \ndesired Spectrum API function passing the reqinfo structure as an\nargument. For sync calls, the result of the calls is returned \nimmediately in the reqinfo structure. For successful async calls, a call\nin progress value is returned. Later, when the async call completes\nor a timeout occurs, the async callback function is called with the\nappropriate information needed to complete processing.\nThe modular/layered design of the Spectrum architecture \nsimplifies the objective of distribution of functionality. Furthermore,\ncommunication between functions is typically of a master-slave(s)\nnature. This means that several approaches to distributed operation\nare possible that would satisfy the architectural requirements. In\nour implementation we have opted to realize this functionality with\na simple modular design. We provide a set of asynchronous remote\naccess stub routines that allow users to select the transport \nprotocol to use and to select the encoding method that should be used\nwith the data to be transferred. Transport protocols can range \nsimple protocols such as UDP up to more complex protocols such as\nHTTP. We currently are using plain TCP for most of our transport.\nFunction calls across the different Spectrum APIs can be \nencoded using a variety of formats include plain text, XDR, and XML.\nWe are currently using the eXpat XML library [4] to encode our\ncalls. While we are current transferring our XML encoded \nmessages using a simple TCP connection, in a real world setting this\ncan easily be replaced with an implementation based on secure\nsockets layer (SSL) to improve security by adding SSL as a \ntransport protocol.\nAn important aspect of Spectrum is that it can manage content\nbased on a given policy across heterogenous platforms. As we \nexplained previously in Section 2.2, envision a small set of base-level\npolicy functions that can be parameterized to produce a wide range\nof storage polices. In order for this to work properly, all \nSpectrumbased applications must understand the base-level policies and how\nthey can be parameterized. To address this issue, we treat each\nbase-level policy as if it was a separate program. Each base-level\npolicy should have a well known name and command line \noptions for parameterization. In fact, in our implementation we pass\nparameters to base-level policies as a string that can be parsed using\na getopt-like function. This format is easily understood and \nprovides portability since byte order is not an issue in a string. Since\nthis part of Spectrum is not on the critical data path, this type of\nformatting is not a performance issue.\n3.2 Using the Spectrum Content Management\nSystem\nIn this section we show two examples of the use of the Spectrum\nContent Management System in our environment. The focus of our\nprevious work has been content distribution for streaming media\ncontent [2] and network enabled digital video recording [3]. The\nSpectrum system is applicable to both scenarios as follows.\nFigure 2 shows the Network Enabled DVR (NED) architecture.\nIn this case all layers of the Spectrum architecture reside on the\nsame physical device in a local configuration. The DVR \napplication obtains program listings from some network source, deals with\nuser presentation through a graphical user interface (GUI), and \ninterface with the Spectrum system through the content management\nlayer APIs. This combination of higher level functions allows the\nuser to select both content to be stored and what storage policies to\n8\nContent Manager\nCentralized Content\nManagement station\nContent\nInformationUser Interface\nPolicy Manager\nStorage Manager\nStorage\nFetcher\nEdge Portal\nServer\nPolicy Manager\nStorage Manager\nStorage\nFetcher\nEdge Portal\nServer\nDistributed Content\nTo Media Endpoints\nTo Media Endpoints\nFigure 3: Spectrum in a Content Distribution Architecture\napply to such content. Obtaining the content (through the network\nor locally) and the subsequent storage on the local system is then\nhandled by the policy and storage managers.\nThe use of Spectrum in a streaming content distribution \narchitecture (e.g. PRISM [2]) is depicted in Figure 3. In this environment\nstreaming media content (both live, canned-live and on-demand) is\nbeing distributed to edge portals from where streaming endpoints\nare being served. In our environment content distribution and \nstorage is done from a centralized content management station which\ncontrols several of the edge portals. The centralized station allows\nadministrators to manage the distribution and storage of content\nwithout requiring continuous communication between the content\nmanager and the edge devices, i.e. once instructions have been\ngiven to edge devices they can operate independently until changes\nare to be made.\n3.3 Spectrum Operational Example\nTo illustrate how Spectrum handles references to content, \nconsider a Spectrum-based PVR application programmed to store one\ndays worth of streaming content in a rolling window. To set up the\nrolling window, the application would use the content manager API\nto create a policy group and policy reference to the desired content.\nThe establishment of the one-day rolling window policy reference\nwould cause the policy manger to ask the storage manager to start\nreceiving the stream. As each chunk of streaming data arrives, the\npolicy manager executes the policy reference\"s newclip function.\nThe newclip function adds a reference to each arriving chunk,\nand schedules a callback a day later. At that time, the policy will\ndrop its now day-old reference to the content and the content will\nbe discarded unless it is referenced by some other policy.\nNow, consider the case where the user decides to save part of the\ncontent (e.g. a specific program) in the rolling window for an extra\nweek. To do this, the application requests that the content manager\nadd an additional new policy reference to the part of the content\nto preserved. Thus, the preserved content has two references to it:\none from the rolling window and one from the request to preserve\nthe content for an additional week. After one day the reference\nfrom the rolling window will be discarded, but the content will be\n9\nref2, etc.\nbase\ndata\nurl1\nurl2 (media files...)\n(media files...)\nmeta\nstore (general info...)\nurl1 chunks\nprefs\nranges\nmedia\nchunks, etc.url2\npoly\nhost ref1\nref1.files\nref1.state\nFigure 4: Data layout of Spectrum policy store\npreserved by the second reference. After the additional week has\npast, the callback function for the second reference will be called.\nThis function will discard the remaining reference to the content\nand as there are no remaining references the content will be freed.\nIn order to function in scenarios like the ones described above,\nSpectrum\"s policy manager must manage and maintain all the \nreferences to various chunks of media. These references are persistent\nand thus must be able to survive even if the machine maintaining\nthem is rebooted. Our Spectrum policy manager implementation\naccomplishes this using the file and directory structure shown in\nFigure 4. There are three classes of data stored, and each class has\nits own top level directory. The directories are:\ndata: this directory is used by the storage manager to store each\nactive URL\"s chunks of media. The media files can be \nencoded in any format, for example MPEG, Windows Media,\nor QuickTime. Note that this directory is used only if the\nstorage manager is local. If the policy manager is using an\nexternal storage manager (e.g. a storage appliance), then the\nmedia files are stored remotely and are only remotely \nreferenced by the policy manager.\nmeta: this directory contains general meta information about the\nstorage manager being used and the data it is storing. \nGeneral information is stored in the store subdirectory and \nincludes the location of the store (local or remote) and \ninformation about the types of chunks of data the store can handle.\nThe meta directory also contains a subdirectory per-URL\nthat contains information about the chunks of data stored.\nThe chunks file contains a list of chunks currently stored\nand their reference counts. The prefs file contains a list of\nactive policy references that point to this URL. The ranges\nfile contains a list of time ranges of data currently stored. \nFinally, the media file describes the format of the media being\nstored under the current URL.\npoly: this directory contains a set of host subdirectories. Each\nhost subdirectory contains the set of policy references \ncreated by that host. Information on each policy reference is\nbroken up into three files. For example, a policy reference\nnamed ref1 would be stored in ref1, ref1.files, and\nref1.state. The ref1 file contains information about\nthe policy reference that does not change frequently. This \ninformation includes the base-policy and the parameters used\nto create the reference. The ref1.files file contains the\nlist of references to chunks that pref ref1 owns. Finally,\nthe ref1.state file contains optional policy-specific state\ninformation that can change over time.\nTogether, these files and directories are used to track references in\nour implementation of Spectrum. Note that other implementations\nare possible. For example, a carrier-grade Spectrum manager might\nstore all its policy and reference information in a high-performance\ndatabase system.\n10\n4. RELATED WORK\nSeveral authors have addressed the problem of the management\nof content in distributed networks. Much of the work focuses on\nthe policy management aspect. For example in [5], the problem\nof serving multimedia content via distributed servers is \nconsidered. Content is distributed among server resources in proportion\nto user demand using a Demand Dissemination Protocol. The \nperformance of the scheme is benchmarked via simulation. In [1]\ncontent is distributed among sub-caches. The authors construct a\nsystem employing various components, such as a Central Router,\nCache Knowledge base, Subcaches, and a Subcache eviction judge.\nThe Cache Knowledge base allows sophisticated policies to be \nemployed. Simulation is used to compare the proposed scheme with\nwell-known replacement algorithms. Our work differs in that we\nare considering more than the policy management aspects of the\nproblem. After carefully considering the required functionality to\nimplement content management in the networked environment, we\nhave partitioned the system into three simple functions, namely\nContent manager, Policy manager and Storage manager. This has\nallowed us to easily implement and experiment with a prototype\nsystem.\nOther related work involves so called TV recommendation \nsystems which are used in PVRs to automatically select content for\nusers, e.g. [6]. In the case where Spectrum is used in a PVR \nconfiguration this type of system would perform a higher level function\nand could clearly benefit from the functionalities of the Spectrum\narchitecture.\nFinally, in the commercial CDN environment vendors (e.g. Cisco\nand Netapp) have developed and implemented content management\nproducts and tools. Unlike the Spectrum architecture which allows\nedge devices to operate in a largely autonomous fashion, the \nvendor solutions typically are more tightly coupled to a centralized\ncontroller and do not have the sophisticated time-based operations\noffered by Spectrum.\n5. CONCLUSION AND FUTURE WORK\nIn this paper we presented the design and implementation of the\nSpectrum content management architecture. Spectrum allows \nstorage policies to be applied to large volumes of content to facilitate\nefficient storage. Specifically, the system allows different policies\nto be applied to the same content without replication. Spectrum can\nalso apply policies that are time-aware which effectively deals\nwith the storage of continuous media content. Finally, the \nmodular design of the Spectrum architecture allows both stand-alone\nand distributed realizations so that the system can be deployed in a\nvariety of applications.\nThere are a number of open issues that will require future work.\nSome of these issues include:\n\u00e2\u20ac\u00a2 We envision Spectrum being able to manage content on \nsystems ranging from large CDNs down to smaller appliances\nsuch as TiVO [8]. In order for these smaller systems to \nsupport Spectrum they will require networking and an external\nAPI. When that API becomes available, we will have to work\nout how it can be fit into the Spectrum architecture.\n\u00e2\u20ac\u00a2 Spectrum names content by URL, but we have intentionally\nnot defined the format of Spectrum URLs, how they map\nback to the content\"s actual name, or how the names and\nURLs should be presented to the user. While we previously\ntouched on these issues elsewhere [2], we believe there is\nmore work to be done and that consensus-based standards on\nnaming need to be written.\n\u00e2\u20ac\u00a2 In this paper we\"ve focused on content management for \ncontinuous media objects. We also believe the Spectrum \narchitecture can be applied to any type of document including\nplain files, but we have yet to work out the details necessary\nto support this in our prototype environment.\n\u00e2\u20ac\u00a2 Any project that helps allow multimedia content to be \neasily shared over the Internet will have legal hurdles to \novercome before it can achieve widespread acceptance. Adapting\nSpectrum to meet legal requirements will likely require more\ntechnical work.\n6. REFERENCES\n[1] K. . Cheng and Y. Kambayashi. Multicache-based Content\nManagement for Web Caching. Proceedings of the First\nInternational Conference on Web Information Systems\nEngineering, Jume 2000.\n[2] C. Cranor, M. Green, C. Kalmanek, D. Shur, S. Sibal,\nC. Sreenan, and J. van der Merwe. PRISM Architecture:\nSupporting Enhanced Streaming Services in a Content\nDistribution Network. IEEE Internet Computing, July/August\n2001.\n[3] C. Cranor, C. Kalmanek, D. Shur, S. Sibal, C. Sreenan, and\nJ. van der Merwe. NED: a Network-Enabled Digital Video\nRecorder. 11th IEEE Workshop on Local and Metropolitan\nArea Networks, March 2001.\n[4] eXpat. expat.sourceforge.net.\n[5] Z. Ge, P. Ji, and P. Shenoy. A Demand Adaptive and Locality\nAware (DALA) Streaming Media Server Cluster Architecture.\nNOSSDAV, May 2002.\n[6] K. Kurapati and S. Gutta and D. Schaffer and J. Martino and J.\nZimmerman. A multi-agent TV recommender. Proceedings of\nthe UM 2001 workshop, July 2001.\n[7] ReplayTV. www.sonicblue.com.\n[8] TiVo. www.tivo.com.\n11\n": ["spectrum content management system", "continuous media storage", "home-networking scenario", "application program interface", "content distribution network", "uniform resource locator", "policy manager", "network enabled dvr", "high-performance database system", "carrier-grade spectrum manager", "distribute content management", ""]}