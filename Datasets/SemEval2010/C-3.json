{"Self-Adaptive Applications on the Grid\nGosia Wrzesinska Jason Maassen Henri E. Bal\nDept. of Computer Systems, Vrije Universiteit Amsterdam\n{gosia, jason, bal}@cs.vu.nl\nAbstract\nGrids are inherently heterogeneous and dynamic. One important\nproblem in grid computing is resource selection, that is, finding\nan appropriate resource set for the application. Another problem\nis adaptation to the changing characteristics of the grid \nenvironment. Existing solutions to these two problems require that a \nperformance model for an application is known. However, \nconstructing such models is a complex task. In this paper, we investigate\nan approach that does not require performance models. We start an\napplication on any set of resources. During the application run, we\nperiodically collect the statistics about the application run and \ndeduce application requirements from these statistics. Then, we adjust\nthe resource set to better fit the application needs. This approach \nallows us to avoid performance bottlenecks, such as overloaded WAN\nlinks or very slow processors, and therefore can yield significant\nperformance improvements. We evaluate our approach in a number\nof scenarios typical for the Grid.\nCategories and Subject Descriptors C.2.4 [COMPUTER \nCOMMUNICATION NETWORKS]: Distributed Systems-Distributed\napplications\n; C.4 [PERFORMANCE OF SYSTEMS]: Measurement \ntechniques, Modelling techniques\nGeneral Terms Algorithms, Measurement, Performance, \nExperimentation\n1. Introduction\nIn recent years, grid computing has become a real alternative to \ntraditional parallel computing. A grid provides much computational\npower, and thus offers the possibility to solve very large problems,\nespecially if applications can run on multiple sites at the same time\n(7; 15; 20). However, the complexity of Grid environments also\nis many times larger than that of traditional parallel machines like\nclusters and supercomputers. One important problem is resource\nselection - selecting a set of compute nodes such that the \napplication achieves good performance. Even in traditional, \nhomogeneous parallel environments, finding the optimal number of nodes\nis a hard problem and is often solved in a trial-and-error fashion.\nIn a grid environment this problem is even more difficult, because\nof the heterogeneity of resources: the compute nodes have various\nspeeds and the quality of network connections between them varies\nfrom low-latency and high-bandwidth local-area networks (LANs)\nto high-latency and possibly low-bandwidth wide-area networks\n(WANs). Another important problem is that the performance and\navailability of grid resources varies over time: the network links or\ncompute nodes may become overloaded, or the compute nodes may\nbecome unavailable because of crashes or because they have been\nclaimed by a higher priority application. Also, new, better resources\nmay become available. To maintain a reasonable performance level,\nthe application therefore needs to adapt to the changing conditions.\nThe adaptation problem can be reduced to the resource selection\nproblem: the resource selection phase can be repeated during \napplication execution, either at regular intervals, or when a performance\nproblem is detected, or when new resources become available. This\napproach has been adopted by a number of systems (5; 14; 18). For\nresource selection, the application runtime is estimated for some\nresource sets and the set that yields the shortest runtime is selected\nfor execution. Predicting the application runtime on a given set of\nresources, however, requires knowledge about the application. \nTypically, an analytical performance model is used, but constructing\nsuch a model is inherently difficult and requires an expertise which\napplication programmers may not have.\nIn this paper, we introduce and evaluate an alternative approach\nto application adaptation and resource selection which does not\nneed a performance model. We start an application on any set of\nresources. During the application run, we periodically collect \ninformation about the communication times and idle times of the \nprocessors. We use these statistics to automatically estimate the resource\nrequirements of the application. Next, we adjust the resource set the\napplication is running on by adding or removing compute nodes\nor even entire clusters. Our adaptation strategy uses the work by\nEager et al. (10) to determine the efficiency and tries to keep the\nefficiency of the application between a lower and upper threshold\nderived from their theory. Processors are added or deleted to stay\nbetween the thresholds, thus adapting automatically to the \nchanging environment.\nA major advantage of our approach is that it improves \napplication performance in many different situations that are typical for\ngrid computing. It handles all of the following cases:\n\u00e2\u20ac\u00a2 automatically adapting the number of processors to the degree\nof parallelism in the application, even when this degree changes\ndynamically during the computation\n\u00e2\u20ac\u00a2 migrating (part of) a computation away from overloaded \nresources\n\u00e2\u20ac\u00a2 removing resources with poor communication links that slow\ndown the computation\n\u00e2\u20ac\u00a2 adding new resources to replace resources that have crashed\nOur work assumes the application is malleable and can run \n(efficiently) on multiple sites of a grid (i.e., using co-allocation (15)).\nIt should not use static load balancing or be very sensitive to \nwide121\narea latencies. We have applied our ideas to divide-and-conquer\napplications, which satisfy these requirements. Divide-and-conquer\nhas been shown to be an attractive paradigm for programming grid\napplications (4; 20). We believe that our approach can be extended\nto other classes of applications with the given assumptions.\nWe implemented our strategy in Satin, which is a Java-centric\nframework for writing grid-enabled divide-and-conquer \napplications (20). We evaluate the performance of our approach on the\nDAS-2 wide-area system and we will show that our approach yields\nmajor performance improvements (roughly 10-60 %) in the above\nscenarios.\nThe rest of this paper is structured as follows. In Section 2, we\nexplain what assumptions we are making about the applications and\ngrid resources. In Section 3, we present our resource selection and\nadaptation strategy. In Section 4, we describe its implementation in\nthe Satin framework. In Section 5, we evaluate our approach in a\nnumber of grid scenarios. In Section 6, we compare our approach\nwith the related work. Finally, in Section 7, we conclude and \ndescribe future work.\n2. Background and assumptions\nIn this section, we describe our assumptions about the applications\nand their resources. We assume the following resource model. The\napplications are running on multiple sites at the same time, where\nsites are clusters or supercomputers. We also assume that the \nprocessors of the sites are accessible using a grid scheduling system,\nsuch as Koala (15), Zorilla (9) or GRMS (3). Processors \nbelonging to one site are connected by a fast LAN with a low latency\nand high bandwidth. The different sites are connected by a WAN.\nCommunication between sites suffers from high latencies. We \nassume that the links connecting the sites with the Internet backbone\nmight become bottlenecks causing the inter-site communication to\nsuffer from low bandwidths.\nWe studied the adaptation problem in the context of \ndivide-andconquer applications. However, we believe that our methodology\ncan be used for other types of applications as well. In this section\nwe summarize the assumptions about applications that are \nimportant to our approach.\nThe first assumption we make is that the application is \nmalleable, i.e., it is able to handle processors joining and leaving\nthe on-going computation. In (23), we showed how \ndivide-andconquer applications can be made fault tolerant and malleable.\nProcessors can be added or removed at any point in the \ncomputation with little overhead. The second assumption is that the \napplication can efficiently run on processors with different speeds.\nThis can be achieved by using a dynamic load balancing \nstrategy, such as work stealing used by divide-and-conquer \napplications (19). Also, master-worker applications typically use dynamic\nload-balancing strategies (e.g., MW - a framework for writing \ngridenabled master-worker applications (12)). We find it a reasonable\nassumption for a grid application, since applications for which the\nslowest processor becomes a bottleneck will not be able to \nefficiently utilize grid resources. Finally, the application should be \ninsensitive to wide-area latencies, so it can run efficiently on a \nwidearea grid (16; 17).\n3. Self-adaptation\nIn this section we will explain how we use application \nmalleability to find a suitable set of resources for a given application and to\nadapt to changing conditions in the grid environment. In order to\nmonitor the application performance and guide the adaptation, we\nadded an extra process to the computation which we call \nadaptation coordinator. The adaptation coordinator periodically collects\nperformance statistics from the application processors. We \nintroduce a new application performance metric: weighted average \nefficiency which describes the application performance on a \nheterogeneous set of resources. The coordinator uses statistics from \napplication processors to compute the weighted average efficiency. If\nthe efficiency falls above or below certain thresholds, the \ncoordinator decides on adding or removing processors. A heuristic formula\nis used to decide which processors have to be removed. During\nthis process the coordinator learns the application requirements by\nremembering the characteristics of the removed processors. These\nrequirements are then used to guide the adding of new processors.\n3.1 Weighted average efficiency\nIn traditional parallel computing, a standard metric describing the\nperformance of a parallel application is efficiency. Efficiency is\ndefined as the average utilization of the processors, that is, the\nfraction of time the processors spend doing useful work rather than\nbeing idle or communicating with other processors (10).\nefficiency =\n1\nn\n\u00e2\u02c6\u2014\nn\ni=0\n(1 \u00e2\u02c6\u2019 overheadi )\nwhere n is the number of processors and overheadi is the \nfraction of time the ith\nprocessor spends being idle or communicating.\nEfficiency indicates the benefit of using multiple processors.\nTypically, the efficiency drops as new processors are added to\nthe computation. Therefore, achieving a high speedup (and thus\na low execution time) and achieving a high system utilization are\nconflicting goals (10). The optimal number of processors is the\nnumber for which the ratio of efficiency to execution time is \nmaximized. Adding processors beyond this number yields little benefit.\nThis number is typically hard to find, but in (10) it was \ntheoretically proven that if the optimal number of processors is used, the\nefficiency is at least 50%. Therefore, adding processors when \nefficiency is smaller or equal to 50% will only decrease the system\nutilization without significant performance gains.\nFor heterogeneous environments with different processor speeds,\nwe extended the notion of efficiency and introduced weighted \naverage efficiency.\nwa efficiency =\n1\nn\n\u00e2\u02c6\u2014\nn\ni=0\nspeedi \u00e2\u02c6\u2014 (1 \u00e2\u02c6\u2019 overheadi )\nThe useful work done by a processor (1 \u00e2\u02c6\u2019 overheadi) is\nweighted by multiplying it by the speed of this processor \nrelative to the fastest processor. The fastest processor has speed = 1,\nfor others holds: 0 < speed \u00e2\u2030\u00a4 1. Therefore, slower processors are\nmodeled as fast ones that spend a large fraction of the time being\nidle. Weighted average efficiency reflects the fact that adding slow\nprocessors yields less benefit than adding fast processors.\nIn the heterogeneous world, it is hardly beneficial to add \nprocessors if the efficiency is lower than 50% unless the added processor\nis faster than some of the currently used processors. Adding faster\nprocessors might be beneficial regardless of the efficiency.\n3.2 Application monitoring\nEach processor measures the time it spends communicating or \nbeing idle. The computation is divided into monitoring periods. \nAfter each monitoring period, the processors compute their overhead\nover this period as the percentage of the time they spent being idle\nor communicating in this period. Apart from total overhead, each\nprocessor also computes the overhead of inter-cluster and \nintracluster communication.\nTo calculate weighted average efficiency, we need to know the\nrelative speeds of the processors, which depend on the \napplication and the problem size used. Since it is impractical to run the\n122\nwhole application on each processor separately, we use \napplicationspecific benchmarks. Currently we use the same application with a\nsmall problem size as a benchmark and we require the application\nprogrammer to specify this problem size. This approach requires\nextra effort from the programmer to find the right problem size and\npossibly to produce input files for this problem size, which may\nbe hard. In the future, we are planning to generate benchmarks \nautomatically by choosing a random subset of the task graph of the\noriginal application.\nBenchmarks have to be re-run periodically because the speed of\na processor might change if it becomes overloaded by another \napplication (for time-shared machines). There is a trade-off between\nthe accuracy of speed measurements and the overhead it incurs. The\nlonger the benchmark, the greater the accuracy of the measurement.\nThe more often it is run, the faster changes in processor speed are\ndetected. In our current implementation, the application \nprogrammer specifies the length of the benchmark (by specifying its \nproblem size) and the maximal overhead it is allowed to cause. \nProcessors run the benchmark at such frequency so as not to exceed the\nspecified overhead. In the future, we plan to combine \nbenchmarking with monitoring the load of the processor which would allow\nus to avoid running the benchmark if no change in processor load\nis detected. This optimization will further reduce the benchmarking\noverhead.\nNote that the benchmarking overhead could be avoided \ncompletely for more regular applications, for example, for \nmasterworker applications with tasks of equal or similar size. The \nprocessor speed could then be measured by counting the tasks \nprocessed by this processor within one monitoring period. \nUnfortunately, divide-and-conquer applications typically exhibit a very \nirregular structure. The sizes of tasks can vary by many orders of\nmagnitude.\nAt the end of each monitoring period, the processors send the\noverhead statistics and processor speeds to the coordinator. \nPeriodically, the coordinator computes the weighted average efficiency and\nother statistics, such as average inter-cluster overhead or overheads\nin each cluster. The clocks of the processors are not synchronized\nwith each other or with the clock of the coordinator. Each \nprocessor decides separately when it is time to send data. Occasionally,\nthe coordinator may miss data at the end of a monitoring period,\nso it has to use data from the previous monitoring period for these\nprocessors. This causes small inaccuracies in the calculations of the\ncoordinator, but does not influence the performance of adaptation.\n3.3 Adaptation strategy\nThe adaptation coordinator tries to keep the weighted average \nefficiency between Emin and Emax. When it exceeds Emax, the \ncoordinator requests new processors from the scheduler. The number of\nrequested processors depends on the current efficiency: the higher\nthe efficiency, the more processors are requested. The coordinator\nstarts removing processors when the weighted average efficiency\ndrops below Emin. The number of nodes that are removed again\ndepends on the weighted average efficiency. The lower the \nefficiency, the more nodes are removed. The thresholds we use are\nEmax = 50%, because we know that adding processors when \nefficiency is lower does not make sense, and Emin = 30%. \nEfficiency of 30% or lower might indicate performance problems such\nas low bandwidth or overloaded processors. In that case, \nremoving bad processors will be beneficial for the application. Such low\nefficiency might also indicate that we simply have too many \nprocessors. In that case, removing some processors may not be beneficial\nbut it will not harm the application. The coordinator always tries\nto remove the worst processors. The badness of a processor is\ndetermined by the following formula:\nproc badnessi = \u00ce\u00b1 \u00e2\u02c6\u2014\n1\nspeedi\n+ \u00ce\u00b2 \u00e2\u02c6\u2014 ic overheadi\n+ \u00ce\u00b3 \u00e2\u02c6\u2014 inW orstCluster(i)\nThe processor is considered bad if it has low speed ( 1\nspeed\nis\nbig) and high inter-cluster overhead (ic overhead). High \nintercluster overhead indicates that the bandwidth to this processor\"s\ncluster is insufficient. Removing processors located in a single\ncluster is desirable since it decreases the amount of wide-area\ncommunication. Therefore, processors belonging to the worst\ncluster are preferred. Function inW orstCluster(i) returns 1 for\nprocessors belonging to the worst cluster and 0 otherwise. The\nbadness of clusters is computed similarly to the badness of\nprocessors:\ncluster badnessi = \u00ce\u00b1 \u00e2\u02c6\u2014\n1\nspeedi\n+ \u00ce\u00b2 \u00e2\u02c6\u2014 ic overheadi\nThe speed of a cluster is the sum of processor speeds normalized\nto the speed of the fastest cluster. The ic overhead of a cluster is\nan average of processor inter-cluster overheads. The \u00ce\u00b1, \u00ce\u00b2 and \u00ce\u00b3\ncoefficients determine the relative importance of the terms. Those\ncoefficients are established empirically. Currently we are using\nthe following values: \u00ce\u00b1 = 1, \u00ce\u00b2 = 100 and \u00ce\u00b3 = 10, based\non the observation that ic overhead > 0.2 indicates bandwidth\nproblems and processors with speed < 0.05 do not contribute to\nthe computation.\nAdditionally, when one of the clusters has an exceptionally high\ninter-cluster overhead (larger than 0.25), we conclude that the \nbandwidth on the link between this cluster and the Internet backbone is\ninsufficient for the application. In that case, we simply remove the\nwhole cluster instead of computing node badness and removing the\nworst nodes. After deciding which nodes are removed, the \ncoordinator sends a message to these nodes and the nodes leave the\ncomputation. Figure 1 shows a schematic view of the adaptation\nstrategy. Dashed lines indicate a part that is not supported yet, as\nwill be explained below.\nThis simple adaptation strategy allows us to improve application\nperformance in several situations typical for the Grid:\n\u00e2\u20ac\u00a2 If an application is started on fewer processors than its degree of\nparallelism allows, it will automatically expand to more \nprocessors (as soon as there are extra resources available). Conversely,\nif an application is started on more processors than it can \nefficiently use, a part of the processors will be released.\n\u00e2\u20ac\u00a2 If an application is running on an appropriate set of resources\nbut after a while some of the resources (processors and/or \nnetwork links) become overloaded and slow down the \ncomputation, the overloaded resources will be removed. After removing\nthe overloaded resources, the weighted average efficiency will\nincrease to above the Emax threshold and the adaptation \ncoordinator will try to add new resources. Therefore, the application\nwill be migrated from overloaded resources.\n\u00e2\u20ac\u00a2 If some of the original resources chosen by the user are \ninappropriate for the application, for example the bandwidth to one\nof the clusters is too small, the inappropriate resources will be\nremoved. If necessary, the adaptation component will try to add\nother resources.\n\u00e2\u20ac\u00a2 If during the computation a substantial part of the processors\nwill crash, the adaptation component will try to add new \nresources to replace the crashed processors.\n123\n0\n2000\n4000\n6000\nruntime(secs.)\nScenario 0\na b c\nScenario 1 Scenario 2 Scenario 3 Scenario 4 Scenario 5\nwithout monitoring and adaptation (runtime 1)\nwith monitoring and adaptation (runtime 2)\nwith monitoring but no adaptation (runtime 3)\nFigure 2. The runtimes of the Barnes-Hut application, scenarios 0-5\nadd nodes\nfaster nodes\navailable\nif\ncompute weighted\naverage efficiency E wa\nwait & collect\nstatistics\nrank nodes\nremove worst nodes\nwaE\nEwa\nY\nN\nN\nY\nabove\nif\nbelow\nif\nEmin\nmaxE\nFigure 1. Adaptation strategy\n\u00e2\u20ac\u00a2 If the application degree of parallelism is changing during the\ncomputation, the number of nodes the application is running on\nwill be automatically adjusted.\nFurther improvements are possible, but require extra \nfunctionality from the grid scheduler and/or integration with monitoring\nservices such as NWS (22). For example, adding nodes to a \ncomputation can be improved. Currently, we add any nodes the \nscheduler gives us. However, it would be more efficient to ask for the\nfastest processors among the available ones. This could be done, for\nexample, by passing a benchmark to the grid scheduler, so that it\ncan measure processor speeds in an application specific way. \nTypically, it would be enough to measure the speed of one processor\nper site, since clusters and supercomputers are usually \nhomogeneous. An alternative approach would be ranking the processors\nbased on parameters such as clock speed and cache size. This \napproach is sometimes used for resource selection for sequential \napplications (14). However, it is less accurate than using an \napplication specific benchmark.\nAlso, during application execution, we can learn some \napplication requirements and pass them to the scheduler. One example is\nminimal bandwidth required by the application. The lower bound\non minimal required bandwidth is tightened each time a cluster\nwith high inter-cluster overhead is removed. The bandwidth \nbetween each pair of clusters is estimated during the computation by\nmeasuring data transfer times, and the bandwidth to the removed\ncluster is set as a minimum. Alternatively, information from a grid\nmonitoring system can be used. Such bounds can be passed to the\nscheduler to avoid adding inappropriate resources. It is especially\nimportant when migrating from resources that cause performance\nproblems: we have to be careful not to add the resources we have\njust removed. Currently we use blacklisting - we simply do not \nallow adding resources we removed before. This means, however,\nthat we cannot use these resources even if the cause of the \nperformance problem disappears, e.g. the bandwidth of a link might\nimprove if the background traffic diminishes.\nWe are currently not able to perform opportunistic migration\n- migrating to better resources when they are discovered. If an\napplication runs with efficiency between Emin and Emax, the\nadaptation component will not undertake any action, even if \nbetter resources become available. Enabling opportunistic migration\nrequires, again, the ability to specify to the scheduler what \nbetter resources are (faster, with a certain minimal bandwidth) and\nreceiving notifications when such resources become available.\nExisting grid schedulers such as GRAM from the Globus\nToolkit (11) do not support such functionality. The developers of\nthe KOALA metascheduler (15) have recently started a project\nwhose goal is to provide support for adaptive applications. We\nare currently discussing with them the possibility of providing the\nfunctionalities required by us, aiming to extend our adaptivity \nstrat124\negy to support opportunistic migration and to improve the initial\nresource selection.\n4. Implementation\nWe incorporated our adaptation mechanism into Satin - a Java\nframework for creating grid-enabled divide-and-conquer \napplications. With Satin, the programmer annotates the sequential code\nwith divide-and-conquer primitives and compiles the annotated\ncode with a special Satin compiler that generates the necessary\ncommunication and load balancing code. Satin uses a very \nefficient, grid-aware load balancing algorithm - Cluster-aware \nRandom Work Stealing (CRS) (19), which hides wide-area latencies\nby overlapping local and remote stealing. Satin also provides \ntransparent fault tolerance and malleability (23). With Satin, removing\nand adding processors from/to an ongoing computation incurs little\noverhead.\nWe instrumented the Satin runtime system to collect runtime\nstatistics and send them to the adaptation coordinator. The \ncoordinator is implemented as a separate process. Both coordinator and\nSatin are implemented entirely in Java on top of the Ibis \ncommunication library (21). The core of Ibis is also implemented in Java.\nThe resulting system therefore is highly portable (due to Java\"s\nwrite once, run anywhere property) allowing the software to run\nunmodified on a heterogeneous grid.\nIbis also provides the Ibis Registry. The Registry provides,\namong others, a membership service to the processors taking part\nin the computation. The adaptation coordinator uses the Registry\nto discover the application processes, and the application processes\nuse this service to discover each other. The Registry also offers fault\ndetection (additional to the fault detection provided by the \ncommunication channels). Finally, the Registry provides the possibility\nto send signals to application processes. The coordinator uses this\nfunctionality to notify the processors that they need to leave the\ncomputation. Currently the Registry is implemented as a \ncentralized server.\nFor requesting new nodes, the Zorilla (9) system is used - a\npeer-to-peer supercomputing middleware which allows \nstraightforward allocation of processors in multiple clusters and/or \nsupercomputers. Zorilla provides locality-aware scheduling, which tries to\nallocate processors that are located close to each other in terms\nof communication latency. In the future, Zorilla will also support\nbandwidth-aware scheduling, which tries to maximize the total\nbandwidth in the system. Zorilla can be easily replaced with \nanother grid scheduler. In the future, we are planning to integrate\nour adaptation component with GAT (3) which is becoming a \nstandard in the grid community and KOALA (15) a scheduler that \nprovides co-allocation on top of standard grid middleware, such as the\nGlobus Toolkit (11).\n5. Performance evaluation\nIn this section, we will evaluate our approach. We will demonstrate\nthe performance of our mechanism in a few scenarios. The first\nscenario is an ideal situation: the application runs on a \nreasonable set of nodes (i.e., such that the efficiency is around 50%) and\nno problems such as overloaded networks and processors, \ncrashing processors etc. occur. This scenario allows us to measure the\noverhead of the adaptation support. The remaining scenarios are\ntypical for grid environments and demonstrate that with our \nadaptation support the application can avoid serious performance \nbottlenecks such as overloaded processors or network links. For each \nscenario, we compare the performance of an application with \nadaptation support to a non-adaptive version. In the non-adaptive version,\nthe coordinator does not collect statistics and no benchmarking (for\nmeasuring processor speeds) is performed. In the ideal scenario,\n0 5 10 15\niteration number\n0\n200\n400\n600\niterationduration(secs.)\nstarting on 8 nodes\nstarting on 16 nodes\nstarting on 24 nodes\nstarting on 8 nodes\nstarting on 16 nodes\nstarting on 24 nodes\n}no adaptation\n}with adaptation\nFigure 3. Barnes-Hut iteration durations with/without adaptation,\ntoo few processors\n0 5 10 15\niteration number\n0\n200\n400\n600\n800\n1000\niterationduration(secs.)\nno adaptation\nwith adaptation\nCPU load introduced\noverloaded nodes removed\nstarted adding nodes\n36 nodes reached\nFigure 4. Barnes-Hut iteration durations with/without adaptation,\noverloaded CPUs\nwe additionally measure the performance of an application with\ncollecting statistics and benchmarking turned on but without \ndoing adaptation, that is, without allowing it to change the number\nof nodes. This allows us to measure the overhead of benchmarking\nand collecting statistics. In all experiments we used a monitoring\nperiod of 3 minutes for the adaptive versions of the applications.\nAll the experiments were carried out on the DAS-2 wide-area \nsystem (8), which consists of five clusters located at five Dutch \nuni125\nversities. One of the clusters consists of 72 nodes, the others of 32\nnodes. Each node contains two 1 GHz Pentium processors. Within\na cluster, the nodes are connected by Fast Ethernet. The clusters\nare connected by the Dutch university Internet backbone. In our\nexperiments, we used the Barnes-Hut N-body simulation. \nBarnesHut simulates the evolution of a large set of bodies under influence\nof (gravitational or electrostatic) forces. The evolution of N bodies\nis simulated in iterations of discrete time steps.\n5.1 Scenario 0: adaptivity overhead\nIn this scenario, the application is started on 36 nodes. The nodes\nare equally divided over 3 clusters (12 nodes in each cluster). On\nthis number of nodes, the application runs with 50% efficiency, so\nwe consider it a reasonable number of nodes. As mentioned above,\nin this scenario we measured three runtimes: the runtime of the \napplication without adaptation support (runtime 1), the runtime with\nadaptation support (runtime 2) and the runtime with monitoring\n(i.e., collection of statistics and benchmarking) turned on but \nwithout allowing it to change the number of nodes (runtime 3). Those\nruntimes are shown in Figure 2, first group of bars. The comparison\nbetween runtime 3 and 1 shows the overhead of adaptation support.\nIn this experiment it is around 15%. Almost all overhead comes\nfrom benchmarking. The benchmark is run 1-2 times per \nmonitoring period. This overhead can be made smaller by increasing the\nlength of the monitoring period and decreasing the benchmarking\nfrequency. The monitoring period we used (3 minutes) is relatively\nshort, because the runtime of the application was also relatively\nshort (30-60 minutes). Using longer running applications would\nnot allow us to finish the experimentation in a reasonable time.\nHowever, real-world grid applications typically need hours, days or\neven weeks to complete. For such applications, a much longer \nmonitoring period can be used and the adaptation overhead can be kept\nmuch lower. For example, with the Barnes-Hut application, if the\nmonitoring period is extended to 10 minutes, the overhead drops to\n6%. Note that combining benchmarking with monitoring processor\nload (as described in Section 3.2) would reduce the benchmarking\noverhead to almost zero: since the processor load is not changing,\nthe benchmarks would only need to be run at the beginning of the\ncomputation.\n5.2 Scenario 1: expanding to more nodes\nIn this scenario, the application is started on fewer nodes than the\napplication can efficiently use. This may happen because the user\ndoes not know the right number of nodes or because insufficient\nnodes were available at the moment the application was started. We\ntried 3 initial numbers of nodes: 8 (Scenario 1a), 16 (Scenario 1b)\nand 24 (Scenario 1c). The nodes were located in 1 or 2 clusters. In\neach of the three sub-scenarios, the application gradually expanded\nto 36-40 nodes located in 4 clusters. This allowed to reduce the\napplication runtimes by 50% (Scenario 1a), 35% (Scenario 1b) and\n12% (Scenario 1c) with respect to the non-adaptive version. Those\nruntimes are shown in Figure 2. Since Barnes-Hut is an iterative\napplication, we also measured the time of each iteration, as shown\nin Figure 3. Adaptation reduces the iteration time by a factor of 3\n(Scenario 1a), 1.7 (Scenario 1b) and 1.2 (Scenario 1c) which allows\nus to conclude that the gains in the total runtime would be even\nbigger if the application were run longer than for 15 iterations.\n5.3 Scenario 2: overloaded processors\nIn this scenario, we started the application on 36 nodes in 3 clusters.\nAfter 200 seconds, we introduced a heavy, artificial load on the \nprocessors in one of the clusters. Such a situation may happen when\nan application with a higher priority is started on some of the \nresources. Figure 4 shows the iteration durations of both the adaptive\nand non-adaptive versions. After introducing the load, the iteration\n0 5 10 15\niteration number\n0\n200\n400\n600\n800\n1000\niterationduration(secs.)\nno adaptation\nwith adaptation\none cluster is badly connected\nbadly connected cluster removed\nstarted adding nodes\n36 nodes reached\nFigure 5. Barnes-Hut iteration durations with/without adaptation,\noverloaded network link\n0 5 10 15\niteration number\n0\n200\n400\n600\n800\n1000\niterationduration(secs.)\nno adaptation\nwith adaptation\none cluster is badly connected\n12 nodes lightly overloaded\nremoved badly connected cluster\nremoved 2 lightly overloaded nodes\nFigure 6. Barnes-Hut iteration durations with/without adaptation,\noverloaded CPUs and an overloaded network link\nduration increased by a factor of 2 to 3. Also, the iteration times\nbecame very variable. The adaptive version reacted by removing\nthe overloaded nodes. After removing these nodes, the weighted\naverage efficiency rose to around 35% which triggered adding new\nnodes and the application expanded back to 38 nodes. So, the \noverloaded nodes were replaced by better nodes, which brought the \niteration duration back to the initial values. This reduced the total\nruntime by 14%. The runtimes are shown in Figure 2.\n126\n5.4 Scenario 3: overloaded network link\nIn this scenario, we ran the application on 36 nodes in 3 clusters.\nWe simulated that the uplink to one of the clusters was overloaded\nand the bandwidth on this uplink was reduced to approximately\n100 KB/s. To simulate low bandwidth we use the traffic-shaping\ntechniques described in (6). The iteration durations in this \nexperiment are shown in Figure 5. The iteration durations of the \nnonadaptive version exhibit enormous variation: from 170 to 890 \nseconds. The adaptive version removed the badly connected cluster\nafter the first monitoring period. As a result, the weighted \naverage efficiency rose to around 35% and new nodes were gradually\nadded until their number reached 38. This brought the iteration\ntimes down to around 100 seconds. The total runtime was reduced\nby 60% (Figure 2).\n5.5 Scenario 4: overloaded processors and an overloaded\nnetwork link\nIn this scenario, we ran the application on 36 nodes in 3 clusters.\nAgain, we simulated an overloaded uplink to one of the clusters.\nAdditionally, we simulated processors with heterogeneous speeds\nby inserting a relatively light artificial load on the processors in one\nof the remaining clusters. The iteration durations are shown in \nFigure 6. Again, the non-adaptive version exhibits a great variation in\niteration durations: from 200 to 1150 seconds. The adaptive \nversion removes the badly connected cluster after the first monitoring\nperiod which brings the iteration duration down to 210 seconds on\naverage. After removing one of the clusters, since some of the \nprocessors are slower (approximately 5 times), the weighted average\nefficiency raises only to around 40%. Since this value lies between\nEmin and Emax, no nodes are added or removed. This example \nillustrates what the advantages of opportunistic migration would be.\nThere were faster nodes available in the system. If these nodes were\nadded to the application (which could trigger removing the slower\nnodes) the iteration duration could be reduced even further. Still,\nthe adaptation reduced the total runtime by 30% (Figure 2).\n5.6 Scenario 5: crashing nodes\nIn the last scenario, we also run the application on 36 nodes in 3\nclusters. After 500 seconds, 2 out of 3 clusters crash. The iteration\ndurations are shown in Figure 7. After the crash, the iteration\nduration raised from 100 to 200 seconds. The weighted efficiency\nrose to around 30% which triggered adding new nodes in the\nadaptive version. The number of nodes gradually went back to 35\nwhich brought the iteration duration back to around 100 seconds.\nThe total runtime was reduced by 13% (Figure 2).\n6. Related work\nA number of Grid projects address the question of resource \nselection and adaptation. In GrADS (18) and ASSIST (1), resource \nselection and adaptation requires a performance model that allows\npredicting application runtimes. In the resource selection phase, a\nnumber of possible resource sets is examined and the set of \nresources with the shortest predicted runtime is selected. If \nperformance degradation is detected during the computation, the resource\nselection phase is repeated. GrADS uses the ratio of the predicted\nexecution times (of certain application phases) to the real \nexecution times as an indicator of application performance. ASSIST uses\nthe number of iterations per time unit (for iterative applications)\nor the number of tasks per time unit (for regular master-worker\napplications) as a performance indicator. The main difference \nbetween these approaches and our approach is the use of performance\nmodels. The main advantage is that once the performance model\nis known, the system is able to take more accurate migration \ndecisions than with our approach. However, even if the performance\n0 5 10 15\niteration number\n0\n200\n400\n600\n800\n1000\niterationduration(secs.)\nno adaptation\nwith adaptation\n2 out of 3 clusters crash\nstarted adding nodes\n36 nodes reached\nFigure 7. Barnes-Hut iteration durations with/without adaptation,\ncrashing CPUs\nmodel is known, the problem of finding an optimal resource set (i.e.\nthe resource set with the minimal execution time) is NP-complete.\nCurrently, both GrADS and ASSIST examine only a subset of all\npossible resource sets and therefore there is no guarantee that the\nresulting resource set will be optimal. As the number of available\ngrid resources increases, the accuracy of this approach diminishes,\nas the subset of possible resource sets that can be examined in a\nreasonable time becomes smaller. Another disadvantage of these\nsystems is that the performance degradation detection is suitable\nonly for iterative or regular applications.\nCactus (2) and GridWay (14) do not use performance models.\nHowever, these frameworks are only suitable for sequential \n(GridWay) or single-site applications (Cactus). In that case, the resource\nselection problem boils down to selecting the fastest machine or\ncluster. Processor clock speed, average load and a number of \nprocessors in a cluster (Cactus) are used to rank resources and the \nresource with the highest rank is selected. The application is migrated\nif performance degradation is detected or better resources are \ndiscovered. Both Cactus and GridWay use the number of iterations per\ntime unit as the performance indicator. The main limitation of this\nmethodology is that it is suitable only for sequential or single-site\napplications. Moreover, resource selection based on clock speed is\nnot always accurate. Finally, performance degradation detection is\nsuitable only for iterative applications and cannot be used for \nirregular computations such as search and optimization problems.\nThe resource selection problem was also studied by the AppLeS\nproject (5). In the context of this project, a number of applications\nwere studied and performance models for these applications were\ncreated. Based on such a model a scheduling agent is built that\nuses the performance model to select the best resource set and the\nbest application schedule on this set. AppLeS scheduling agents are\nwritten on a case-by-case basis and cannot be reused for another \napplication. Two reusable templates were also developed for specific\nclasses of applications, namely master-worker (AMWAT template)\nand parameter sweep (APST template) applications. Migration is\nnot supported by the AppLeS software.\n127\nIn (13), the problem of scheduling master-worker applications\nis studied. The authors assume homogeneous processors (i.e., with\nthe same speed) and do not take communication costs into account.\nTherefore, the problem is reduced to finding the right number of\nworkers. The approach here is similar to ours in that no \nperformance model is used. Instead, the system tries to deduce the \napplication requirements at runtime and adjusts the number of workers\nto approach the ideal number.\n7. Conclusions and future work\nIn this paper, we investigated the problem of resource selection and\nadaptation in grid environments. Existing approaches to these \nproblems typically assume the existence of a performance model that\nallows predicting application runtimes on various sets of resources.\nHowever, creating performance models is inherently difficult and\nrequires knowledge about the application. We propose an approach\nthat does not require in-depth knowledge about the application. We\nstart the application on an arbitrary set of resources and monitor\nits performance. The performance monitoring allows us to learn\ncertain application requirements such as the number of processors\nneeded by the application or the application\"s bandwidth \nrequirements. We use this knowledge to gradually refine the resource set\nby removing inadequate nodes or adding new nodes if necessary.\nThis approach does not result in the optimal resource set, but in a\nreasonable resource set, i.e. a set free from various performance\nbottlenecks such as slow network connections or overloaded \nprocessors. Our approach also allows the application to adapt to the\nchanging grid conditions.\nThe adaptation decisions are based on the weighted average \nefficiency - an extension of the concept of parallel efficiency defined\nfor traditional, homogeneous parallel machines. If the weighted \naverage efficiency drops below a certain level, the adaptation \ncoordinator starts removing worst nodes. The badness of the nodes is\ndefined by a heuristic formula. If the weighted average efficiency\nraises above a certain level, new nodes are added. Our simple \nadaptation strategy allows us to handle multiple scenarios typical for\ngrid environments: expand to more nodes or shrink to fewer nodes\nif the application was started on an inappropriate number of \nprocessors, remove inadequate nodes and replace them with better ones,\nreplace crashed processors, etc. The application adapts fully \nautomatically to changing conditions. We implemented our approach\nin the Satin divide-and-conquer framework and evaluated it on\nthe DAS-2 distributed supercomputer and demonstrate that our \napproach can yield significant performance improvements (up to 60%\nin our experiments).\nFuture work will involve extending our adaptation strategy\nto support opportunistic migration. This, however, requires grid\nschedulers with more sophisticated functionality than currently \nexists. Further research is also needed to decrease the benchmarking\noverhead. For example, the information about CPU load could\nbe used to decrease the benchmarking frequency. Another line of\nresearch that we wish to investigate is using feedback control to\nrefine the adaptation strategy during the application run. For \nexample, the node badness formula could be refined at runtime based\non the effectiveness of the previous adaptation decisions. Finally,\nthe centralized implementation of the adaptation coordinator might\nbecome a bottleneck for applications which are running on very\nlarge numbers of nodes (hundreds or thousands). This problem can\nbe solved by implementing a hierarchy of coordinators: one \nsubcoordinator per cluster which collects and processes statistics from\nits cluster and one main coordinator which collects the information\nfrom the sub-coordinators.\nAcknowledgments\nThis work was carried out in the context of Virtual Laboratory for\ne-Science project (ww.vl-e.nl). This project is supported by a BSIK\ngrant from the Dutch Ministry of Education, Culture and Science\n(OC&W) and is part of the ICT innovation program of the Ministry\nof Economic Affairs (EZ).\nReferences\n[1] M. Aldinucci, F. Andre, J. Buisson, S. Campa, M. Coppola,\nM. Danelutto, and C. Zoccolo. Parallel program/component\nadaptivity management. In ParCo 2005, Sept. 2005.\n[2] G. Allen, D. Angulo, I. Foster, G. Lanfermann, C. Liu,\nT. Radke, E. Seidel, and J. Shalf. The cactus worm: \nExperiments with resource discovery and allocation in a grid \nenvironment. Int\"l Journal of High Performance Computing \nApplications, 15(4):345-358, 2001.\n[3] G. Allen, K. Davis, K. N. Dolkas, N. D. Doulamis, T. Goodale,\nT. Kielmann, A. Merzky, J. Nabrzyski, J. Pukacki, T. Radke,\nM. Russell, E. Seidel, J. Shalf, and I. Taylor. Enabling \napplications on the grid - a gridlab overview. Int\"l Journal of\nHigh-Performance Computing Applications, 17(4):449-466,\nAug. 2003.\n[4] J. E. Baldeschwieler, R. D. Blumofe, and E. A. Brewer. \nATLAS: An Infrastructure for Global Computing. In 7th ACM\nSIGOPS European Workshop on System Support for \nWorldwide Applications, pages 165-172, Sept. 1996.\n[5] F. Berman, R. Wolski, H. Casanova, W. Cirne, H. Dail,\nM. Faerman, S. Figueira, J. Hayes, G. Obertelli, J. Schopf,\nG. Shao, S. Smallen, N. Spring, A. Su, and D. \nZagorodnov. Adaptive Computing on the Grid Using AppLeS. IEEE\nTrans. on Parallel and Distributed Systems, 14(4):369-382,\nApr. 2003.\n[6] D.-M. Chiu, M. Kadansky, J. Provino, and J. Wesley. \nExperiences in programming a traffic shaper. In 5th IEEE Symp. on\nComputers and Communications, pages 470-476, 2000.\n[7] W. Chrabakh and R. Wolski. GridSAT: A Chaff-based \nDistributed SAT Solver for the Grid. In 2003 ACM/IEEE \nconference on Supercomputing, page 37, 2003.\n[8] The Distributed ASCI Supercomputer (DAS).\nhttp://www.cs.vu.nl/das2/.\n[9] N. Drost, R. V. van Nieuwport, and H. E. Bal. Simple \nlocalityaware co-allocation in peer-to-peer supercomputing. In 6th\nInt\"l Workshop on Global Peer-2-Peer Computing, May 2005.\n[10] D. L. Eager, J. Zahorjan, and E. D. Lazowska. Speedup\nversus efficiency in parallel systems. IEEE Transactions on\nComputers, 38(3):408-423, Mar. 1989.\n[11] I. Foster. Globus toolkit version 4: Software for \nserviceoriented systems. In IFIP International Conference on \nNetwork and Parallel Computing, pages 2-13. Springer-Verlag\nLNCS 3779, 2005.\n[12] J.-P. Goux, S. Kulkarni, M. Yoder, and J. Linderoth. An\nEnabling Framework for Master-Worker Applications on the\nComputational Grid. In 9th IEEE Int\"l Symp. on High \nPerformance Distributed Computing, pages 43-50, Aug. 2000.\n[13] E. Heymann, M. A. Senar, E. Luque, and M. Livny. \nAdaptive scheduling for master-worker applications on the \ncomputational grid. In 1st IEEE/ACM International Workshop\non Grid Computing, pages 214-227. Springer Verlag LNCS\n1971, 2000.\n128\n[14] E. Huedo, R. S. Montero, and I. M. Llorente. A framework\nfor adaptive execution in grids. Software - Practice & \nExperience, 34(7):631-651, 2004.\n[15] H. H. Mohamed and D. H. Epema. Experiences with the\nKOALA Co-Allocating Scheduler in Multiclusters. In 5th\nIEEE/ACM Int\"l Symp. on Cluster Computing and the GRID,\npages 640-650, May 2005.\n[16] A. Plaat, H. E. Bal, and R. F. H. Hofman. Sensitivity of\nparallel applications to large differences in bandwidth and\nlatency in two-layer interconnects. In 5th Int\"l Symp. On\nHigh Performance Computer Architecture, pages 244-253,\nJan. 1999.\n[17] J. W. Romein, H. E. Bal, J. Schaeffer, and A. Plaat. A \nperformance analysis of transposition-table-driven work scheduling\nin distributed search. IEEE Trans. on Parallel and Distributed\nSystems, 13(5):447-459, May 2002.\n[18] S. S. Vadhiyar and J. J. Dongarra. Self adaptivity in Grid\ncomputing. Concurrency and Computation: Practice and\nExperience, 17(2-4):235-257, 2005.\n[19] R. V. van Nieuwpoort, T. Kielmann, and H. E. Bal. Efficient\nload balancing for wide-area divide-and-conquer applications.\nIn 8th ACM SIGPLAN Symp. on Principles and Practices of\nParallel Programming, pages 34-43, 2001.\n[20] R. V. van Nieuwpoort, J. Maassen, T. Kielmann, and H. E. Bal.\nSatin: Simple and Efficient Java-based Grid Programming.\nScalable Computing: Practice and Experience, 6(3):19-32,\nSept. 2004.\n[21] R. V. van Nieuwpoort, J. Maassen, G. Wrzesinska, R. \nHofman, C. Jacobs, T. Kielmann, and H. E. Bal. Ibis: a \nFlexible and Efficient Java-based Grid Programming Environment.\nConcurrency & Computation: Practice & Experience, \n17(78):1079-1107, 2005.\n[22] R. Wolski, N. Spring, and J. Hayes. The network weather \nservice: A distributed resource performance forecasting service\nfor metacomputing. Journal of Future Generation Computing\nSystems, 15(5-6):757-768, Oct. 1999.\n[23] G. Wrzesinska, R. V. van Nieuwport, J. Maassen, and H. E.\nBal. Fault-tolerance, Malleability and Migration for \nDivideand-Conquer Applications on the Grid. In Int\"l Parallel and\nDistributed Processing Symposium, Apr. 2005.\n129\n": ["grid computing", "resource selection", "grid environment", "parallel computing", "homogeneous parallel environment", "heterogeneity of resource", "resource heterogeneity", "high-bandwidth local-area network", "lower-bandwidth wide-area network", "network link", "communication time", "idle time of the processor", "the processor idle time", "degree of parallelism", "parallelism degree", "overloaded resource", "divide-and-conquer", "self-adaptivity", ""]}