{"Pruning Policies for Two-Tiered Inverted Index\nwith Correctness Guarantee\nAlexandros Ntoulas\u00e2\u02c6\u2014\nMicrosoft Search Labs\n1065 La Avenida\nMountain View, CA 94043, USA\nantoulas@microsoft.com\nJunghoo Cho\u00e2\u20ac\u00a0\nUCLA Computer Science Dept.\nBoelter Hall\nLos Angeles, CA 90095, USA\ncho@cs.ucla.edu\nABSTRACT\nThe Web search engines maintain large-scale inverted indexes\nwhich are queried thousands of times per second by users eager\nfor information. In order to cope with the vast amounts of query\nloads, search engines prune their index to keep documents that are\nlikely to be returned as top results, and use this pruned index to\ncompute the first batches of results. While this approach can \nimprove performance by reducing the size of the index, if we compute\nthe top results only from the pruned index we may notice a \nsignificant degradation in the result quality: if a document should be in\nthe top results but was not included in the pruned index, it will be\nplaced behind the results computed from the pruned index. Given\nthe fierce competition in the online search market, this phenomenon\nis clearly undesirable.\nIn this paper, we study how we can avoid any degradation of\nresult quality due to the pruning-based performance optimization,\nwhile still realizing most of its benefit. Our contribution is a \nnumber of modifications in the pruning techniques for creating the\npruned index and a new result computation algorithm that \nguarantees that the top-matching pages are always placed at the top\nsearch results, even though we are computing the first batch from\nthe pruned index most of the time. We also show how to determine\nthe optimal size of a pruned index and we experimentally evaluate\nour algorithms on a collection of 130 million Web pages.\nCategories and Subject Descriptors\nH.3.1 [Information Storage and Retrieval]: Content Analysis\nand Indexing; H.3.3 [Information Storage and Retrieval]: \nInformation Search and Retrieval\nGeneral Terms\nAlgorithms, Measuring, Performance, Design, Experimentation\n1. INTRODUCTION\nThe amount of information on the Web is growing at a prodigious\nrate [24]. According to a recent study [13], it is estimated that the\nWeb currently consists of more than 11 billion pages. Due to this\nimmense amount of available information, the users are becoming\nmore and more dependent on the Web search engines for locating\nrelevant information on the Web. Typically, the Web search \nengines, similar to other information retrieval applications, utilize a\ndata structure called inverted index. An inverted index provides for\nthe efficient retrieval of the documents (or Web pages) that contain\na particular keyword.\nIn most cases, a query that the user issues may have thousands\nor even millions of matching documents. In order to avoid \noverwhelming the users with a huge amount of results, the search \nengines present the results in batches of 10 to 20 relevant documents.\nThe user then looks through the first batch of results and, if she\ndoesn\"t find the answer she is looking for, she may potentially \nrequest to view the next batch or decide to issue a new query.\nA recent study [16] indicated that approximately 80% of the\nusers examine at most the first 3 batches of the results. That is,\n80% of the users typically view at most 30 to 60 results for every\nquery that they issue to a search engine. At the same time, given the\nsize of the Web, the inverted index that the search engines maintain\ncan grow very large. Since the users are interested in a small \nnumber of results (and thus are viewing a small portion of the index for\nevery query that they issue), using an index that is capable of \nreturning all the results for a query may constitute a significant waste\nin terms of time, storage space and computational resources, which\nis bound to get worse as the Web grows larger over time [24].\nOne natural solution to this problem is to create a small index on\na subset of the documents that are likely to be returned as the top \nresults (by using, for example, the pruning techniques in [7, 20]) and\ncompute the first batch of answers using the pruned index. While\nthis approach has been shown to give significant improvement in\nperformance, it also leads to noticeable degradation in the quality of\nthe search results, because the top answers are computed only from\nthe pruned index [7, 20]. That is, even if a page should be placed as\nthe top-matching page according to a search engine\"s ranking \nmetric, the page may be placed behind the ones contained in the pruned\nindex if the page did not become part of the pruned index for \nvarious reasons [7, 20]. Given the fierce competition among search\nengines today this degradation is clearly undesirable and needs to\nbe addressed if possible.\nIn this paper, we study how we can avoid any degradation of\nsearch quality due to the above performance optimization while\nstill realizing most of its benefit. That is, we present a number of\nsimple (yet important) changes in the pruning techniques for \ncreating the pruned index. Our main contribution is a new answer\ncomputation algorithm that guarantees that the top-matching pages\n(according to the search-engine\"s ranking metric) are always placed\nat the top of search results, even though we are computing the first\nbatch of answers from the pruned index most of the time. These\nenhanced pruning techniques and answer-computation algorithms\nare explored in the context of the cluster architecture commonly\nemployed by today\"s search engines. Finally, we study and present\nhow search engines can minimize the operational cost of answering\nqueries while providing high quality search results.\nIF IF IF\nIF\nIF\nIF\nIF\nIp\nIp\nIp\nIp\nIp\nIp\n5000 queries/sec 5000 queries/sec\n: 1000 queries/sec\n: 1000 queries/sec\n2nd tier\n1st tier\n(a) (b)\nFigure 1: (a) Search engine replicates its full index IF to \nincrease query-answering capacity. (b) In the 1st\ntier, small \npindexes IP handle most of the queries. When IP cannot answer\na query, it is redirected to the 2nd\ntier, where the full index IF\nis used to compute the answer.\n2. CLUSTER ARCHITECTURE AND COST\nSAVINGS FROM A PRUNED INDEX\nTypically, a search engine downloads documents from the Web\nand maintains a local inverted index that is used to answer queries\nquickly.\nInverted indexes. Assume that we have collected a set of \ndocuments D = {D1, . . . , DM } and that we have extracted all the\nterms T = {t1, . . . , tn} from the documents. For every single\nterm ti \u00e2\u02c6\u02c6 T we maintain a list I(ti) of document IDs that contain\nti. Every entry in I(ti) is called a posting and can be extended to\ninclude additional information, such as how many times ti appears\nin a document, the positions of ti in the document, whether ti is\nbold/italic, etc. The set of all the lists I = {I(t1), . . . , I(tn)} is\nour inverted index.\n2.1 Two-tier index architecture\nSearch engines are accepting an enormous number of queries\nevery day from eager users searching for relevant information. For\nexample, Google is estimated to answer more than 250 million user\nqueries per day. In order to cope with this huge query load, search\nengines typically replicate their index across a large cluster of \nmachines as the following example illustrates:\nExample 1 Consider a search engine that maintains a cluster of\nmachines as in Figure 1(a). The size of its full inverted index IF\nis larger than what can be stored in a single machine, so each copy\nof IF is stored across four different machines. We also suppose\nthat one copy of IF can handle the query load of 1000 queries/sec.\nAssuming that the search engine gets 5000 queries/sec, it needs\nto replicate IF five times to handle the load. Overall, the search\nengine needs to maintain 4 \u00c3\u2014 5 = 20 machines in its cluster. 2\nWhile fully replicating the entire index IF multiple times is a\nstraightforward way to scale to a large number of queries, typical\nquery loads at search engines exhibit certain localities, allowing for\nsignificant reduction in cost by replicating only a small portion of\nthe full index. In principle, this is typically done by pruning a full\nindex IF to create a smaller, pruned index (or p-index) IP , which\ncontains a subset of the documents that are likely to be returned as\ntop results.\nGiven the p-index, search engines operate by employing a \ntwotier index architecture as we show in Figure 1(b): All incoming\nqueries are first directed to one of the p-indexes kept in the 1st\ntier.\nIn the cases where a p-index cannot compute the answer (e.g. was\nunable to find enough documents to return to the user) the query\nis answered by redirecting it to the 2nd\ntier, where we maintain\na full index IF . The following example illustrates the potential\nreduction in the query-processing cost by employing this two-tier\nindex architecture.\nExample 2 Assume the same parameter settings as in Example 1.\nThat is, the search engine gets a query load of 5000 queries/sec\nAlgorithm 2.1 Computation of answer with correctness guarantee\nInput q = ({t1, . . . , tn}, [i, i + k]) where\n{t1, . . . , tn}: keywords in the query\n[i, i + k]: range of the answer to return\nProcedure\n(1) (A, C) = ComputeAnswer(q, IP )\n(2) If (C = 1) Then\n(3) Return A\n(4) Else\n(5) A = ComputeAnswer(q, IF )\n(6) Return A\nFigure 2: Computing the answer under the two-tier \narchitecture with the result correctness guarantee.\nand every copy of an index (both the full IF and p-index IP ) can\nhandle up to 1000 queries/sec. Also assume that the size of IP is\none fourth of IF and thus can be stored on a single machine. \nFinally, suppose that the p-indexes can handle 80% of the user queries\nby themselves and only forward the remaining 20% queries to IF .\nUnder this setting, since all 5000/sec user queries are first directed\nto a p-index, five copies of IP are needed in the 1st\ntier. For the\n2nd\ntier, since 20% (or 1000 queries/sec) are forwarded, we need\nto maintain one copy of IF to handle the load. Overall we need\na total of 9 machines (five machines for the five copies of IP and\nfour machines for one copy of IF ). Compared to Example 1, this\nis more than 50% reduction in the number of machines. 2\nThe above example demonstrates the potential cost saving\nachieved by using a p-index. However, the two-tier architecture\nmay have a significant drawback in terms of its result quality \ncompared to the full replication of IF ; given the fact that the p-index\ncontains only a subset of the data of the full index, it is possible that,\nfor some queries, the p-index may not contain the top-ranked \ndocument according to the particular ranking criteria used by the search\nengine and fail to return it as the top page, leading to noticeable\nquality degradation in search results. Given the fierce competition\nin the online search market, search engine operators desperately try\nto avoid any reduction in search quality in order to maximize user\nsatisfaction.\n2.2 Correctness guarantee under two-tier\narchitecture\nHow can we avoid the potential degradation of search quality\nunder the two-tier architecture? Our basic idea is straightforward:\nWe use the top-k result from the p-index only if we know for sure\nthat the result is the same as the top-k result from the full index.\nThe algorithm in Figure 2 formalizes this idea. In the algorithm,\nwhen we compute the result from IP (Step 1), we compute not\nonly the top-k result A, but also the correctness indicator function\nC defined as follows:\nDefinition 1 (Correctness indicator function) Given a query q,\nthe p-index IP returns the answer A together with a correctness\nindicator function C. C is set to 1 if A is guaranteed to be identical\n(i.e. same results in the same order) to the result computed from\nthe full index IF . If it is possible that A is different, C is set to 0. 2\nNote that the algorithm returns the result from IP (Step 3) only\nwhen it is identical to the result from IF (condition C = 1 in\nStep 2). Otherwise, the algorithm recomputes and returns the \nresult from the full index IF (Step 5). Therefore, the algorithm is\nguaranteed to return the same result as the full replication of IF all\nthe time.\nNow, the real challenge is to find out (1) how we can compute\nthe correctness indicator function C and (2) how we should prune\nthe index to make sure that the majority of queries are handled by\nIP alone.\nQuestion 1 How can we compute the correctness indicator \nfunction C?\nA straightforward way to calculate C is to compute the top-k \nanswer both from IP and IF and compare them. This naive solution,\nhowever, incurs a cost even higher than the full replication of IF\nbecause the answers are computed twice: once from IP and once\nfrom IF . Is there any way to compute the correctness indicator\nfunction C only from IP without computing the answer from IF ?\nQuestion 2 How should we prune IF to IP to realize the maximum\ncost saving?\nThe effectiveness of Algorithm 2.1 critically depends on how\noften the correctness indicator function C is evaluated to be 1. If\nC = 0 for all queries, for example, the answers to all queries will be\ncomputed twice, once from IP (Step 1) and once from IF (Step 5),\nso the performance will be worse than the full replication of IF .\nWhat will be the optimal way to prune IF to IP , such that C = 1\nfor a large fraction of queries? In the next few sections, we try to\naddress these questions.\n3. OPTIMAL SIZE OF THE P-INDEX\nIntuitively, there exists a clear tradeoff between the size of IP\nand the fraction of queries that IP can handle: When IP is large and\nhas more information, it will be able to handle more queries, but\nthe cost for maintaining and looking up IP will be higher. When\nIP is small, on the other hand, the cost for IP will be smaller,\nbut more queries will be forwarded to IF , requiring us to maintain\nmore copies of IF . Given this tradeoff, how should we determine\nthe optimal size of IP in order to maximize the cost saving? To\nfind the answer, we start with a simple example.\nExample 3 Again, consider a scenario similar to Example 1,\nwhere the query load is 5000 queries/sec, each copy of an index\ncan handle 1000 queries/sec, and the full index spans across 4 \nmachines. But now, suppose that if we prune IF by 75% to IP 1 (i.e.,\nthe size of IP 1 is 25% of IF ), IP 1 can handle 40% of the queries\n(i.e., C = 1 for 40% of the queries). Also suppose that if IF is\npruned by 50% to IP 2, IP 2 can handle 80% of the queries. Which\none of the IP 1, IP 2 is preferable for the 1st\n-tier index?\nTo find out the answer, we first compute the number of machines\nneeded when we use IP 1 for the 1st\ntier. At the 1st\ntier, we need 5\ncopies of IP 1 to handle the query load of 5000 queries/sec. Since\nthe size of IP 1 is 25% of IF (that requires 4 machines), one copy of\nIP 1 requires one machine. Therefore, the total number of machines\nrequired for the 1st\ntier is 5\u00c3\u20141 = 5 (5 copies of IP 1 with 1 machine\nper copy). Also, since IP 1 can handle 40% of the queries, the 2nd\ntier has to handle 3000 queries/sec (60% of the 5000 queries/sec),\nso we need a total of 3\u00c3\u20144 = 12 machines for the 2nd\ntier (3 copies\nof IF with 4 machines per copy). Overall, when we use IP 1 for the\n1st\ntier, we need 5 + 12 = 17 machines to handle the load. We\ncan do similar analysis when we use IP 2 and see that a total of 14\nmachines are needed when IP 2 is used. Given this result, we can\nconclude that using IP 2 is preferable. 2\nThe above example shows that the cost of the two-tier \narchitecture depends on two important parameters: the size of the p-index\nand the fraction of the queries that can be handled by the 1st\ntier\nindex alone. We use s to denote the size of the p-index relative to\nIF (i.e., if s = 0.2, for example, the p-index is 20% of the size of\nIF ). We use f(s) to denote the fraction of the queries that a p-index\nof size s can handle (i.e., if f(s) = 0.3, 30% of the queries return\nthe value C = 1 from IP ). In general, we can expect that f(s) will\nincrease as s gets larger because IP can handle more queries as its\nsize grows. In Figure 3, we show an example graph of f(s) over s.\nGiven the notation, we can state the problem of p-index-size \noptimization as follows. In formulating the problem, we assume that\nthe number of machines required to operate a two-tier architecture\n0\n0.2\n0.4\n0.6\n0.8\n1\n0 0.2 0.4 0.6 0.8 1\nFractionofqueriesguaranteed-f(s)\nFraction of index - s\nFraction of queries guaranteed per fraction of index\nOptimal size s=0.16\nFigure 3: Example function showing the fraction of guaranteed\nqueries f(s) at a given size s of the p-index.\nis roughly proportional to the total size of the indexes necessary to\nhandle the query load.\nProblem 1 (Optimal index size) Given a query load Q and the\nfunction f(s), find the optimal p-index size s that minimizes the\ntotal size of the indexes necessary to handle the load Q. 2\nThe following theorem shows how we can determine the optimal\nindex size.\nTheorem 1 The cost for handling the query load Q is minimal\nwhen the size of the p-index, s, satisfies d f(s)\nd s\n= 1. 2\nProof The proof of this and the following theorems is omitted due\nto space constraints.\nThis theorem shows that the optimal point is when the slope of\nthe f(s) curve is 1. For example, in Figure 3, the optimal size\nis when s = 0.16. Note that the exact shape of the f(s) graph\nmay vary depending on the query load and the pruning policy. For\nexample, even for the same p-index, if the query load changes \nsignificantly, fewer (or more) queries may be handled by the p-index,\ndecreasing (or increasing)f(s). Similarly, if we use an effective\npruning policy, more queries will be handled by IP than when we\nuse an ineffective pruning policy, increasing f(s). Therefore, the\nfunction f(s) and the optimal-index size may change significantly\ndepending on the query load and the pruning policy. In our later \nexperiments, however, we find that even though the shape of the f(s)\ngraph changes noticeably between experiments, the optimal index\nsize consistently lies between 10%-30% in most experiments.\n4. PRUNING POLICIES\nIn this section, we show how we should prune the full index IF\nto IP , so that (1) we can compute the correctness indicator function\nC from IP itself and (2) we can handle a large fraction of queries\nby IP . In designing the pruning policies, we note the following two\nlocalities in the users\" search behavior:\n1. Keyword locality: Although there are many different words\nin the document collection that the search engine indexes, a\nfew popular keywords constitute the majority of the query\nloads. This keyword locality implies that the search engine\nwill be able to answer a significant fraction of user queries\neven if it can handle only these few popular keywords.\n2. Document locality: Even if a query has millions of \nmatching documents, users typically look at only the first few \nresults [16]. Thus, as long as search engines can compute the\nfirst few top-k answers correctly, users often will not notice\nthat the search engine actually has not computed the correct\nanswer for the remaining results (unless the users explicitly\nrequest them).\nBased on the above two localities, we now investigate two \ndifferent types of pruning policies: (1) a keyword pruning policy, which\ntakes advantage of the keyword locality by pruning the whole \ninverted list I(ti) for unpopular keywords ti\"s and (2) a document\npruning policy, which takes advantage of the document locality by\nkeeping only a few postings in each list I(ti), which are likely to\nbe included in the top-k results.\nAs we discussed before, we need to be able to compute the \ncorrectness indicator function from the pruned index alone in order to\nprovide the correctness guarantee. Since the computation of \ncorrectness indicator function may critically depend on the particular\nranking function used by a search engine, we first clarify our \nassumptions on the ranking function.\n4.1 Assumptions on ranking function\nConsider a query q = {t1, t2, . . . , tw} that contains a subset\nof the index terms. The goal of the search engine is to return the\ndocuments that are most relevant to query q. This is done in two\nsteps: first we use the inverted index to find all the documents that\ncontain the terms in the query. Second, once we have the \nrelevant documents, we calculate the rank (or score) of each one of the\ndocuments with respect to the query and we return to the user the\ndocuments that rank the highest.\nMost of the major search engines today return documents \ncontaining all query terms (i.e. they use AND-semantics). In order to\nmake our discussions more concise, we will also assume the \npopular AND-semantics while answering a query. It is straightforward\nto extend our results to OR-semantics as well. The exact ranking\nfunction that search engines employ is a closely guarded secret.\nWhat is known, however, is that the factors in determining the \ndocument ranking can be roughly categorized into two classes:\nQuery-dependent relevance. This particular factor of relevance\ncaptures how relevant the query is to every document. At a high\nlevel, given a document D, for every term ti a search engine assigns\na term relevance score tr(D, ti) to D. Given the tr(D, ti) scores\nfor every ti, then the query-dependent relevance of D to the query,\nnoted as tr(D, q), can be computed by combining the individual\nterm relevance values. One popular way for calculating the \nquerydependent relevance is to represent both the document D and the\nquery q using the TF.IDF vector space model [29] and employ a\ncosine distance metric.\nSince the exact form of tr(D, ti) and tr(D, q) differs \ndepending on the search engine, we will not restrict to any particular form;\ninstead, in order to make our work applicable in the general case,\nwe will make the generic assumption that the query-dependent \nrelevance is computed as a function of the individual term relevance\nvalues in the query:\ntr(D, q) = ftr(tr(D, t1), . . . , tr(D, tw)) (1)\nQuery-independent document quality. This is a factor that \nmeasures the overall quality of a document D independent of the \nparticular query issued by the user. Popular techniques that compute\nthe general quality of a page include PageRank [26], HITS [17] and\nthe likelihood that the page is a spam page [25, 15]. Here, we\nwill use pr(D) to denote this query-independent part of the final\nranking function for document D.\nThe final ranking score r(D, q) of a document will depend on\nboth the query-dependent and query-independent parts of the \nranking function. The exact combination of these parts may be done in\na variety of ways. In general, we can assume that the final \nranking score of a document is a function of its query-dependent and\nquery-independent relevance scores. More formally:\nr(D, q) = fr(tr(D, q), pr(D)) (2)\nFor example, fr(tr(D, q), pr(D)) may take the form\nfr(tr(D, q), pr(D)) = \u00ce\u00b1 \u00c2\u00b7 tr(D, q) + (1 \u00e2\u02c6\u2019 \u00ce\u00b1) \u00c2\u00b7 pr(D),\nthus giving weight \u00ce\u00b1 to the query-dependent part and the weight\n1 \u00e2\u02c6\u2019 \u00ce\u00b1 to the query-independent part.\nIn Equations 1 and 2 the exact form of fr and ftr can vary \ndepending on the search engine. Therefore, to make our discussion\napplicable independent of the particular ranking function used by\nsearch engines, in this paper, we will make only the generic \nassumption that the ranking function r(D, q) is monotonic on its \nparameters tr(D, t1), . . . , tr(D, tw) and pr(D).\nt1 \u00e2\u2020\u2019 D1 D2 D3 D4 D5 D6\nt2 \u00e2\u2020\u2019 D1 D2 D3\nt3 \u00e2\u2020\u2019 D3 D5 D7 D8\nt4 \u00e2\u2020\u2019 D4 D10\nt5 \u00e2\u2020\u2019 D6 D8 D9\nFigure 4: Keyword and document pruning.\nAlgorithm 4.1 Computation of C for keyword pruning\nProcedure\n(1) C = 1\n(2) Foreach ti \u00e2\u02c6\u02c6 q\n(3) If (I(ti) /\u00e2\u02c6\u02c6 IP ) Then C = 0\n(4) Return C\nFigure 5: Result guarantee in keyword pruning.\nDefinition 2 A function f(\u00ce\u00b1, \u00ce\u00b2, . . . , \u00cf\u2030) is monotonic if \u00e2\u02c6\u20ac\u00ce\u00b11 \u00e2\u2030\u00a5\n\u00ce\u00b12, \u00e2\u02c6\u20ac\u00ce\u00b21 \u00e2\u2030\u00a5 \u00ce\u00b22, . . . \u00e2\u02c6\u20ac\u00cf\u20301 \u00e2\u2030\u00a5 \u00cf\u20302 it holds that: f(\u00ce\u00b11, \u00ce\u00b21, . . . , \u00cf\u20301) \u00e2\u2030\u00a5\nf(\u00ce\u00b12, \u00ce\u00b22, . . . , \u00cf\u20302).\nRoughly, the monotonicity of the ranking function implies that,\nbetween two documents D1 and D2, if D1 has higher \nquerydependent relevance than D2 and also a higher query-independent\nscore than D2, then D1 should be ranked higher than D2, which\nwe believe is a reasonable assumption in most practical settings.\n4.2 Keyword pruning\nGiven our assumptions on the ranking function, we now \ninvestigate the keyword pruning policy, which prunes the inverted index\nIF horizontally by removing the whole I(ti)\"s corresponding to\nthe least frequent terms. In Figure 4 we show a graphical \nrepresentation of keyword pruning, where we remove the inverted lists for\nt3 and t5, assuming that they do not appear often in the query load.\nNote that after keyword pruning, if all keywords {t1, . . . , tn} in\nthe query q appear in IP , the p-index has the same information as\nIF as long as q is concerned. In other words, if all keywords in q\nappear in IP , the answer computed from IP is guaranteed to be the\nsame as the answer computed from IF . Figure 5 formalizes this\nobservation and computes the correctness indicator function C for\na keyword-pruned index IP . It is straightforward to prove that the\nanswer from IP is identical to that from IF if C = 1 in the above\nalgorithm.\nWe now consider the issue of optimizing the IP such that it can\nhandle the largest fraction of queries. This problem can be formally\nstated as follows:\nProblem 2 (Optimal keyword pruning) Given the query load Q\nand a goal index size s \u00c2\u00b7 |IF | for the pruned index, select the \ninverted lists IP = {I(t1), . . . , I(th)} such that |IP | \u00e2\u2030\u00a4 s \u00c2\u00b7 |IF | and\nthe fraction of queries that IP can answer (expressed by f(s)) is\nmaximized. 2\nUnfortunately, the optimal solution to the above problem is \nintractable as we can show by reducing from knapsack (we omit the\ncomplete proof).\nTheorem 2 The problem of calculating the optimal keyword \npruning is NP-hard. 2\nGiven the intractability of the optimal solution, we need to resort\nto an approximate solution. A common approach for similar \nknapsack problems is to adopt a greedy policy by keeping the items\nwith the maximum benefit per unit cost [9]. In our context, the\npotential benefit of an inverted list I(ti) is the number of queries\nthat can be answered by IP when I(ti) is included in IP . We\napproximate this number by the fraction of queries in the query\nload Q that include the term ti and represent it as P(ti). For \nexample, if 100 out of 1000 queries contain the term computer,\nAlgorithm 4.2 Greedy keyword pruning HS\nProcedure\n(1) \u00e2\u02c6\u20acti, calculate HS(ti) =\nP (ti)\n|I(ti)|\n.\n(2) Include the inverted lists with the highest\nHS(ti) values such that |IP | \u00e2\u2030\u00a4 s \u00c2\u00b7 |IF |.\nFigure 6: Approximation algorithm for the optimal keyword\npruning.\nAlgorithm 4.3 Global document pruning V SG\nProcedure\n(1) Sort all documents Di based on pr(Di)\n(2) Find the threshold value \u00cf\u201ep, such that\nonly s fraction of the documents have pr(Di) > \u00cf\u201ep\n(4) Keep Di in the inverted lists if pr(Di) > \u00cf\u201ep\nFigure 7: Global document pruning based on pr.\nthen P(computer) = 0.1. The cost of including I(ti) in the \npindex is its size |I(ti)|. Thus, in our greedy approach in Figure 6,\nwe include I(ti)\"s in the decreasing order of P(ti)/|I(ti)| as long\nas |IP | \u00e2\u2030\u00a4 s \u00c2\u00b7 |IF |. Later in our experiment section, we evaluate\nwhat fraction of queries can be handled by IP when we employ\nthis greedy keyword-pruning policy.\n4.3 Document pruning\nAt a high level, document pruning tries to take advantage of the\nobservation that most users are mainly interested in viewing the\ntop few answers to a query. Given this, it is unnecessary to keep\nall postings in an inverted list I(ti), because users will not look at\nmost of the documents in the list anyway. We depict the conceptual\ndiagram of the document pruning policy in Figure 4. In the figure,\nwe vertically prune postings corresponding to D4, D5 and D6 of\nt1 and D8 of t3, assuming that these documents are unlikely to be\npart of top-k answers to user queries. Again, our goal is to develop\na pruning policy such that (1) we can compute the correctness \nindicator function C from IP alone and (2) we can handle the largest\nfraction of queries with IP . In the next few sections, we discuss a\nfew alternative approaches for document pruning.\n4.3.1 Global PR-based pruning\nWe first investigate the pruning policy that is commonly used by\nexisting search engines. The basic idea for this pruning policy is\nthat the query-independent quality score pr(D) is a very important\nfactor in computing the final ranking of the document (e.g. \nPageRank is known to be one of the most important factors determining\nthe overall ranking in the search results), so we build the p-index\nby keeping only those documents whose pr values are high (i.e.,\npr(D) > \u00cf\u201ep for a threshold value \u00cf\u201ep). The hope is that most of\nthe top-ranked results are likely to have high pr(D) values, so the\nanswer computed from this p-index is likely to be similar to the \nanswer computed from the full index. Figure 7 describes this pruning\npolicy more formally, where we sort all documents Di\"s by their\nrespective pr(Di) values and keep a Di in the p-index when its\nAlgorithm 4.4 Local document pruning V SL\nN: maximum size of a single posting list\nProcedure\n(1) Foreach I(ti) \u00e2\u02c6\u02c6 IF\n(2) Sort Di\"s in I(ti) based on pr(Di)\n(3) If |I(ti)| \u00e2\u2030\u00a4 N Then keep all Di\"s\n(4) Else keep the top-N Di\"s with the highest pr(Di)\nFigure 8: Local document pruning based on pr.\nAlgorithm 4.5 Extended keyword-specific document pruning\nProcedure\n(1) For each I(ti)\n(2) Keep D \u00e2\u02c6\u02c6 I(ti) if pr(D) > \u00cf\u201epi or tr(D, ti) > \u00cf\u201eti\nFigure 9: Extended keyword-specific document pruning based\non pr and tr.\npr(Di) value is higher than the global threshold value \u00cf\u201ep. We refer\nto this pruning policy as global PR-based pruning (GPR).\nVariations of this pruning policy are possible. For example, we\nmay adjust the threshold value \u00cf\u201ep locally for each inverted list\nI(ti), so that we maintain at least a certain number of postings\nfor each inverted list I(ti). This policy is shown in Figure 8. We\nrefer to this pruning policy as local PR-based pruning (LPR). \nUnfortunately, the biggest shortcoming of this policy is that we can\nprove that we cannot compute the correctness function C from IP\nalone when IP is constructed this way.\nTheorem 3 No PR-based document pruning can provide the result\nguarantee. 2\nProof Assume we create IP based on the GPR policy \n(generalizing the proof to LPR is straightforward) and that every \ndocument D with pr(D) > \u00cf\u201ep is included in IP . Assume that the\nkth\nentry in the top-k results, has a ranking score of r(Dk, q) =\nfr(tr(Dk, q), pr(Dk)). Now consider another document Dj that\nwas pruned from IP because pr(Dj) < \u00cf\u201ep. Even so, it is still\npossible that the document\"s tr(Dj, q) value is very high such that\nr(Dj, q) = fr(tr(Dj, q), pr(Dj)) > r(Dk, q).\nTherefore, under a PR-based pruning policy, the quality of the \nanswer computed from IP can be significantly worse than that from\nIF and it is not possible to detect this degradation without \ncomputing the answer from IF . In the next section, we propose simple yet\nessential changes to this pruning policy that allows us to compute\nthe correctness function C from IP alone.\n4.3.2 Extended keyword-specific pruning\nThe main problem of global PR-based document pruning \npolicies is that we do not know the term-relevance score tr(D, ti) of\nthe pruned documents, so a document not in IP may have a higher\nranking score than the ones returned from IP because of their high\ntr scores.\nHere, we propose a new pruning policy, called extended\nkeyword-specific document pruning (EKS), which avoids this \nproblem by pruning not just based on the query-independent pr(D)\nscore but also based on the term-relevance tr(D, ti) score. That\nis, for every inverted list I(ti), we pick two threshold values, \u00cf\u201epi\nfor pr and \u00cf\u201eti for tr, such that if a document D \u00e2\u02c6\u02c6 I(ti) satisfies\npr(D) > \u00cf\u201epi or tr(D, ti) > \u00cf\u201eti, we include it in I(ti) of IP .\nOtherwise, we prune it from IP . Figure 9 formally describes this\nalgorithm. The threshold values, \u00cf\u201epi and \u00cf\u201eti, may be selected in\na number of different ways. For example, if pr and tr have equal\nweight in the final ranking and if we want to keep at most N \npostings in each inverted list I(ti), we may want to set the two \nthreshold values equal to \u00cf\u201ei (\u00cf\u201epi = \u00cf\u201eti = \u00cf\u201ei) and adjust \u00cf\u201ei such that N\npostings remain in I(ti).\nThis new pruning policy, when combined with a monotonic \nscoring function, enables us to compute the correctness indicator \nfunction C from the pruned index. We use the following example to\nexplain how we may compute C.\nExample 4 Consider the query q = {t1, t2} and a monotonic\nranking function, f(pr(D), tr(D, t1), tr(D, t2)). There are three\npossible scenarios on how a document D appears in the pruned\nindex IP .\n1. D appears in both I(t1) and I(t2) of IP : Since complete\ninformation of D appears in IP , we can compute the exact\nAlgorithm 4.6 Computing Answer from IP\nInput Query q = {t1, . . . , tw}\nOutput A: top-k result, C: correctness indicator function\nProcedure\n(1) For each Di \u00e2\u02c6\u02c6 I(t1) \u00e2\u02c6\u00aa \u00c2\u00b7 \u00c2\u00b7 \u00c2\u00b7 \u00e2\u02c6\u00aa I(tw)\n(2) For each tm \u00e2\u02c6\u02c6 q\n(3) If Di \u00e2\u02c6\u02c6 I(tm)\n(4) tr\u00e2\u02c6\u2014(Di, tm) = tr(Di, tm)\n(5) Else\n(6) tr\u00e2\u02c6\u2014(Di, tm) = \u00cf\u201etm\n(7) f(Di) = f(pr(Di), tr\u00e2\u02c6\u2014(Di, t1), . . . , tr\u00e2\u02c6\u2014(Di, tn))\n(8) A = top-k Di\"s with highest f(Di) values\n(9) C =\nj\n1 if all Di \u00e2\u02c6\u02c6 A appear in all I(ti), ti \u00e2\u02c6\u02c6 q\n0 otherwise\nFigure 10: Ranking based on thresholds tr\u00cf\u201e (ti) and pr\u00cf\u201e (ti).\nscore of D based on pr(D), tr(D, t1) and tr(D, t2) values\nin IP : f(pr(D), tr(D, t1), tr(D, t2)).\n2. D appears only in I(t1) but not in I(t2): Since D does\nnot appear in I(t2), we do not know tr(D, t2), so we \ncannot compute its exact ranking score. However, from our\npruning criteria, we know that tr(D, t2) cannot be larger\nthan the threshold value \u00cf\u201et2. Therefore, from the \nmonotonicity of f (Definition 2), we know that the ranking score\nof D, f(pr(D), tr(D, t1), tr(D, t2)), cannot be larger than\nf(pr(D), tr(D, t1), \u00cf\u201et2).\n3. D does not appear in any list: Since D does not appear\nat all in IP , we do not know any of the pr(D), tr(D, t1),\ntr(D, t2) values. However, from our pruning criteria, we\nknow that pr(D) \u00e2\u2030\u00a4 \u00cf\u201ep1 and \u00e2\u2030\u00a4 \u00cf\u201ep2 and that tr(D, t1) \u00e2\u2030\u00a4 \u00cf\u201et1\nand tr(D, t2) \u00e2\u2030\u00a4 \u00cf\u201et2. Therefore, from the monotonicity of f,\nwe know that the ranking score of D, cannot be larger than\nf(min(\u00cf\u201ep1, \u00cf\u201ep2), \u00cf\u201et1, \u00cf\u201et2). 2\nThe above example shows that when a document does not appear\nin one of the inverted lists I(ti) with ti \u00e2\u02c6\u02c6 q, we cannot compute\nits exact ranking score, but we can still compute its upper bound\nscore by using the threshold value \u00cf\u201eti for the missing values. This\nsuggests the algorithm in Figure 10 that computes the top-k result\nA from IP together with the correctness indicator function C. In\nthe algorithm, the correctness indicator function C is set to one only\nif all documents in the top-k result A appear in all inverted lists\nI(ti) with ti \u00e2\u02c6\u02c6 q, so we know their exact score. In this case,\nbecause these documents have scores higher than the upper bound\nscores of any other documents, we know that no other documents\ncan appear in the top-k. The following theorem formally proves the\ncorrectness of the algorithm. In [11] Fagin et al., provides a similar\nproof in the context of multimedia middleware.\nTheorem 4 Given an inverted index IP pruned by the algorithm\nin Figure 9, a query q = {t1, . . . , tw} and a monotonic ranking\nfunction, the top-k result from IP computed by Algorithm 4.6 is the\nsame as the top-k result from IF if C = 1. 2\nProof Let us assume Dk is the kth\nranked document computed\nfrom IP according to Algorithm 4.6. For every document Di \u00e2\u02c6\u02c6\nIF that is not in the top-k result from IP , there are two possible\nscenarios:\nFirst, Di is not in the final answer because it was pruned from\nall inverted lists I(tj), 1 \u00e2\u2030\u00a4 j \u00e2\u2030\u00a4 w, in IP . In this case, we know\nthat pr(Di) \u00e2\u2030\u00a4 min1\u00e2\u2030\u00a4j\u00e2\u2030\u00a4w\u00cf\u201epj < pr(Dk) and that tr(Di, tj) \u00e2\u2030\u00a4\n\u00cf\u201etj < tr(Dk, tj), 1 \u00e2\u2030\u00a4 j \u00e2\u2030\u00a4 w. From the monotonicity assumption,\nit follows that the ranking score of DI is r(Di) < r(Dk). That is,\nDi\"s score can never be larger than that of Dk.\nSecond, Di is not in the answer because Di is pruned from some\ninverted lists, say, I(t1), . . . , I(tm), in IP . Let us assume \u00c2\u00afr(Di) =\nf(pr(Di),\u00cf\u201et1,. . . ,\u00cf\u201etm,tr(Di, tm+1),. . . ,tr(Di, tw)). Then, from\ntr(Di, tj) \u00e2\u2030\u00a4 \u00cf\u201etj(1 \u00e2\u2030\u00a4 j \u00e2\u2030\u00a4 m) and the monotonicity assumption,\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nFractionofqueriesguaranteed\u00e2\u02c6\u2019f(s)\nFraction of index \u00e2\u02c6\u2019 s\nFraction of queries guaranteed per fraction of index\nqueries guaranteed\nFigure 11: Fraction of guaranteed queries f(s) answered in a\nkeyword-pruned p-index of size s.\nwe know that r(Di) \u00e2\u2030\u00a4 \u00c2\u00afr(Di). Also, Algorithm 4.6 sets C =\n1 only when the top-k documents have scores larger than \u00c2\u00afr(Di).\nTherefore, r(Di) cannot be larger than r(Dk).\n5. EXPERIMENTAL EVALUATION\nIn order to perform realistic tests for our pruning policies, we\nimplemented a search engine prototype. For the experiments in this\npaper, our search engine indexed about 130 million pages, crawled\nfrom the Web during March of 2004. The crawl started from the\nOpen Directory\"s [10] homepage and proceeded in a breadth-first\nmanner. Overall, the total uncompressed size of our crawled Web\npages is approximately 1.9 TB, yielding a full inverted index IF of\napproximately 1.2 TB.\nFor the experiments reported in this section we used a real set\nof queries issued to Looksmart [22] on a daily basis during April\nof 2003. After keeping only the queries containing keywords that\nwere present in our inverted index, we were left with a set of about\n462 million queries. Within our query set, the average number of\nterms per query is 2 and 98% of the queries contain at most 5 terms.\nSome experiments require us to use a particular ranking \nfunction. For these, we use the ranking function similar to the one used\nin [20]. More precisely, our ranking function r(D, q) is\nr(D, q) = prnorm(D) + trnorm(D, q) (3)\nwhere prnorm(D) is the normalized PageRank of D computed\nfrom the downloaded pages and trnorm(D, q) is the normalized\nTF.IDF cosine distance of D to q. This function is clearly simpler\nthan the real functions employed by commercial search engines,\nbut we believe for our evaluation this simple function is adequate,\nbecause we are not studying the effectiveness of a ranking function,\nbut the effectiveness of pruning policies.\n5.1 Keyword pruning\nIn our first experiment we study the performance of the keyword\npruning, described in Section 4.2. More specifically, we apply\nthe algorithm HS of Figure 6 to our full index IF and create a\nkeyword-pruned p-index IP of size s. For the construction of our\nkeyword-pruned p-index we used the query frequencies observed\nduring the first 10 days of our data set. Then, using the remaining\n20-day query load, we measured f(s), the fraction of queries \nhandled by IP . According to the algorithm of Figure 5, a query can be\nhandled by IP (i.e., C = 1) if IP includes the inverted lists for all\nof the query\"s keywords.\nWe have repeated the experiment for varying values of s, \npicking the keywords greedily as discussed in Section 4.2.The result is\nshown in Figure 11. The horizontal axis denotes the size s of the\np-index as a fraction of the size of IF . The vertical axis shows the\nfraction f(s) of the queries that the p-index of size s can answer.\nThe results of Figure 11, are very encouraging: we can answer a\nsignificant fraction of the queries with a small fraction of the \noriginal index. For example, approximately 73% of the queries can be\nanswered using 30% of the original index. Also, we find that when\nwe use the keyword pruning policy only, the optimal index size is\ns = 0.17.\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\nFractionofqueriesguaranteed-f(s)\nFraction of index - s\nFraction of queries guaranteed for top-20 per fraction of index\nfraction of queries guaranteed (EKS)\nFigure 12: Fraction of guaranteed queries f(s) answered in a\ndocument-pruned p-index of size s.\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\nFractionofqueriesanswered\nindex size - s\nFraction of queries answered for top-20 per fraction of index\nGPR\nLPR\nEKS\nFigure 13: Fraction of queries answered in a document-pruned\np-index of size s.\n5.2 Document pruning\nWe continue our experimental evaluation by studying the \nperformance of the various document pruning policies described in \nSection 4.3. For the experiments on document pruning reported here\nwe worked with a 5.5% sample of the whole query set. The reason\nbehind this is merely practical: since we have much less machines\ncompared to a commercial search engine it would take us about a\nyear of computation to process all 462 million queries.\nFor our first experiment, we generate a document-pruned p-index\nof size s by using the Extended Keyword-Specific pruning (EKS)\nin Section 4. Within the p-index we measure the fraction of queries\nthat can be guaranteed (according to Theorem 4) to be correct. We\nhave performed the experiment for varying index sizes s and the\nresult is shown in Figure 12. Based on this figure, we can see that\nour document pruning algorithm performs well across the scale of\nindex sizes s: for all index sizes larger than 40%, we can guarantee\nthe correct answer for about 70% of the queries. This implies that\nour EKS algorithm can successfully identify the necessary \npostings for calculating the top-20 results for 70% of the queries by\nusing at least 40% of the full index size. From the figure, we can\nsee that the optimal index size s = 0.20 when we use EKS as our\npruning policy.\nWe can compare the two pruning schemes, namely the keyword\npruning and EKS, by contrasting Figures 11 and 12. Our \nobservation is that, if we would have to pick one of the two pruning\npolicies, then the two policies seem to be more or less equivalent\nfor the p-index sizes s \u00e2\u2030\u00a4 20%. For the p-index sizes s > 20%,\nkeyword pruning does a much better job as it provides a higher\nnumber of guarantees at any given index size. Later in Section 5.3,\nwe discuss the combination of the two policies.\nIn our next experiment, we are interested in comparing EKS\nwith the PR-based pruning policies described in Section 4.3. To\nthis end, apart from EKS, we also generated document-pruned \npindexes for the Global pr-based pruning (GPR) and the Local \nprbased pruning (LPR) policies. For each of the polices we created\ndocument-pruned p-indexes of varying sizes s. Since GPR and\nLPR cannot provide a correctness guarantee, we will compare the\nfraction of queries from each policy that are identical (i.e. the same\nresults in the same order) to the top-k results calculated from the\nfull index. Here, we will report our results for k = 20; the results\nare similar for other values of k. The results are shown in Figure 13.\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\nAveragefractionofdocsinanswer\nindex size - s\nAverage fraction of docs in answer for top-20 per fraction of index\nGPR\nLPR\nEKS\nFigure 14: Average fraction of the top-20 results of p-index with\nsize s contained in top-20 results of the full index.\nFraction of queries guaranteed for top-20 per fraction of index, using keyword and document\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nKeyword fraction\nof index - sh\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nDocument fraction\nof index - sv\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nFraction of queries\nguaranteed - f(s)\nFigure 15: Combining keyword and document pruning.\nThe horizontal axis shows the size s of the p-index; the vertical\naxis shows the fraction f(s) of the queries whose top-20 results are\nidentical to the top-20 results of the full index, for a given size s.\nBy observing Figure 13, we can see that GPR performs the\nworst of the three policies. On the other hand EKS, picks up early,\nby answering a great fraction of queries (about 62%) correctly with\nonly 10% of the index size. The fraction of queries that LPR can\nanswer remains below that of EKS until about s = 37%. For any\nindex size larger than 37%, LPR performs the best.\nIn the experiment of Figure 13, we applied the strict definition\nthat the results of the p-index have to be in the same order as the\nones of the full index. However, in a practical scenario, it may\nbe acceptable to have some of the results out of order. Therefore,\nin our next experiment we will measure the fraction of the results\ncoming from an p-index that are contained within the results of the\nfull index. The result of the experiment is shown on Figure 14. The\nhorizontal axis is, again, the size s of the p-index; the vertical axis\nshows the average fraction of the top-20 results common with the\ntop-20 results from the full index. Overall, Figure 14 depicts that\nEKS and LPR identify the same high (\u00e2\u2030\u02c6 96%) fraction of results\non average for any size s \u00e2\u2030\u00a5 30%, with GPR not too far behind.\n5.3 Combining keyword and document\npruning\nIn Sections 5.1 and 5.2 we studied the individual performance\nof our keyword and document pruning schemes. One interesting\nquestion however is how do these policies perform in \ncombination? What fraction of queries can we guarantee if we apply both\nkeyword and document pruning in our full index IF ?\nTo answer this question, we performed the following experiment.\nWe started with the full index IF and we applied keyword pruning\nto create an index Ih\nP of size sh \u00c2\u00b7 100% of IF . After that, we\nfurther applied document pruning to Ih\nP , and created our final \npindex IP of size sv \u00c2\u00b7100% of Ih\nP . We then calculated the fraction of\nguaranteed queries in IP . We repeated the experiment for different\nvalues of sh and sv. The result is shown on Figure 15. The x-axis\nshows the index size sh after applying keyword pruning; the y-axis\nshows the index size sv after applying document pruning; the z-axis\nshows the fraction of guaranteed queries after the two prunings. For\nexample the point (0.2, 0.3, 0.4) means that if we apply keyword\npruning and keep 20% of IF , and subsequently on the resulting\nindex we apply document pruning keeping 30% (thus creating a \npindex of size 20%\u00c2\u00b730% = 6% of IF ) we can guarantee 40% of the\nqueries. By observing Figure 15, we can see that for p-index sizes\nsmaller than 50%, our combined pruning does relatively well. For\nexample, by performing 40% keyword and 40% document pruning\n(which translates to a pruned index with s = 0.16) we can provide\na guarantee for about 60% of the queries. In Figure 15, we also\nobserve a plateau for sh > 0.5 and sv > 0.5. For this combined\npruning policy, the optimal index size is at s = 0.13, with sh =\n0.46 and sv = 0.29.\n6. RELATED WORK\n[3, 30] provide a good overview of inverted indexing in Web\nsearch engines and IR systems. Experimental studies and analyses\nof various partitioning schemes for an inverted index are presented\nin [6, 23, 33]. The pruning algorithms that we have presented in\nthis paper are independent of the partitioning scheme used.\nThe works in [1, 5, 7, 20, 27] are the most related to ours, as they\ndescribe pruning techniques based on the idea of keeping the \npostings that contribute the most in the final ranking. However, [1, 5, 7,\n27] do not consider any query-independent quality (such as \nPageRank) in the ranking function. [32] presents a generic framework\nfor computing approximate top-k answers with some probabilistic\nbounds on the quality of results. Our work essentially extends [1,\n2, 4, 7, 20, 27, 31] by proposing mechanisms for providing the\ncorrectness guarantee to the computed top-k results.\nSearch engines use various methods of caching as a means of \nreducing the cost associated with queries [18, 19, 21, 31]. This thread\nof work is also orthogonal to ours because a caching scheme may\noperate on top of our p-index in order to minimize the answer \ncomputation cost. The exact ranking functions employed by current\nsearch engines are closely guarded secrets. In general, however,\nthe rankings are based on query-dependent relevance and \nqueryindependent document quality. Query-dependent relevance can\nbe calculated in a variety of ways (see [3, 30]). Similarly, there are a\nnumber of works that measure the quality of the documents, \ntypically as captured through link-based analysis [17, 28, 26]. Since\nour work does not assume a particular form of ranking function, it\nis complementary to this body of work.\nThere has been a great body of work on top-k result calculation.\nThe main idea is to either stop the traversal of the inverted lists\nearly, or to shrink the lists by pruning postings from the lists [14,\n4, 11, 8]. Our proof for the correctness indicator function was \nprimarily inspired by [12].\n7. CONCLUDING REMARKS\nWeb search engines typically prune their large-scale inverted \nindexes in order to scale to enormous query loads. While this \napproach may improve performance, by computing the top results\nfrom a pruned index we may notice a significant degradation in\nthe result quality. In this paper, we provided a framework for\nnew pruning techniques and answer computation algorithms that\nguarantee that the top matching pages are always placed at the\ntop of search results in the correct order. We studied two pruning\ntechniques, namely keyword-based and document-based pruning as\nwell as their combination. Our experimental results demonstrated\nthat our algorithms can effectively be used to prune an inverted\nindex without degradation in the quality of results. In particular, a\nkeyword-pruned index can guarantee 73% of the queries with a size\nof 30% of the full index, while a document-pruned index can \nguarantee 68% of the queries with the same size. When we combine the\ntwo pruning algorithms we can guarantee 60% of the queries with\nan index size of 16%. It is our hope that our work will help search\nengines develop better, faster and more efficient indexes and thus\nprovide for a better user search experience on the Web.\n8. REFERENCES\n[1] V. N. Anh, O. de Kretser, and A. Moffat. Vector-space ranking with\neffective early termination. In SIGIR, 2001.\n[2] V. N. Anh and A. Moffat. Pruning strategies for mixed-mode\nquerying. In CIKM, 2006.\n[3] R. A. Baeza-Yates and B. A. Ribeiro-Neto. Modern Information\nRetrieval. ACM Press / Addison-Wesley, 1999.\n[4] N. Bruno, L. Gravano, and A. Marian. Evaluating top-k queries over\nweb-accessible databases. In ICDE, 2002.\n[5] S. B\u00c2\u00a8uttcher and C. L. A. Clarke. A document-centric approach to\nstatic index pruning in text retrieval systems. In CIKM, 2006.\n[6] B. Cahoon, K. S. McKinley, and Z. Lu. Evaluating the performance\nof distributed architectures for information retrieval using a variety of\nworkloads. ACM TOIS, 18(1), 2000.\n[7] D. Carmel, D. Cohen, R. Fagin, E. Farchi, M. Herscovici, Y. Maarek,\nand A. Soffer. Static index pruning for information retrieval systems.\nIn SIGIR, 2001.\n[8] S. Chaudhuri and L. Gravano. Optimizing queries over multimedia\nrepositories. In SIGMOD, 1996.\n[9] T. H. Cormen, C. E. Leiserson, and R. L. Rivest. Introduction to\nAlgorithms, 2nd Edition. MIT Press/McGraw Hill, 2001.\n[10] Open directory. http://www.dmoz.org.\n[11] R. Fagin. Combining fuzzy information: an overview. In SIGMOD\nRecord, 31(2), 2002.\n[12] R. Fagin, A. Lotem, and M. Naor. Optimal aggregation algorithms\nfor middleware. In PODS, 2001.\n[13] A. Gulli and A. Signorini. The indexable web is more than 11.5\nbillion pages. In WWW, 2005.\n[14] U. Guntzer, G. Balke, and W. Kiessling. Towards efficient\nmulti-feature queries in heterogeneous environments. In ITCC, 2001.\n[15] Z. Gy\u00c2\u00a8ongyi, H. Garcia-Molina, and J. Pedersen. Combating web\nspam with trustrank. In VLDB, 2004.\n[16] B. J. Jansen and A. Spink. An analysis of web documents retrieved\nand viewed. In International Conf. on Internet Computing, 2003.\n[17] J. Kleinberg. Authoritative sources in a hyperlinked environment.\nJournal of the ACM, 46(5):604-632, September 1999.\n[18] R. Lempel and S. Moran. Predictive caching and prefetching of query\nresults in search engines. In WWW, 2003.\n[19] R. Lempel and S. Moran. Optimizing result prefetching in web search\nengines with segmented indices. ACM Trans. Inter. Tech., 4(1), 2004.\n[20] X. Long and T. Suel. Optimized query execution in large search\nengines with global page ordering. In VLDB, 2003.\n[21] X. Long and T. Suel. Three-level caching for efficient query\nprocessing in large web search engines. In WWW, 2005.\n[22] Looksmart inc. http://www.looksmart.com.\n[23] S. Melnik, S. Raghavan, B. Yang, and H. Garcia-Molina. Building a\ndistributed full-text index for the web. ACM TOIS, 19(3):217-241,\n2001.\n[24] A. Ntoulas, J. Cho, C. Olston. What\"s new on the web? The evolution\nof the web from a search engine perspective. In WWW, 2004.\n[25] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly. Detecting spam\nweb pages through content analysis. In WWW, 2006.\n[26] L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank\ncitation ranking: Bringing order to the web. Technical report,\nStanford University.\n[27] M. Persin, J. Zobel, and R. Sacks-Davis. Filtered document retrieval\nwith frequency-sorted indexes. Journal of the American Society of\nInformation Science, 47(10), 1996.\n[28] M. Richardson and P. Domingos. The intelligent surfer: Probabilistic\ncombination of link and content information in pagerank. In\nAdvances in Neural Information Processing Systems, 2002.\n[29] S. Robertson and K. Sp\u00c2\u00a8arck-Jones. Relevance weighting of search\nterms. Journal of the American Society for Information Science,\n27:129-46, 1976.\n[30] G. Salton and M. J. McGill. Introduction to modern information\nretrieval. McGraw-Hill, first edition, 1983.\n[31] P. C. Saraiva, E. S. de Moura, N. Ziviani, W. Meira, R. Fonseca, and\nB. Riberio-Neto. Rank-preserving two-level caching for scalable\nsearch engines. In SIGIR, 2001.\n[32] M. Theobald, G. Weikum, and R. Schenkel. Top-k query evaluation\nwith probabilistic guarantees. In VLDB, 2004.\n[33] A. Tomasic and H. Garcia-Molina. Performance of inverted indices\nin shared-nothing distributed text document information retrieval\nsystems. In Parallel and Distributed Information Systems, 1993.\n": ["web search engine", "large-scale inverted index", "query load", "pruned index", "online search market", "degradation of result quality", "result quality degradation", "pruning-based performance optimization", "pruning technique", "result computation algorithm", "top-matching page", "top search result", "optimal size", "pruned index", "invert index", "prune", "correctness guarantee", ""]}