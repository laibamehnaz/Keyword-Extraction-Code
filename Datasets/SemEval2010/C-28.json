{"PackageBLAST: An Adaptive Multi-Policy Grid Service for\nBiological Sequence Comparison\n\u00e2\u02c6\u2014\nMarcelo S. Sousa\nUniversity of Brasilia\nCampus UNB - ICC Norte, sub-solo\nBrasilia, Brazil\nmsousa@unb.br\nAlba Cristina M. A. Melo\nUniversity of Brasilia\nCampus UNB - ICC Norte, sub-solo\nBrasilia, Brazil\nalves@unb.br\nABSTRACT\nIn this paper, we propose an adaptive task allocation \nframework to perform BLAST searches in a grid environment\nagainst sequence database segments. The framework, called\nPackageBLAST, provides an infrastructure to choose or \nincorporate task allocation strategies. Furthermore, we \npropose a mechanism to compute grid nodes execution weight,\nadapting the chosen allocation policy to the current \ncomputational power of the nodes. Our results present very good\nspeedups and also show that no single allocation strategy is\nable to achieve the lowest execution times for all scenarios.\nCategories and Subject Descriptors\nC.2.4 [Distributed Systems]: Distributed Applications;\nJ.3 [Life and Medical Sciences]: Biology and Genetics\n1. INTRODUCTION\nBiological sequence comparison (or sequence alignment)\nis one of the most important problems in computational \nbiology, given the number and diversity of the sequences and\nthe frequency on which it is needed to be solved daily.\nSW [14] is an exact algorithm that finds the best local\nalignment between two sequences of size n in quadratic time\nand space. In genome projects, the size of the sequences to\nbe compared is constantly increasing, thus an O(n2\n) solution\nis expensive. For this reason, heuristics like BLAST [3] were\nproposed to reduce execution time.\nThe popularity of the Internet made possible the \ninterconnection of millions of powerful machines in a global scale.\nThis led to the idea of grid computing, which involves \ncooperative and secure sharing of non-dedicated and \nheterogeneous resources that are geographically distributed [5].\nResource scheduling is one of the most important \ncomponents of a grid system. The choice of the best resources for\na particular application is called task allocation, which is\nan NP-Complete problem. Grid applications usually do not\nhave high communication rates and many of them follow the\nmaster/slave model [13]. In order to schedule master/slave\napplications many task allocation policies were proposed\nsuch as Self Scheduling [15] and FAC2 [8]. The choice of\nthe best allocation policy depends on the application access\npattern and on the environment in which it runs [13].\nIn this paper, we propose PackageBLAST, an adaptive\nmulti-policy grid service to run BLAST searches in grids\ncomposed by segmented genetic databases. PackageBLAST\nexecutes on Globus 3 [4] and, by now, provides five allocation\npolicies. Also, we propose an adaptive mechanism to assign\nweights to the grid nodes, taking into account their current\nworkload. As far as we know, this is the first grid service that\nruns BLAST with multiple task policies with a segmented\ndatabase in a heterogeneous non-dedicated platform.\nThis paper is organized as follows. Section 2 presents the\nsequence comparison problem and the BLAST algorithm.\nSection 3 describes allocation policies for grids. Section\n4 discusses related work. Section 5 presents the design of\nPackageBLAST. Experimental results are discussed in \nsection 6. Section 7 concludes the paper.\n2. SEQUENCE COMPARISON\nTo compare two sequences, we must find the best \nalignment, which is to place one sequence above the other making\nclear the correspondence between similar characters [7].\nGiven an alignment between two sequences, a score is \nusually associated for it as follows (figure 1). For each column,\nwe associate, for instance, +1 if the two characters are \nidentical, -1 if the characters are different and -2 if one of them\nis a space. The score is the sum of all the values and the\nmaximal score is the similarity between the sequences.\nTo compute exact local sequence alignments, [14] \nproposed an algorithm (SW), based on dynamic programming,\nwith quadratic time and space complexity.\nUsually, one given biological sequence is compared against\nthousands or even millions of sequences that compose \ngenetic data banks. By now, there are millions of entries \ncomposed of billions of nucleotides at GenBank, which is one\nof the most important public gene repositories. Due to the\n156\nG A C G G A T T A G\nG A T C G G A A T A G\n+1 +1 \u00e2\u02c6\u20192 +1 +1 +1 +1 \u00e2\u02c6\u20191 +1 +1 +1\n\u00ce\u00a3 = 6\nFigure 1: Example of an alignment with score 6\ncurrent growth rate, these databases will soon achieve \nterabytes.\nIn this scenario, the use of exact methods such as SW is\nprohibitive. For this reason, faster heuristic methods are\nproposed which do not guarantee that the best alignment\nwill be produced. Usually, these heuristic methods are \nevaluated using the concepts of sensitivity and sensibility. \nSensitivity is the rate at which the method fails to identify similar\nsequences whereas sensibility is the rate at which the method\nidentifies sequences that are not similar [7]. BLAST [1] is the\nmost widely used heuristic method for sequence comparison.\n2.1 The BLAST Algorithm\nBLAST (Basic Local Alignment Tool) [1] is a set of \nprograms used to search DNA and protein databases for \nsimilarities between sequences. It is designed to obtain high \nperformance with low impact in terms of sensibility. BLAST\nprovides programs to compare many combinations of query\nand database sequence types (table 1).\nTable 1: Some of the BLAST family programs\nProgram Database Query Translation\nBLASTN Nucleotide Nucleotide None\nBLASTP Protein Protein None\nBLASTX Protein Nucleotide Query\nThe first version of BLAST searched for local similarities\nwithout taking spaces (gaps) into account. In 1996-1997,\ntwo gapped versions of BLAST emerged: NCBI-BLAST [3]\nand WU-BLAST [6].\nBasically, the algorithm proceeds in three steps: seeding,\nextension and evaluation. In the seeding step, a query \nsequence is split in portions called words of size W. These\nwords are matched to database sequences and used as \nalignment seeds if their scores are higher than a threshold T.\nIn the extension step, alignments are generated from seeds.\nA parameter X maintains the recent alignment history and\ncontrols this step. Once seeds are extended, the last step\nbegins. The alignments are evaluated to determine if they\nare statistically significant. The significant ones are termed\nHSPs (High-scoring Segment Pairs). A new parameter, S,\nis used to sort alignments. The combination of parameters\nW, T, X and S is used to determine the sensitivity and\nspeed of BLAST searches.\n3. TASK ALLOCATION FOR GRIDS\n3.1 Grid Computing\nGrid Computing was initially developed to enable resource\nsharing between scientific institutions who needed to share\ndata, software and computational power. The Globus Toolkit\n[4] emerged as an open source project and quickly became a\nde facto standard for grid computing infrastructure. Globus\nimplements a set of protocols, APIs and services used by\nhundreds of grid applications all over the world.\nIn 2002, the Open Grid Services Architecture (OGSA)\nwas introduced by the Global Grid Forum (GGF) to expand\nstandardization. OGSA provided a new architecture for grid\napplications based on web services in order to achieve \ninteroperability using industry standards. Many OGSA \narchitecture implementations were developed, including one for\nGlobus. The work carried out in this paper is deployed on\na grid based on Globus (GT3).\nUsually, grid applications are modelled as master/slave,\nwhere one problem is divided in many independent work\nunits (tasks) of smaller size that can be distributed to slave\nnodes for parallel processing.\nA very important problem to be solved in this context\nis task allocation. The task allocation problem consists of\nassigning tasks to processors in order to maximize system\nperformance [13]. In this problem, it is assumed that no\nprecedence relations exist among the tasks.\n3.2 Task Allocation Strategies\nGiven a master/slave application composed by a master\nm and S slaves, the allocation function allocate(m, si, N, S)\ndetermines how many tasks out of N must be assigned to\na slave si (equation 1), where A(N, S) represents an \nallocation policy. WeightFactor(m, si, S) was defined by [13]\n(equation 2) and provides weights for each slave si, based\non its statically known processing rate (WorkerRate).\nallocate(m, si, N, S) = A(N, S) \u00e2\u02c6\u2014 W eightF actor(m, si, S) (1)\nW eightF actor(m, si, S) =\nP \u00e2\u02c6\u2014 W orkerRate(m, si)\nP\ni=1 W orkerRate(m, si)\n(2)\nThe following subsections present some work allocation\npolicies, which are instances A(N, S) of equation 1.\n3.3 Fixed (Static Scheduling)\nThe Fixed [13] strategy distributes all work units \nuniformly to slaves nodes. This strategy is appropriate for \nhomogeneous systems with dedicated resources (equation 3).\nA(N, S) =\nN\nS\n(3)\n3.4 Self Scheduling (SS)\nSelf Scheduling (SS) [15] distributes a single work unit to\nevery slave node (equation 4).\nA(N, S) = 1, while work units are still left to allocate (4)\nIn SS, the maximum imbalance is limited by the \nprocessing time of a work unit in the slowest node. Nevertheless,\nSS usually demands a lot of communication, since each work\nunit retrieval requires one interaction with the master.\n3.5 Trapezoidal Self Scheduling (TSS)\nTrapezoidal Self-Scheduling (TSS) [16] allocates work units\nin groups with a linearly decreasing size. This strategy uses\ntwo variables, steps and \u00ce\u00b4, that represent the total number\nof allocation steps and the block reduction factor, \nrespectively (equations 5 and 6).\nsteps =\n4NS\nN + 2S\n(5)\n157\n\u00ce\u00b4 =\nN \u00e2\u02c6\u2019 2S\n2S(steps \u00e2\u02c6\u2019 1)\n(6)\nTSS calculates the length of the sth\nblock using the \ndifference between the length of the first block and total reduction\nfrom the last s \u00e2\u02c6\u2019 1 blocks (equation 7).\nA(s, N, S) = max\nN\n2S\n\u00e2\u02c6\u2019 [(s \u00e2\u02c6\u2019 1) \u00e2\u02c6\u2014 \u00ce\u00b4] , 1 (7)\n3.6 Guided Self Scheduling (GSS)\nGuided Self-Scheduling (GSS) [11] allocates work units\nin groups whose length decrease exponentially. Its goal is\nto create a tradeoff between the number of the work units\nprocessed and the imbalance in finishing times (equation 8).\nA(s, N, S) = max\nN 1 \u00e2\u02c6\u2019 1\nS\ns\u00e2\u02c6\u20191\nS\n, 1 , s > 0 (8)\n3.7 Factoring (FAC2)\nFAC2 allocates work units in cycles consisting of S \nallocation sequences. Equation 9 shows the function that defines\nthe cycle number of an iteration s. In FAC2, half of the\nremaining work units are allocated in each round (equation\n10).\nround(s) =\n(s \u00e2\u02c6\u2019 1)\nS\n+ 1 (9)\nA(s, N, S) = max\nN\nS \u00e2\u02c6\u2014 2round(s)\n, 1 (10)\n4. RELATED WORK\nMpiBLAST [2] was proposed for clusters and has two\nphases. First, the genetic database is segmented. Then, the\nqueries are evenly distributed among the nodes. If the node\ndoes not have a database fragment, a local copy is made. A\nmethod is proposed that associates data fragments to nodes,\ntrying to minimize the number of copies.\nBLAST++ [10] groups multiple sequences to reduce the\nnumber of database accesses. A master/slave approach is\nused that allocates the queries to the slaves according to the\nfixed policy (section 3.3). Each worker executes BLAST++\nindependently and, finally, the results are collected and \ncombined by the master.\nGridBlast [9] is a master/slave grid application that uses\nGlobus 2. It distributes sequences among the grid nodes\nusing two allocation policies: FCFS and minmax. Of those,\nonly the last one takes into account the current load and the\nheterogeneity of the environment. However, to use minmax,\nthe total execution time of each BLAST task must be known.\nHaving decided which sequences will be compared by each\nnode, GridBlast sends the sequences, the executable files and\nthe whole database to the chosen node. When the search\nfinishes, the results are compacted and sent to the master.\nGrid Blast Toolkit (GBTK) [12] is a web portal to execute\nBLAST searches in Globus 3. All genetic databases are \nstatically placed on the grid nodes (without replication). GBTK\nis a master/slave application that receives the sequences and\nthe name of the genetic database. It then verifies if the node\nthat contains the database is available. If so, it is selected.\nIf the node is not available, the less loaded node is chosen\nand the database is copied to it.\nMaster\nSlaveSlaveSlave\nInternet\ndatabase\nsegment\nbut only part of it is processed in each node\nThe database is replicated in the nodes,\nFigure 2: PackageBLAST segmentation and \ndistribution mechanism.\n5. DESIGN OF PACKAGEBLAST\nWe propose an adaptive task allocation framework which\nis a grid service to perform BLAST searches against \nsequence database segments. The framework, called \nPackageBLAST, provides an infrastructure to choose or incorporate\nallocation strategies in a master/slave application. We also\npropose a strategy to compute grid nodes execution weight\nwhich distributes work units (database segments) to grid\nnodes according to their current computational power.\n5.1 Database Segmentation and Replication\nSegmentation consists in the division of a database archive\nin many portions of smaller size, called segments, that can\nbe processed independently. It enables grid nodes to search\nsmaller parts of a sequence database, reducing the number\nof disk accesses and hence improving BLAST performance.\nAlso, a single query sequence can be compared against all\nsegments in parallel. Just as in mpiBLAST (section 4),\nwe decided to use database segmentation in PackageBLAST\nwith an NCBI tool called formatdb, which was modified to\ngenerate more database segments of smaller size.\nWe opted to replicate the segmented database in every\nslave grid node to improve data accesses times and to \nprovide a potential for fault tolerance. Figure 2 illustrates this.\n5.2 Task Allocation\nAs [13], we think that no allocation policy will produce\nthe best results for every situation. Thus, we propose the\nuse of a framework where many allocation policies can be \nincorporated. By now, our framework contains five allocation\npolicies: Fixed, SS, GSS, TSS, FAC2, all described in \nsection 3. So, the user can choose or even create the allocation\npolicy which is the most appropriate to his/her environment\nand his/her BLAST parameters.\nBesides that, we propose PSS (Package Weighted \nAdaptive Self-Scheduling), a new strategy that adapts the chosen\nallocation policy to a grid with local workload. Considering\nthe heterogeneity and dynamic characteristics of the grid,\nPSS is able to modify the length of the work units during\nexecution, based on average processing time of each node.\nThe expression used for work unit allocation is shown in\nequation 11, where A(N, P) is the allocation policy for a \nsystem with N workload units and P nodes and \u00ce\u00a6(m, pi, P) is\nthe weight calculated by PSS. A(N, P) can be a pre-defined\nallocation policy or a user-defined one.\n158\nallocate(m, pi, N, P ) = A(N, P ) \u00e2\u02c6\u2014 \u00ce\u00a6(m, pi, P ) (11)\nTo distribute database segments to nodes, the master \nanalyzes periodic slave notifications. The expression used is\n\u00ce\u00a6(m, pi, P) (equation 12), defined as the weighted mean\nfrom the last \u00e2\u201e\u00a6 notifications sent by each pi slave node.\n\u00ce\u00a6(m, pi, P ) =\nP \u00e2\u02c6\u2014\nP\ni=1 \u00ce\u201c(m,pi,\u00e2\u201e\u00a6)\n\u00ce\u201c(m,pi,\u00e2\u201e\u00a6)\nP\ni=1\nP\ni=1\n\u00ce\u201c(m,pi,\u00e2\u201e\u00a6)\n\u00ce\u201c(m,pi,\u00e2\u201e\u00a6)\n(12)\n\u00ce\u201c(m, pi, \u00e2\u201e\u00a6) (equation 13) specifies the average computing\ntime of a segment in a node pi, considering the last \u00e2\u201e\u00a6 \nnotifications of TE(m, pi, \u00cf\u201e), which is the average computation\ntime of \u00cf\u201e work units (database segments) assigned by the\nmaster m to a slave pi. At the moment of computation of\n\u00ce\u201c, if there is not enough notifications of TE, the calculation\nis done with total k notifications already received.\n\u00ce\u201c(m, pi, \u00e2\u201e\u00a6) =\nmin(\u00e2\u201e\u00a6,k)\nj=1 T E(m, pi, \u00cf\u201e)\nmin(\u00e2\u201e\u00a6, k)\n(13)\n5.3 PackageBLAST\"s General Architecture\nPackageBLAST was designed as a grid service over Globus\n3, based on Web Services and Java. Figure 3 presents the\nPackageBLAST architecture.\nBLAST\nreceives\nMASTER\nStrategies\nAllocation\nWork units\nGenerate\nWork Units\nDistribute\nReports\nGenerate\nwork units (to slaves)reports\nsearches\nFigure 3: PackageBLAST architecture.\nThe module Allocation Strategies contains \nimplementations for the pre-defined allocation policies (Fixed, SS, GSS,\nTSS and FAC2) and also makes possible the creation of new\nallocation strategies.\nThe module Generate Work Units is the core of the PSS\nmechanism. It calculates the weight of each slave node and\ndecides how many work units will be assigned to a particular\nslave node, according to the chosen allocation policy.\nDistribute Work Units is the module responsible for the\ncommunication between the master and slaves nodes. It\ndistributes the work units generated by the previous module\nand collects the notifications.\nFinally, the module Generate Reports obtains the \nintermediary outputs sent by the slave nodes through file transfer\nand merges them into a single BLAST output report.\nIn general, the following execution flow is executed. The\nuser specifies the sequence to be compared and chooses the\nallocation strategy. The master node starts execution and\nwaits for slave connections. To start processing, a minimum\nnumber of slaves must register into the master node, by \ncalling a master grid service. After receiving connections from\nthe slaves, the master notifies them about their initial \nsegments to compare. The slave processes \u00cf\u201e database segments\nand notifies the master, which uses the last \u00e2\u201e\u00a6 notifications\nto compute the next allocation block size based on the \nselected allocation strategy and the weight provided by PSS.\nThen, the master sends a XML message to the slave \ninforming its new segments to process. This flow continues until\nall segments are processed.\n6. EXPERIMENTAL RESULTS\nPackageBLAST was evaluated in a 16-node grid testbed,\ncomposed by two laboratories, interconnected by a \nlocalarea network. Eleven desktops (P01-11) and a notebook\n(NB) were used in LABPOS and four desktops (L01-04)\nwere used in LAICO (table 2). All grid nodes used Linux\nwith Globus 3.2.1, NCBI BLAST 2.2.10 and Java VM 1.4.2.\nTable 2: Characteristics of the grid testbed.\nNode Names CPU Main Memory HD\nNB 3200 MHz 512 MB 80 GB\nL01-L03 1700 MHz 256 MB 30 GB\nL04 350 MHz 160 MB 6 GB\nP01-P10 1000 MHz 256 MB 20 GB\nP11 900 MHz 128 MB 20 GB\nTo investigate the performance gains of PackageBLAST,\nwe executed BLASTX in 2, 4, 8 and 16 grid nodes. Each\nBLAST search compared a 10KBP real DNA sequence against\nthe 1.2GB nr genetic database segmented in 167 parts of\n5MB each. Fixed, SS, TSS, GSS and FAC2 allocation\nstrategies were employed in the tests. Execution times for\nall allocation strategies are presented in table 3.\nTable 3: Execution times for BLASTX.\nStrategy 2 nodes 4 nodes 8 nodes 16 nodes\nFIXED 2037 999 491 252\nSS 1112 514 246 134\nTSS 1296 570 259 143\nGSS 1115 535 250 127\nFAC2 1187 514 266 142\nTable 4 presents execution times in a single machine and\nabsolute speedups for 2, 4, 8 and 16 nodes, considering the\nbest execution time for a given number of nodes. To \ncalculate the absolute speedups, the BLAST sequential version\nwas executed with the nr unsegmented database.\nTable 4: Sequential execution times and speedups.\nNode SeqTime 2 nodes 4 nodes 8 nodes 16 nodes\nNB 1432 1.29 2.79 5.82 11.28\nL01 1585 1.43 3.08 6.44 12.48\nP01 1853 1.67 3.61 7.53 14.59\nP11 2004 1.80 3.90 8.15 15.78\nL04 3810 3.43 7.41 15.49 30.00\nPackageBLAST achieved very good speedups. \nConsidering the worst (L04), average (P01) and best (NB) node in\nthe grid, the speedups obtained were superlinear, close to\nlinear and sublinear, respectively.\nIn table 3, it can also be noticed that there is no allocation\nstrategy that always reaches the best execution time. This\nvariation justifies the allocation framework provided.\nTo evaluate PSS, we executed PackageBLAST with 16\ngrid nodes, introducing local workload in nodes L01, L02,\nP01 and P02. The load was started simultaneously 30 \nseconds after the beginning of BLAST and consisted of the\n159\nexecution of formatdb on the nr database. Three scenarios\nwere simulated (table 5): 1) with PSS strategy, but without\nworkload; 2) with PSS strategy and workload (PSS 2x), to\nuse grid environment knowledge obtained in the preceeding\niteration; and 3) Execution without PSS and with workload.\nTable 5: PSS evaluation with local workload. Gain\nis the comparison of without PSS with PSS 2x\nStrategy with PSS PSS 2x without PSS Gain\nFixed 316 184 393 113.59%\nSS 186 177 179 1.13%\nTSS 160 162 171 5.56%\nGSS 149 159 339 113.21%\nFAC2 156 165 153 -7.27%\nAs expected, the allocation strategies that assign a large\namount of work to the nodes (fixed and GSS) obtained great\nbenefit from using PSS. This is due to the fact that a slow\nnode can easily become a bottleneck in these strategies. TSS\nalso obtained a reduction of 5.56% in its execution time.\nPSS uses two parameters: \u00cf\u201e and \u00e2\u201e\u00a6 (section 5.2). We \nvaried these parameters in order to evaluate the PSS behavior\nin two scenarios. In both cases, we used a four-node (NB,\nL01, P01, L04) grid. In the first experiment, a local \nworkload (formatdb) was introduced when the last task of the\nfirst TSS allocation starts and was stopped immediately \nafter the processing of one segment. The goal was to evaluate\nthe impact of short-lived local tasks in PSS. In the second\ncase, local workload was introduced at the same time of the\nprevious case, but continued until the end. The goal was to\nevaluate long-lived local tasks. Figure 4 presents the gains.\nFigure 4: Percentual gain obtained by PSS varying\n\u00cf\u201e and \u00e2\u201e\u00a6 parameters.\nIn scenario 1, when a very recent history is considered\n(\u00cf\u201e=1 and \u00e2\u201e\u00a6=1), PSS tries to adapt to a situation that will\nshortly disappear. For \u00cf\u201e=5 and \u00e2\u201e\u00a6=4, PSS takes longer to\nnotice modification and short-lived tasks have low impact.\nOn the other hand, in scenario 2, \u00cf\u201e=1,\u00e2\u201e\u00a6=1 presents better\nresults than \u00cf\u201e=5, \u00e2\u201e\u00a6=4, because it changes weights faster.\n7. CONCLUSION\nIn this article, we proposed and evaluated PackageBLAST,\nan adaptive multi-policy grid service to execute master/slave\nBLAST searches. PackageBLAST contains a framework\nwhere the user can choose or incorporate allocation policies.\nWe also defined a strategy, PSS, that adapts the chosen \npolicy to a heterogeneous non-dedicated grid environment.\nThe results collected by running PackageBLAST with 5\nallocation policies in a grid testbed were very good. In \norder to compare a 10KBP real DNA sequence against the\nnr genetic database, we were able to reduce execution time\nfrom 30.88 min to 2.11 min. Also, we showed that, in our\ntestbed, there is no allocation policy that always achieves\nthe best performance and that makes evident the \nimportance of providing multiple policies. Moreover, we showed\nthat the introduction of PSS led to very good performance\ngains for some policies.\nAs future work, we intend to run PackageBLAST in a \ngeographically dispersed grid, to evaluate the impact of high\nnetwork latencies in the allocation policies and in PSS. Also,\nwe intend to provide support for genomic database \nsynchronization and dynamic join/leave operations for slaves.\n8. REFERENCES\n[1] S. F. Altschul, W. Gish, W. Miller, E. W. Myers, and\nD. J. Lipman. A basic local alignment search tool.\nJournal of Molecular Biology, 215:403-410, 1990.\n[2] A. Darling, L. Carey, and W. Feng. The design,\nimplementation, and evaluation of mpiblast. 4th\nInternational Conference on Linux Clusters, 2003.\n[3] S. F. A. et al. Gapped blast and psi-blast: a new\ngeneration of protein database search programs.\nNucleic Acids Research, 25(17):3389-3402, 1997.\n[4] I. Foster and C. Kesselman. Globus: A metacomputing\ninfrastructure toolkit. International Journal of\nSupercomputer Applications, 11(2):115-128, 1997.\n[5] I. Foster and C. Kesselman. The Grid: Blueprint of a\nFuture Computing Infrastructure. Morgan-Kauffman,\n1999.\n[6] W. Gish. Washington university blast.\nhttp://blast.wustl.edu, 1996-2002.\n[7] D. Gusfield. Algorithms on Strings, Trees and\nSequences. Cambridge University Press, 1997.\n[8] S. F. Hummel, E. Schonberg, and L. E. Flynn.\nFactoring: A method for scheduling parallel loops.\nCommunications of the ACM, 35(8):90-101, 1992.\n[9] A. Krishnan. Gridblast: High throughput blast on the\ngrid. Symposium on Biocomputing, January 2003.\n[10] D. Peng., W. Yan, and Z. Lei. Parallelization of\nblast++. Technical report, Singapore-MIT, 2004.\n[11] C. D. Polychronopoulos and D. J. Kuck. Guided\nself-scheduling: A practical scheduling scheme for\nparallel supercomputers. IEEE Transactions on\nComputers, 36(12):1425-1439, Dec. 1987.\n[12] M. K. Satish and R. R. Joshi. Gbtk: A toolkit for grid\nimplementation of blast. 7th International Conference\nHPCAsia, pages 378-382, 2004.\n[13] G. Shao. Adaptive Scheduling of Master/Worker\nApplications on Distributed Computational Resources.\nPhD thesis, Univ. California at San Diego, 2001.\n[14] T. Smith and M. Waterman. Identification of common\nmolecular subsequences. J. Mol. Biol., 147:195-197,\n1981.\n[15] P. Tang and P. C. Yew. Processor self-scheduling for\nmultiple nested parallel loops. In Int. Conf. on\nParallel Processing (ICPP), pages 528-535, 1986.\n[16] T. H. Tzen and L. M. Ni. Trapezoidal self-scheduling:\nA practical scheme for parallel compilers. IEEE\nTransactions on Parallel and Distributed Systems,\n4(1):87-98, Jan. 1993.\n160\n": ["biological sequence comparison", "adaptive multi-policy grid service", "task allocation", "blast search", "packageblast", "bioinformatics", "grid computing", "computational biology", "genome project", "segmented genetic database", "heterogeneous non-dedicated platform", "grid environment", "pss", "package weighted adaptive self-scheduling", "bioinformatic", ""]}