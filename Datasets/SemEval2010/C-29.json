{"Implementation and Performance Evaluation of\nCONFLEX-G: Grid-enabled Molecular Conformational\nSpace Search Program with OmniRPC\nYoshihiro Nakajima\nGraduate School of Systems & Information\nEngineering, University of Tsukuba\nTsukuba, 305-8577, Japan\nyoshihiro@hpcs.is.tsukuba.ac.jp\nMitsuhisa Sato\nInstitute of Information Sciences and Electronics,\nUniversity of Tsukuba\nTsukuba, 305-8577, Japan\nmsato@is.tsukuba.ac.jp\nHitoshi Goto\nKnowledge-based Information Engineering,\nToyohashi University of Technology\nToyohashi, 441-8580, Japan\ngotoh@cochem2.tutkie.tut.ac.jp\nTaisuke Boku, Daisuke Takahashi\nInstitute of Information Sciences and Electronics,\nUniversity of Tsukuba\nTsukuba, 305-8577, Japan\n{taisuke,daisuke}@hpcs.is.tsukuba.ac.jp\nABSTRACT\nCONFLEX-G is the grid-enabled version of a molecular \nconformational space search program called CONFLEX. We\nhave implemented CONFLEX-G using a grid RPC system\ncalled OmniRPC. In this paper, we report the performance\nof CONFLEX-G in a grid testbed of several geographically\ndistributed PC clusters. In order to explore many \nconformation of large bio-molecules, CONFLEX-G generates\ntrial structures of the molecules and allocates jobs to \noptimize a trial structure with a reliable molecular mechanics\nmethod in the grid. OmniRPC provides a restricted \npersistence model to support the parametric search applications.\nIn this model, when the initialization procedure is defined\nin the RPC module, the module is automatically \ninitialized at the time of invocation by calling the initialization\nprocedure. This can eliminate unnecessary communication\nand initialization at each call in CONFLEX-G. \nCONFLEXG can achieve performance comparable to CONFLEX MPI\nand can exploit more computing resources by allowing the\nuse of a cluster of multiple clusters in the grid. The \nexperimental result shows that CONFLEX-G achieved a speedup\nof 56.5 times in the case of the 1BL1 molecule, where the\nmolecule consists of a large number of atoms, and each trial\nstructure optimization requires significant time. The load\nimbalance of the optimization time of the trial structure\nmay also cause performance degradation.\nCategories and Subject Descriptors\nC.2.4 [Computer Systems Organization]: \nCOMPUTERCOMMUNICATION NETWORK-Distributed Systems;\nJ.2.4 [Computer Applications]: PHYSICAL SCIENCES\nAND ENGINEERING\nGeneral Terms\nDesign,Performance\n1. INTRODUCTION\nElucidation of the stable conformations and the folding\nprocess of proteins is one of the most fundamental and \nchallenging goals in life science. While some of the most \ncommon secondary structures (e.g., certain types of helix, the\nbeta-strand, and the coil) are well known, precise \nanalysis of the thousands of chemically important conformers\nand pico-second-order analysis of their conformational \ninterconversions via the transition states on the potential energy\nsurface are required for the microsecond-order investigation\nof the folding process toward the tertiary structure \nformations.\nRecently, the concept of the computational grid has begun\nto attract significant interest in the field of high-performance\nnetwork computing. Rapid advances in wide-area \nnetworking technology and infrastructure have made it possible to\nconstruct large-scale, high-performance distributed \ncomputing environments, or computational grids, that provide \ndependable, consistent and pervasive access to enormous \ncomputational resources.\nCONFLEX is one of the most efficient and reliable \nconformational space search programs[1]. We have applied this\n154\nprogram to parallelization using global computing. The \nperformance of the parallelized CONFLEX enables exploration\nof the lower-energy region of the conformational space of\nsmall peptides within an available elapsed time using a local\nPC cluster. Since trial structure optimization in CONFLEX\nis calculated via molecular mechanics, conformational space\nsearch can be performed quickly compared to that using\nmolecular orbital calculation.\nAlthough the parallelized version of CONFLEX was used\nto calculate in parallel the structure optimization, which\ntakes up over 90% of the processing in the molecular \nconformation search, sufficient improvement in the speedup could\nnot be achieved by this method alone. Therefore, for high\npolymers from live organisms, such as HIV protease, the\nuse one PC cluster is insufficient due to the requirement\nfor optimization of a huge number of trial structures. This\nrequires the vast computer resources of a grid computing\nenvironment.\nIn this paper, we describe CONFLEX-G, a grid-enabled\nmolecular conformational search program, using OmniRPC\nand report its performance in a grid of several PC \nclusters which are geographically distributed. The prototype\nCONFLEX-G allocates calculation trial structures \noptimization, which is a very time-consuming task, to worker nodes\nin the grid environment in order to obtain high throughput.\nIn addition, we compare the performance of CONFLEX-G\nin a local PC cluster to that in a grid testbed.\nOmniRPC[2, 3, 4] is a thread-safe implementation of Ninf\nRPC[5, 6] which is a Grid RPC facility for grid \nenvironment computing. Several systems adopt the concept of the\nRPC as the basic model for grid environment computing,\nincluding Ninf-G[7], NetSolve[8] and CORBA[9]. The \nRPCstyle system provides an easy-to-use, intuitive programming\ninterface, allowing users of the grid system to easily \ncreate grid-enabled applications. In order to support parallel\nprogramming, an RPC client can issue asynchronous call\nrequests to a different remote computer to exploit \nnetworkwide parallelism via OmniRPC.\nIn this paper, we propose the OmniRPC persistence model\nto a Grid RPC system and demonstrate its effectiveness. In\norder to support a typical application for a grid \nenvironment, such as a parametric search application, in which the\nsame function is executed with different input parameters on\nthe same data set. In the current GridRPC system[10], the\ndata set by the previous call cannot be used by subsequent\ncalls. In the OmniRPC system, once a remote executable\nis invoked, the client attempts to use the invoked remote\nexecutable and its initialized state for subsequent RPC calls\nto the same remote functions in order to eliminate the \ninvocation cost of each call.\nThis paper demonstrates that CONFLEX-G is able to \nexploit the huge computer resources of a grid environment\nand search large-scale molecular conformers. We \ndemonstrate CONFLEX-G on our grid testbed using the actual\nprotein as a sample molecule. The OmniRPC facility of the\nautomatic initializable module (AIM) allows the system to\nefficiently calculate numerous conformers. Furthermore, by\nusing OmniRPC, the user can grid-parallelize the existing\napplication, and move from the cluster to the grid \nenvironment without modifying program code and compiling the\nprogram. In addition, the user can easily build a private\ngrid environment.\nThe rest of this paper is organized as follows. An overview\nSelection of\nInitial Structure\nConformations\nDatabase\nLocal\nPerturbation\nGeometry\nOptimization\nComparison\nand Registration\nFigure 1: Algorithm of conformational space search\nin the original CONFLEX.\nof the CONFLEX system is presented in Section2, and the\nimplementation and design of CONFLEX-G are described\nin Section 3. We report experimental results obtained using\nCONFLEX-G and discuss its performance in Section 4. In\nSection 6, we present conclusions and discuss subjects for\nfuture study.\n2. CONFLEX\nCONFLEX [1] is an efficient conformational space search\nprogram, which can predominately and exhaustively search\nthe conformers in the lower-energy region. Applications of\nCONFLEX include the elucidation of the reactivity and \nselectivity of drugs and possible drug materials with regard to\ntheir conformational flexibility.\n2.1 Algorithm of ConformationalSpaceSearch\nThe basic strategy of CONFLEX is an exhaustive search\nof only the low-energy regions. The original CONFLEX\nperforms the following four major steps:\n1. Selection of an initial structure among the previously\ndiscovered unique conformers sorted in a \nconformational database. (An input structure is used as the\nfirst initial structure at the beginning of a search \nexecution only.)\n2. Generation of trial structures by local perturbations\nto the selected initial structure.\n3. Geometry optimization for the newly generated trial\nstructures.\n4. Comparison of the successfully optimized (trial) \nstructures with the other conformers stored in a \nconformation database, and preservation of newly discovered\nunique conformers in the database.\nFigure 1 shows the outline of CONFLEX, the original \nconformational space search algorithm.\nThese procedures incorporate two unique strategies. \nFigure 2 shows the strategies for generating local perturbations\nin CONFLEX. The first strategy involves both corner \nflapping and edge flipping for the ring atoms and stepwise \nrotation for side-chains or backbone chains. These methods\nprovide a highly efficient way to produce several good trial\nstructures. These perturbations can be considered to mimic\n155\nStepwise Rotation\nCorner Flap\nEdge Flip\nFigure 2: Strategies used to generate the local \nperturbations.\na barrier-crossing step in the elementary process of the \nthermal conformational inter-conversion. Actually, the \nperturbations of an initial structure correspond to the precise \nperformance around the space of the initial structure because\nof localization and weakness of the perturbation.\nThe selection rule of the initial structure, the \nLowestConformer-First rule, is the second strategy for directing\nthe conformation search expanded to the low-energy regions.\nThe initial structure is selected as the set of lowest energy\nconformers stored in the conformation database. This rule\nis effective in moving down the search space toward lower\nenergy regions, like water from a stream running into an\nempty reservoir, while filling local depressions along the\nway. Therefore, these tactical procedures of the CONFLEX\nsearch are referred to as the Reservoir Filling Algorithm.\nIn order to remain in the low-energy region and perform\nan exhaustive search, the search limit (SEL), which \ndetermines the maximum energy of the initial structures, is\npre-defined. Gradually increasing SEL allows only the \nlowenergy conformers to be searched and avoids straying into\nunnecessarily high-energy regions.\n2.2 Parallelization of CONFLEX for Cluster\nFor application to over 100 atoms, CONFLEX was \nimproved using high-performance parallel computing techniques.\nIn the CONFLEX search algorithm, the geometry \noptimization procedures always take 95% of the elapsed time of the\nsearch execution. Therefore, we parallelized this \noptimization using the Master/Worker parallelization technique.\nWe modified the search procedures as follows. After trial\nstructures are generated (step 2), they are temporarily stored\nin a task pool on the master node. Then, each worker node\nis dynamically supplied with one trial structure from the\nmaster node. After an optimization on a worker node is\nfinished, the worker is immediately supplied with another\ntrial structure. When all of the trial structures related to a\ngiven initial structure are optimized, only the master \nprocedure is used in comparison. By parallelizing CONFLEX,\nthe speedup of searching molecular conformers obtained is\nas reported in[11].\n3. CONFLEX-G\nOriginally, CONFLEX was intended for use in \nexploring the conformers of the large bio-molecules, such HIV\nprotease. In such molecules, the number of trial \nstructures increases and the time required for optimization of\nRPC\nSelection of\nInitial Structure\nConformations\nDatabase\nLocal\nPerturbation\nComparison\nand Registration\nClient program\nTask Pool of\nGeometry\nOptimization\nRPC\nRPC\nGrid environment\nCluster B\nCluster A\nCluster C\nTrial structureTrial structure\nTrial structure\nTrial structure\nFigure 3: Procedure of CONFLEX-G.\nagent\nrexrex rex\nClient\njones.tsukuba.ac.jp\nhpc-serv.hpcc.jp\nhpc1 hpc2 hpc3\nAgent invocation\ncommunicationNetwork\nFigure 4: Overview of the OmniRPC system for the\nremote cluster having a private IP address.\nthe trial structure becomes immense. We implemented the\nparallelized version of CONFLEX, which cannot treat such\nmolecules using only a local PC cluster.\nIn order to exploit the vast computing resources of a grid\nenvironment, we designed and implemented CONFLEX-G,\nwhich is a grid-enabled version of CONFLEX, with the \nOmniRPC system. CONFLEX-G allocates jobs to optimize\na trial structure to the computational nodes of each \ncluster in the grid environment. Figure 3 shows the process of\nCONFLEX-G. The worker programs are initialized by the\ninitialize method, which is provided by the OmniRPC AIM\nfacility at worker invocation. At each RPC call, the \ninitialized state is reused on the remote host. In other words, the\nclient program can eliminate the initialization for each RPC\ncall, and can therefore optimize trial structures efficiently.\n3.1 The OmniRPC system\nOmniRPC is a Grid RPC system which allows seamless\nparallel programming from a PC cluster to a grid \nenvironment. OmniRPC inherits its API and basic architecture\nfrom Ninf. A client and the remote computational hosts\nwhich execute the remote procedures may be connected via\na network. The remote libraries are implemented as an \nexecutable program which contains a network stub routine as\nits main routine. We call this executable program a remote\nexecutable program (rex).\nWhen the OmniRPC client program starts, the \ninitialization function of OmniRPC system invokes the OmniRPC\nagent program omrpc-agent in the remote hosts listed in\nthe host file. To invoke the agent, the user can use the \nremote shell command rsh in a local-area network, the GRAM\n(Globus Resource Allocation Manager) API of the Globus\n156\ntoolkit[12] in a grid environment, or the secure remote shell\ncommand ssh. The user can switch the configurations only\nby changing the host file.\nOmniRpcCall is a simple client programming interface for\ncalling remote functions. When OmniRpcCall makes a \nremote procedure call, the call is allocated to an appropriate\nremote host. When the client issues the RPC request, it\nrequests that the agent in the selected host submit the job\nof the remote executable with the local job scheduler \nspecified in the host file. If the job scheduler is not specified, the\nagent executes the remote executable in the same node by\nthe fork system call. The client sends the data of the input\narguments to the invoked remote executable, and receives\nthe results upon return of the remote function. Once a \nremote executable is invoked, the client attempts to use the\ninvoked remote executable for subsequent RPC calls in order\nto eliminate the cost of invoking the same remote executable\nagain.\nWhen the agent and the remote executables are invoked,\nthe remote programs obtain the client address and port from\nthe argument list and connect back to the client by direct\nTCP/IP or Globus-IO for data transmission. Because the\nOmniRPC system does not use any fixed service ports, the\nclient program allocates unused ports dynamically to wait\nfor connection from the remote executables. This avoids\npossible security problems, and allows the user to install the\nOmniRPC system without requiring a privileged account.\nHerein, a typical grid resource is regarded as a cluster of\ngeographically distributed PC clusters. For PC clusters on\na private network, an OmniRPC agent process on the server\nhost functions as a proxy to relay communications between\nthe client and the remote executables by multiplexing the\ncommunications using a single connection.\nThis feature, called multiplex IO (MXIO), allows a single\nclient to use up to 1,000 remote computing hosts. When the\nPC cluster is inside a firewall, the port forwarding of SSH\nenables the node to communicate to the outside with MXIO.\nFigure 4 shows the overview of the OmniRPC system for a\nremote cluster with a private IP address.\nFor parallel programming, the programmer can use \nasynchronous remote procedure calls, allowing the client to issue\nseveral requests while continuing with other computations.\nThe requests are dispatched to different remote hosts to be\nexecuted in parallel, and the client waits or polls the \ncompleted request. In such a programming model with \nasynchronous remote procedure calls, the programmer should\nhandle outstanding requests explicitly. Because OmniRPC\nis a thread-safe system, a number of remote procedure calls\nmay be outstanding at any time for multi-threaded programs\nwritten in OpenMP.\n3.2 OmniRPC persistence model: automatic\ninitializable module\nOmniRPC efficiently supports typical Master/Worker \nparallel applications such as parametric execution programs.\nFor parametric search applications, which often require large\namount of identical data for each call, OmniRPC supports a\nlimited persistence model, which is implemented by the \nautomatic initializable module. The user can define an \ninitialization procedure in the remote executable in order to send\nand store data automatically in advance of actual remote\nprocedure calls. Since the remote executable may accept \nrequests for subsequent calls, the data set which has been set\nby the initialization procedure can be re-used. As a result,\nthe worker program can execute efficiently and reduce the\namount of data transmitted for initialization.\nOnce a remote executable is invoked, the client attempts\nto use the invoked remote executable for subsequent RPC\ncalls. However, OmniRPC does not guarantee persistence\nof the remote executable, so that the data set by the \nprevious call cannot be used by subsequent calls. This is because\na remote call by OmniRpcCall may be scheduled to any \nremote host dynamically, and remote executables may be \nterminated accidentally due to dynamic re-scheduling or host\nfaults. However, persistence of the remote executable can\nbe exploited in certain applications. An example is a \nparametric search application: in such an application, it would\nbe efficient if a large set of data could be pre-loaded by the\nfirst call, and subsequent calls could be performed on the\nsame data, but with different parameters. This is the case\nfor CONFLEX.\nOmniRPC provides a restricted persistence model through\nthe automatic initializable module (AIM) in order to support\nthis type of application. If the initialization procedure is \ndefined in the module, the module is automatically initialized\nat invocation by calling the initialization procedure. When\nthe remote executable is re-scheduled in different hosts, the\ninitialization is called to initialize the newly allocated \nremote module. This can eliminate unnecessary \ncommunications when RPC calls use the same data.\nTo reveal more about the difference in progress between\nthe cases with OmniRPC AIM and without OmniRPC AIM,\nwe present two figures. Figure 5 illustrates the time chart\nof the progress of a typical OmniRPC application using the\nOmniRPC AIM facility, and Figure 6 illustrates the time\nchart of the same application without the OmniRPC AIM\nfacility. In both figures, the lines between diamonds \nrepresent the processes of initialization, and the lines between\npoints represent the calculation. The bold line indicates the\ntime when the client program sends the data to a worker\nprogram. It is necessary for the application without the\nOmniRPC AIM facility to initialize at each RPC. The \napplication using the OmniRPC AIM facility can re-use the\ninitialized data once the data set is initialized. This can\nreduce the initialization at each RPC. The workers of the\napplication with the AIM can calculate efficiently compared\nto the application without the OmniRPC AIM facility.\n3.3 Implementation of CONFLEX-G using\nOmniRPC\nFigure 3 shows an overview of the process used in \nCONFLEXG. Using RPCs, CONFLEX-G allocates the processes of\ntrial structure optimization, which are performed by the\ncomputation nodes of a PC cluster in the MPI version of\nCONFLEX, to the computational nodes of each cluster in\na grid environment. There are two computations which are\nperformed by the worker programs in CONFLEX-G. One is\nthe initialization of a worker program, and another is the\ncalculation of trial structure optimization.\nFirst, the OmniRPC facility of the AIM is adapted for \ninitialization of a worker program. This facility automatically\ncalls the initialization function, which is contained in the\nworker program, once the client program invokes the worker\nprogram in a remote node. It is necessary for the common\nRPC system including GridRPC to initialize a program for\nevery RPC call, since data persistence of worker programs\n157\ntime\nClient Program\nWorker Program 1\nWorker Program 2\ninitialization\ninitialization\ncalculation calculation\ncalculation calculation\ncalculation\nParallelized using asynchronous RPCs\nFigure 5: Time chart of applications using the OmniRPC facility of the automatic initializable module.\ntime\nClient Program\nWorker Program 1\nWorker Program 2\ninitialization initializationcalculation\ncalculation calculation\ncalculation\ninitialization initialization\ninitialization\nParallelized using asynchronous RPCs\ncalculation\nFigure 6: Time chart of applications without the OmniRPC facility of the automatic initializable module.\nTable 1: Machine configurations in the grid testbed.\nSite Cluster Name Machine Network Authentication # of Nodes # of CPUs\nUniv. of Tsukuba Dennis Dual Xeon 2.4GHz 1Gb Ethernet Globus, SSH 14 28\nAlice Dual Athlon 1800+ 100Mb Ethernet Globus, SSH 18 36\nTUT Toyo Dual Athlon 2600+ 100Mb Ethernet SSH 8 16\nAIST Ume Dual Pentium3 1.4GHz 1Gb Ethernet Globus, SSH 32 64\nis not supported. In OmniRPC, however, when the \nInitialize remote function is defined in the worker program and\na new worker program, corresponding to the other RPC,\nis assigned to execute, an Initialize function is called \nautomatically. Therefore, after the Initialize function call to set\nup common initialization data, a worker program can re-use\nthis data and increase the efficiency of it\"s processes. Thus,\nthe higher the set-up cost, the greater the potential benefit.\nWe implemented the worker program of CONFLEX-G to\nreceive data, such as evaluation parameters of energy, from\na client program and to be initialized by the Initialize\nfunction. We arranged the client program of CONFLEX-G\nto transfer the parameter file at the time of worker \ninitialization. This enables execution to be performed by modify\nonly the client setting if the user wants to run CONFLEX-G\nwith a different data set.\nSecond, in order to calculate trial structure optimization\nin a worker program, the worker program must receive the\ndata, such as the atom arrangement of the trial structure\nand the internal energy state. The result is returned to\nthe client program after the worker has Optimized the trial\nstructure.\nSince the calculation portion of the structure optimization\nin this worker program can be calculated independently \nusing different parameters, we parallelized this portion using\nasynchronous RPCs on the client side. To call the structure\noptimization function in a worker program from the client\nprogram, we use the OmniRpcCallAsync API, which is \nintended for asynchronous RPC. In addition, OmniRpcCallWaitAll\nAPI which waits until all asynchronous RPCs are used in \norder to perform synchronization with all of the asynchronous\nRPCs completed so as to optimize the trial structure. The\nclient program which assigns trial structure optimization to\nthe calculation node of a PC cluster using RPC is outlined\nas follows.\nOmniRpcInit()\nOmniRpcModuleInit(\"conflex_search\",...);\n...\nwhile( <new conformers> ) {\nforeach( <trial structures> )\nOmniRpcCallAsync(\"conflex_search_worker\", ...);\nOmniRpcWaitAll();\n...\nNote that OmniRpcModuleInit API returns only the \narguments needed for initialization and will not actually execute\nthe Initialization function. As described above, the \nactual Initialization is performed at the first remote call.\nSince the OmniRPC system has an easy round-robin \nscheduler, we do not have to explicitly write the code for load \nbalance. Therefore, RPCs are allocated automatically to idle\nworkers.\n158\nTable 2: Network performance between the master\nnode of the Dennis cluster and the master node of\neach PC cluster.\nRound-Trip Throughput\nCluster Time (ms) (Mbps)\nDennis 0.23 879.31\nAlice 0.18 94.12\nToyo 11.27 1.53\nUme 1.07 373.33\n4. PRELIMINARY RESULTS\n4.1 Grid Testbed\nThe grid testbed was constructed by computing resources\nat the University of Tsukuba, the Toyohashi University of\nTechnology (TUT) and the National Institute of Advanced\nIndustrial Science and Technology (AIST). Table 1 shows\nthe computing resources used for the grid of the present\nstudy.\nThe University of Tsukuba and AIST are connected by a\n1-Gbps Tsukuba WAN, and the other PC clusters are \nconnected by SINET, which is wide-area network dedicated to\nacademic research in Japan. Table 2 shows the performance\nof the measured network between the master node of the\nDennis cluster and the master node of each PC cluster in\nthe grid testbed. The communication throughput was \nmeasured using netperf, and the round-trip time was measured\nby ping.\n4.2 Performance of CONFLEX-G\nIn all of the CONFLEX-G experiments, the client \nprogram was executed on the master node of the Dennis \ncluster at the University of Tsukuba. The built-in Round-Robin\nscheduler of OmniRPC was used as a job scheduler.\nSSH was used for an authentication system, the \nOminRPC\"s MXIO, which relays the I/O communication between\nclient program and worker programs by port forwarding of\nSSH was, not used. Note that one worker program is \nassigned and performed on one CPU of the calculation node\nin a PC cluster. That is, the number of workers is equal to\nthe number of CPUs.\nThese programs were compiled by the Intel Fortran \nCompiler 7.0 and gcc 2.95. MPICH, Version 1.2.5, was used\nto compare the performance between CONFLEX MPI and\nCONFLEX-G. In order to demonstrate the usability of the\nOmniRPC facility of the AIM, we implemented another \nversion of CONFLEX-G which did not utilize the OmniRPC\nfacility. The worker program in this version of \nCONFLEXG must be initialized at each RPC because the worker does\nnot hold the previous data set.\nIn order to examine the performance of CONFLEX-G, we\nselected two peptides and two small protein as test molecules:\n\u00e2\u20ac\u00a2 N-acetyl tetra-alanine methylester (AlaX04)\n\u00e2\u20ac\u00a2 N-acetyl hexdeca-alanine methylester (AlaX16)\n\u00e2\u20ac\u00a2 TRP-cage miniprotein construct TC5B (1L2Y)\n\u00e2\u20ac\u00a2 PTH receptor N-terminus fragment (1BL1)\nTable 3 lists the characteristics of these sample molecules.\nThe column trial structure / loops in this table shows the\nFigure 7: Performances of CONFLEX-G, \nCONFLEX MPI and Original CONFLEX in the Dennis\ncluster.\nFigure 8: Speedup ratio, which is based on the\nelapsed time of CONFLEX-G using one worker in\nthe Dennis cluster.\nFigure 9: Performance of CONFLEX-G with and\nwithout the OmniRPC facility of automatic \ninitializable module for AlaX16.\n159\nTable 3: Characteristics of molecules and data transmission for optimizing trial molecular structures in each\nmolecular code.\nMolecular # of # of total trial trial structure Data transfer to Data transfer\ncode atoms structures / loop initialize a worker / trial structure\nAlaX04 181 360 45 2033KB 17.00KB\nAlaX16 191 480 160 2063KB 18.14KB\n1L2Y 315 331 331 2099KB 29.58KB\n1BL1 519 519 519 2150KB 48.67KB\nTable 4: Elapsed search time for the molecular conformation of AlaX04.\nTotal Total Optimization\nCluster # of Structures optimization time Elapsed Speed\n(# of workers) workers / worker time (s) / structure (s) time (s) up\nDennis (sequential) 1 320.0 1786.21 4.96 1786.21 1.00\nToyo (16) 16 20.0 1497.08 4.16 196.32 9.10\nDennis (28) 28 11.4 1905.51 5.29 97.00 18.41\nAlice (36) 36 8.9 2055.25 5.71 87.09 20.51\nUme (56) 56 5.7 2196.77 6.10 120.69 14.80\nDennis (28) + Toyo (16) 44 7.3 1630.09 4.53 162.35 11.00\nAlice (36) + Toyo (16) 52 6.2 1774.53 4.93 178.24 10.02\nDennis (28) + Alice (36) 64 5.0 1999.02 5.55 81.52 21.91\nDennis (28) + Ume (56) 84 3.8 2085.84 5.79 92.22 19.37\nAlice (36) + Ume (56) 92 3.5 2120.87 5.89 101.25 17.64\nTable 5: Elapsed search time for the molecular conformation of AlaX16\nTotal Total Optimization\nCluster # of Structures optimization time Elapsed Speed\n(# of workers) workers / worker time (s) / structure (s) time (s) up\nDennis (1) 1 480.0 74027.80 154.22 74027.80 1.00\nToyo (16) 16 30.0 70414.21 146.70 4699.15 15.75\nDennis (28) 28 17.1 74027.80 154.22 3375.60 21.93\nAlice (36) 36 13.3 90047.27 187.60 3260.41 22.71\nUme (56) 56 8.6 123399.38 257.08 2913.63 25.41\nDennis (28) + Toyo (16) 44 10.9 76747.74 159.89 2762.10 26.80\nAlice (36) + Toyo (16) 52 9.2 82700.44 172.29 2246.73 32.95\nDennis (28) + Alice (36) 64 7.5 87571.30 182.44 2051.50 36.08\nToyo (16) + Ume (56) 72 6.7 109671.32 228.48 2617.85 28.28\nDennis (28) + Ume (56) 84 5.7 102817.90 214.20 2478.93 29.86\nDennis(28)+Ume(56)+Toyo(16) 100 4.8 98238.07 204.66 2478.93 29.86\nTable 6: Elapsed time of the search for the trial structure of 1L2Y.\nCluster Total # of Structures Optimization time Elapsed Elapsed Speed\n(# of workers) workers / worker / structure (s) time (s) time (H) up\nToyo MPI (1) 1 331.0 867 286,967 79.71 1.00\nToyo MPI (16) 16 20.7 867 18,696 5.19 15.34\nDennis (28) 28 11.8 803 14,101 3.91 20.35\nDennis (28) + Ume(56) 84 3.9 1,064 8,316 2.31 34.50\nTable 7: Elapsed time of the search for the trial structure of 1BL1.\nCluster Total # of Structures Optimization time Elapsed Elapsed Speed\n(# of workers) workers / worker / structure (s) time (s) time (H) up\nToyo MPI (1) 1 519.0 3,646 1892,210 525.61 1.00\nToyo MPI (16) 16 32.4 3,646 120,028 33.34 15.76\nDennis (28) 28 18.5 3,154 61,803 17.16 30.61\nDennis (28) + Ume (56) 84 6.1 4,497 33,502 9.30 56.48\n160\nnumber of trial structures generated in each iteration, \nindicating the degree of parallelism. Figure 3 also summarizes\nthe amount of data transmission required for initialization\nof a worker program and for optimization of each trial \nstructure. Note that the amount of data transmission, which is\nrequired in order to initialize a worker program and optimize\na trial structure in the MPI version of CONFLEX, is equal\nto that of CONFLEX-G. We used an improvement version\nof MM2 force field to assign a potential energy function to\nvarious geometric properties of a group of atoms.\n4.2.1 Performance in a Local Cluster\nWe first compared the performance of CONFLEX-G, the\nMPI version of CONFLEX, and the original sequential \nversion of CONFLEX-G using a local cluster. We investigated\nperformance by varying the number of workers using the\nDennis cluster. We chose AlaX04 as a test molecule for this\nexperiment. Figure 7 compares the results for the \nCONFLEX MPI and CONFLEX-G in a local PC cluster.\nThe result of this experiment shows that CONFLEX-G\ncan reduce the execution time as the number of workers\nincreases, as in the MPI version of CONFLEX. We found\nthat CONFLEX-G achieved efficiencies comparable to the\nMPI version. With 28 workers, CONFLEX-G achieved an\n18.00 times speedup compared to the CONFLEX \nsequential version. The performance of CONFLEX-G without the\nOmniRPC AIM facility is worse than that of \nCONFLEXG using the facility, based on the increase in the number\nof workers. This indicates that the OmniRPC AIM enables\nthe worker to calculate efficiently without other calculations,\nsuch initialization or invocation of worker programs.\nAs the number of workers is increased, the performance of\nCONFLEX-G is a slightly lower than that of the MPI \nversion. This performance degradation is caused by differences\nin the worker initialization processes of CONFLEX-G and\nCONFLEX MPI. In the case of CONFLEX MPI, all workers\nare initialized in advance of the optimization phase. In the\ncase of OminRPC, the worker is invoked on-demand when\nthe RPC call is actually issued. Therefore, the initialization\nincurs this overhead.\nSince the objective of CONFLEX-G is to explore the \nconformations of large bio-molecules, the number of trial \nstructures and the time to optimize the trial structure might be\nlarge. In such cases, the overhead to invoke and initialize\nthe worker program can be small compared to the entire\nelapsed time.\n4.2.2 Performance for Peptides in The Grid Testbed\nFirst, the sample molecules (AlaX04 and AlaX16) were\nused to examine the CONFLEX-G performance in a grid\nenvironment. Figure 8 shows the speedup achieved by using\nmultiple clusters compared to using one worker in the Dennis\ncluster. Detailed results are shown in Table 4 and Table 5.\nIn both cases, the best performance was obtained using\n64 workers of the combination of the Dennis and Alice \nclusters. CONFLEX-G achieved a maximum speedup of 36.08\ntimes for AlaX04 and a maximum speedup of 21.91 times\nfor AlaX16.\nIn the case of AlaX04, the performance is improved only\nwhen the network performance between clusters is high.\nHowever, even if two or more clusters are used in a wide\narea network environment, the performance improvement\nwas slight because the optimization time of one trial \nstructure generated from AlaX04, a small molecule, is short. In\naddition, the overhead required for invocation of a worker\nprogram and network data transmission consume a large\nportion of the remaining processing time. In particular,\nthe data transmission required for the initialization of a\nworker program is 2 MB. In the case of Toyo cluster, where\nthe network performance between the client program and\nthe worker programs is poor, the time of data transmission\nto the worker program required approximately 6.7 seconds.\nSince this transmission time was longer than the processing\ntime of one structure optimization in CONFLEX-G, most\nof the time was spent for this data transmission. \nTherefore, even if CONFLEX-G uses a large number of \ncalculation nodes in a wide area network environment, the benefit\nof using a grid resource is not obtained.\nIn the case of AlaX16, CONFLEX-G achieved a speedup\nby using two or more PC clusters in our grid testbed. This\nwas because the calculation time on the worker program\nwas long and the overhead, such as network latency and the\ninvoking of worker programs, became relatively small and\ncould be hidden. The best performance was obtained using\n64 workers in the Dennis and Alice clusters. In the case of\nAaX16, the achieved performance was a speedup of 36.08\ntimes.\nFigure 9 reveals the effect of using the facility of the \nOmniRPC AIM on CONFLEX-G performance. In most cases,\nCONFLEX-G with the OmniRPC AIM facility archived \nbetter performance than CONFLEX-G without the facility. In\nparticular, the OmniRPC AIM facility was advantageous\nwhen using two clusters connected by a low-performance\nnetwork. The results indicate that the OmniRPC AIM \nfacility can improve performance in the grid environment.\n4.2.3 PerformanceforSmallProteininTheGridTestbed\nFinally, we explored the molecular conformation using\nCONFLEX-G for large molecules. In a grid environment,\nthis experiment was conducted using the Dennis and Ume\nclusters. In this experiment, we used two proteins, 1L2Y\nand 1BL1. Table 6 and Table 7 show the performance of\nCONFLEX-G in the grid environment and that of \nCONFLEX MPI in the Toyo cluster, respectively. The speedups\nin these tables were computed respectively based on the \nperformance of one worker and 16 workers of the Toyo cluster\nusing CONFLEX MPI.\nCONFLEX-G with 84 workers in Dennis and Ume clusters\nobtained maximum speedups of 56.5 times for 1L2Y and 34.5\ntimes for 1L2Y. Since the calculation time for structure \noptimization required a great deal of time, the ratio of overhead,\nincluding tasks such as the invocation of a worker program\nand data transmission for initialization, became very small,\nso that the performance of CONFLEX-G was improved.\nWe found that the load imbalance in the processing time\nof optimization for each trial structure caused performance\ndegradation. When we obtained the best performance for\n1L2Y using the Dennis and Ume clusters, the time for each\nstructure optimization varied from 190 to 27,887 seconds,\nand the ratio between the longest and shortest times was\n13.4. For 1BL1, the ratio of minimum time over maximum\ntime was 190. In addition, in order that the worker \nprogram wait until the completion of optimization of all trial\nstructures, all worker programs were found to wait in an\nidle state for approximately 6 hours. This has caused the\nperformance degradation of CONFLEX-G.\n161\n4.3 Discussion\nIn this subsection, we discuss the improvement of the \nperformance reflected in our experiments.\nExploiting parallelism - In order to exploit more \ncomputational resources, it is necessary to increase the degree\nof parallelism. In this experiment, the degree of parallelism\nwas not so large in the case of the sample molecules. When\nusing a set of over 500 computing nodes for 1BL1, the \nnumber of one trial structures assigned to each worker will be\nonly one or two. If over 100 trial structures are assigned\nto each worker program, calculation can be performed more\nefficiently due to the reduction of the overhead for worker \ninvocation and initialization via the facility of the OmniRPC\nAIM.\nOne idea for increasing parallelism is to overlap the \nexecution of two or more sets of trial structures. In the current\nalgorithm, a set of trial structures is generated from one\ninitial structure and computed until optimizations for all\nstructures in this set are calculated. Furthermore, this will\nhelp to improve load imbalance. By having other sets of\ntrial structures overlap, even if some optimizations require\na long time, the optimization for the structures in other sets\ncan be executed to compensate for the idle workers for other\noptimizations. It is however unclear how such modification\nof the algorithm might affect the quality of the final results\nin terms of a conformation search.\nImprovement in load imbalance when optimizing each trial\nstructure - Table 8 lists the statistics for optimization times\nof trial structures generated for each sample molecule \nmeasured using 28 workers in the Dennis cluster. When two or\nmore sets of PC clusters are used, the speedup in \nperformance is hampered by the load imbalance of the \noptimization of the trial structures. The longest time for \noptimizing a trial structure was nearly 24 times longer than the\nshortest time. Furthermore, other workers must wait until\nthe longest job has Finished, so that the entire execution\ntime cannot be reduced. When CONFLEX-G searched the\nconformers of 1BL1 by the Dennis cluster, the longest \ncalculation time of the trial structure optimization made up\napproximately 80% of the elapsed time.\nTherefore, there are two possible solutions for the load\nImbalance.\n\u00e2\u20ac\u00a2 It is necessary to refine the algorithm used to generate\nthe trial structure, which suppresses the time variation\nfor optimizing a trial structure in CONFLEX. This\nenables CONFLEX-G to achieve high-throughput by\nusing many computer resources.\n\u00e2\u20ac\u00a2 One of the solutions is to overlap the executions for\ntwo or more sets of trial structures. In the current\nalgorithms, a set of trial structures is generated from\none initial structure and calculation continues until all\nstructures in this set are calculated. By having other\nsets of trial structures, even if a structure search takes\na long time, a job can be executed in order to \ncompensate the load imbalance by other jobs. However,\nhow such modification of the algorithms might affect\nthe efficiency is not clear.\n\u00e2\u20ac\u00a2 In this experiment, we used a simple build-in \nroundrobbin scheduler of OmniRPC, which is necessary in\norder to apply the scheduler that allocates structures\nwith long optimization times to a high-performance\nTable 8: Statistics of elapsed time of trial structure\noptimization using 28 workers in the Dennis cluster.\nMolecular Min Max Average Variance\ncode (s) (s) (s)\nAlaX04 2.0 11.3 5.3 3\nAlaX16 47.6 920.0 154.2 5404\n1L2Y 114.2 13331.4 803.2 636782\n1BL1 121.0 29641.8 3153.5 2734811\nnode and structures with short optimization times to\nlow-performance nodes. In general, however, it might\nbe difficult to predict the time required for trial \nstructure optimization.\nParallelization of the worker program for speedup to \noptimize a trial structure - In the current implementation, we\ndo not parallelize the worker program. In order to speed up\ntrial structures, hybrid programming using OmniRPC and\nOpenMP in an SMP (Symmetric Multiple Processor) \nmachine may be one of the alternative methods by which to\nimprove overall performance.\n5. RELATED WORK\nRecently, an algorithm has been developed that solves\nthe problems of parallelization and communication in poorly\nconnected processors to be used for simulation. The \nFolding@home project[13] simulates timescales thousands to \nmillions of times longer than previously achieved. This has \nallowed us to simulate folding for the first time and to directly\nexamine folding related diseases.\nSETI@home[14] is a program to search for alien life by\nanalyzing radio telescope signals using Fourier transform\nradio telescope data from telescopes from different sites.\nSETI@home tackles immensely parallel problems, in which\ncalculation can easily be divided among several computers.\nRadio telescope data chunks can easily be assigned to \ndifferent computers.\nMost of these efforts explicitly develop a docking \napplication as a parallel application using a special purpose parallel\nprogramming language and middleware, such as MPI, which\nrequires development skills and effort. However, the skills\nand effort required to develop a grid application may not be\nrequired for OmniRPC.\nNimrod/G[15] is a tool for distributed parametric \nmodeling and implements a parallel task farm for simulations that\nrequire several varying input parameters. Nimrod \nincorporates a distributed scheduling component that can manage\nthe scheduling of individual experiments to idle computers\nin a local area network. Nimrod has been applied to \napplications including bio-informatics, operations research, and\nmolecular modeling for drug design.\nNetSolve[8] is an RPC facility similar to OmniRPC and\nNinf, providing a similar programming interface and \nautomatic load balancing mechanism. Ninf-G[7] is a grid-enabled\nimplementation of Ninf and provides a GridRPC[10] system\nthat uses LDAP to manage the database of remote \nexecutables, but does not support clusters involving private IP \naddresses or addresses inside a firewall. Matsuoka et al.[16]\nhas also discussed several design issues related to grid RPC\nsystems.\n162\n6. CONCLUSIONS AND FUTURE WORK\nWe have designed and implemented CONFLEX-G using\nOmniRPC. We reported its performance in a grid testbed\nof several geographically distributed PC clusters. In order to\nexplore the conformation of large bio-molecules, \nCONFLEXG was used to generate trial structures of the molecules, and\nallocate jobs to optimize them by molecular mechanics in the\ngrid. OmniRPC provides a restricted persistence model so\nthat the module is automatically initialized at invocation by\ncalling the initialization procedure. This can eliminate \nunnecessary communication and the initialization at each call\nin CONFLEX-G.\nCONFLEX-G can achieves performance comparable to\nCONFLEX MPI and exploits more computing resources by\nallowing the use of multiple PC clusters in the grid. The\nexperimental result shows that CONFLEX-G achieved a\nspeedup of 56.5 times for the 1BL1 molecule, where the\nmolecule consists of a large number of atoms and each trial\nstructure optimization requires a great deal of time. The\nload imbalance of the trial structure optimizations may cause\nperformance degradation. We need to refine the algorithm\nused to generate the trial structure in order to improve the\nload balance optimization for trial structures in CONFLEX.\nFuture studies will include development of deployment\ntools and an examination of fault tolerance. In the \ncurrent OmniRPC, the registration of an execution program to\nremote hosts and deployments of worker programs are \nmanually set. Deployment tools will be required as the number\nof remote hosts is increased. In grid environments in which\nthe environment changes dynamically, it is also necessary to\nsupport fault tolerance. This feature is especially important\nin large-scale applications which require lengthy calculation\nin a grid environment.\nWe plan to refine the conformational optimization \nalgorithm in CONFLEX to explore the conformation space search\nof larger bio-molecules such HIV protease using up to 1000\nworkers in a grid environment.\n7. ACKNOWLEDGMENTS\nThis research was supported in part by a Grant-in-Aid\nfrom the Ministry of Education, Culture, Sports, Science\nand Technology in Japan, No. 14019011, 2002, and as part\nof the Program of Research and Development for Applying\nAdvanced Computational Science and Technology by the\nJapan Science and Technology Corporation (Research on\nthe grid computing platform for drug design). We would\nlike to thank grid technology research center, AIST, Japan\nfor providing computing resources for our experiment.\n8. REFERENCES\n[1] H. Goto and E. Osawa. An efficient algorithm for\nsearching low-energy conformers of cyclic and acyclic\nmolecules. J. Chem. Soc., Perkin Trans, 2:187-198,\n1993.\n[2] M. Sato, T. Boku, and D. Takahashi. OmniRPC: a\nGrid RPC System for Parallel Programming in\nCluster and Grid Environment. In Proc. of\nCCGrid2003, pages 219-229, 2003.\n[3] M. Sato, M. Hirano, Y. Tanaka, and S. Sekiguchi.\nOmniRPC: a Grid RPC facility for Cluster and Global\nComputing in OpenMP. In Proc. of Workshop on\nOpenMP Applications and Tools 2001(LNCS 2104 ),\npages 130-135, 2001.\n[4] OmniRPC Project.\nhttp://www.omni.hpcc.jp/omnirpc/.\n[5] M. Sato, H. Nakada, S. Sekiguchi, S. Matsuoka,\nU. Nagashima, and H. Takagi. Ninf: A Network Based\nInformation Library for Global World-Wide\nComputing Infrastructure. In HPCN Europe, pages\n491-502, 1997.\n[6] Ninf Project. http://ninf.apgrid.org/.\n[7] Y. Tanaka, H. Nakada, S. Sekiguchi, T. Suzumura,\nand S. Matsuoka. Ninf-G: A Reference\nImplementation of RPC-based Programming\nMiddleware for Grid Computing . Journal of Grid\nComputing, 1(1):41-51, 2003.\n[8] D. Arnold, S. Agrawal, S. Blackford, J. Dongarra,\nM. Miller, K. Seymour, K. Sagi, Z. Shi, and\nS. Vadhiyar. Users\" Guide to NetSolve V1.4.1.\nInnovative Computing Dept. Technical Report\nICL-UT-02-05, University of Tennessee, Knoxville,\nTN, June 2002.\n[9] Object management group. http://www.omg.org/.\n[10] K. Seymour, H. Nakada, S. Matsuoka, J. Dongarra,\nC. Lee, and H. Casanova. GridRPC: A Remote\nProcedure Call API for Grid Computing.\n[11] H.Goto, T. Takahashi, Y. Takata, K. Ohta, and U\nNagashima. Conflex: Conformational behaviors of\npolypeptides as predicted by a conformational space\nsearch. In Nanotech2003, volume 1, pages 32-35, 2003.\n[12] I. Foster and C. Kesselman. Globus: A metacomputing\ninfrastructure toolkit. The International Journal of\nSupercomputer Applications and High Performanc e\nComputing, 11(2):115-128, Summer 1997.\n[13] Stefan M. Larson, Christopher D. Snow, Michael\nShirts, and Vijay S. Pande. Folding@home and\ngenome@home: Using distributed computing to tackle\nprev iously intractable problems in computational\nbiology. Computational Genomics, 2002.\n[14] seti@home project.\nhttp://setiathome.ssl.berkeley.edu/.\n[15] R. Buyya, K. Branson, J. Giddy, and D. Abramson.\nThe virtual laboratory: a toolset to enable distributed\nmolecular modelling for drug design on the world-wide\ngrid. Concurrency and Computation: Practice and\nExperience, 15(1):1-25, January 2003.\n[16] S. Matsuoka, H. Nakada, M. Sato, and S. Sekiguchi.\nDesign issues of Network Enabled Server Systems for\nthe Grid. In Proc. of GRID 2000 (LNCS 1971), pages\n4-17, 2000.\n163\n": ["conflex-g", "omnirpc", "conformational space search", "bio-molecule", "rpc module", "initialization procedure", "mpus", "pc cluster", "grid computing", "grid rpc system", "conformational space search", "molecular mechanic", "automatic initializable module", "computational chemistry", ""]}